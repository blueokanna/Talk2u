\documentclass[11pt,a4paper]{article}

% ============================================================
%  Packages
% ============================================================
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amsthm,mathtools}
\usepackage{algorithm,algorithmic}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{cleveref}
\usepackage{xcolor}
\usepackage{enumitem}
\usepackage{geometry}
\usepackage{tikz}
\usetikzlibrary{arrows.meta,positioning,calc}
\usepackage{CJKutf8}
\usepackage{multirow}
\usepackage{subcaption}

\geometry{margin=2.5cm}

% ============================================================
%  Theorem environments
% ============================================================
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{assumption}[theorem]{Assumption}
\newtheorem{example}[theorem]{Example}

% ============================================================
%  Operators
% ============================================================
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator{\softmax}{softmax}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\rank}{rank}
\newcommand{\R}{\mathbb{R}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\Prob}{\mathbb{P}}
\newcommand{\cO}{\mathcal{O}}
\newcommand{\cL}{\mathcal{L}}
\newcommand{\cM}{\mathcal{M}}
\newcommand{\cD}{\mathcal{D}}
\newcommand{\cS}{\mathcal{S}}
\newcommand{\cE}{\mathcal{E}}
\newcommand{\cC}{\mathcal{C}}
\newcommand{\cK}{\mathcal{K}}
\newcommand{\cF}{\mathcal{F}}
\newcommand{\cH}{\mathcal{H}}
\newcommand{\cP}{\mathcal{P}}
\newcommand{\cN}{\mathcal{N}}
\newcommand{\cT}{\mathcal{T}}
\newcommand{\cA}{\mathcal{A}}
\newcommand{\cB}{\mathcal{B}}
\newcommand{\cR}{\mathcal{R}}
\newcommand{\cV}{\mathcal{V}}
\newcommand{\cW}{\mathcal{W}}
\newcommand{\cX}{\mathcal{X}}
\newcommand{\cY}{\mathcal{Y}}
\newcommand{\cZ}{\mathcal{Z}}
\newcommand{\bx}{\mathbf{x}}
\newcommand{\by}{\mathbf{y}}
\newcommand{\bz}{\mathbf{z}}
\newcommand{\be}{\mathbf{e}}
\newcommand{\bp}{\mathbf{p}}
\newcommand{\bq}{\mathbf{q}}
\newcommand{\bw}{\mathbf{w}}
\newcommand{\bmu}{\boldsymbol{\mu}}
\newcommand{\bSigma}{\boldsymbol{\Sigma}}
\newcommand{\KL}{\mathrm{KL}}
\newcommand{\TV}{\mathrm{TV}}
\newcommand{\Ent}{\mathrm{H}}

% ============================================================
%  Title
% ============================================================
\title{%
  \textbf{Affective Hierarchical Context Augmentation (AHCA):}\\[6pt]
  \large A Six-Layer Architecture for Emotion-Aware Retrieval-Augmented Generation\\
  in Role-Playing Conversational AI
}

\author{%
  Talk2U Research\\
  \texttt{talk2u@research.org}
}

\date{February 2026}

\begin{document}
\maketitle

% ============================================================
%  Abstract
% ============================================================
\begin{abstract}
Retrieval-augmented generation (RAG) systems for conversational AI typically
treat context injection as a flat, emotion-agnostic operation, leading to
emotionally incongruent responses and degraded user experience in
long-horizon dialogues.  We present \textbf{Affective Hierarchical Context
Augmentation (AHCA)}, a six-layer architecture that decomposes the
context-injection pipeline into formally defined stages: (1)~Identity
Anchoring, (2)~Memory-Augmented Retrieval via hybrid BM25--cosine Weighted
Reciprocal Rank Fusion (W-RRF), (3)~Affective State Tracking with
exponential-decay weighting and softmax normalization, (4)~Coherence
Preservation through bigram-overlap topic-continuity analysis,
(5)~Dialogue History Window with dynamic token-budget allocation, and
(6)~Response Diversity Regulation via coefficient-of-variation monitoring.

We provide rigorous mathematical formulations for each layer with explicit
assumptions.  We establish the following formal properties:
(i)~well-definedness and boundedness of the exponential-decay emotion
aggregation with effective sample size characterization
(\Cref{thm:softmax-welldef}), which, while elementary, makes the
numerical stability guarantees explicit;
(ii)~a Pareto-consistency property for W-RRF confirming that documents
ranked highly by both constituent rankers cannot be suppressed
(\Cref{thm:rrf-dominance}), a standard monotonicity consequence stated
here for completeness;
(iii)~a probabilistic fact-preservation bound under a correlated-error
model (\Cref{thm:fact-preservation}), providing conservative worst-case
estimates via union bounds;
(iv)~a conditional expected entropy increase for the diversity-regulation
mechanism (\Cref{thm:diversity}), valid under an empirically calibrated
compliance assumption;
and (v)~a dynamic regret bound for the exponential-decay estimator viewed
as an online tracker (\Cref{thm:regret}), which reveals the
bias--variance tradeoff governing the half-life parameter.
These results are not deep mathematical contributions; they are careful
formalizations that make assumptions explicit, provide quantitative
parameter-selection guidance, and identify failure modes.

We evaluate AHCA on a corpus of 2{,}000 role-playing dialogue sessions
against four baselines (vanilla RAG, MemoryBank, flat emotion-aware RAG,
and ablated AHCA variants), measuring emotional coherence, factual
consistency, response diversity, and user preference.  AHCA achieves
statistically significant improvements in emotional coherence ($+18.3\%$,
$p < 0.01$) and factual consistency ($+12.7\%$, $p < 0.01$) over the
strongest baseline.  We discuss the fundamental limitations of our
lexicon-based affect detector and frame all theoretical results within
their stated assumptions.
\end{abstract}

\textbf{Keywords:} Retrieval-Augmented Generation, Affective Computing,
Emotion-Aware Dialogue, Reciprocal Rank Fusion, Context Augmentation,
Conversational AI

% ============================================================
\section{Introduction}\label{sec:intro}
% ============================================================

Retrieval-Augmented Generation (RAG)~\cite{lewis2020rag} has become the
dominant paradigm for grounding large language model (LLM) outputs in
external knowledge.  However, applying RAG to emotionally rich,
long-horizon conversational settings---such as role-playing dialogue,
therapeutic chatbots, and companion AI---exposes three structural
limitations:

\begin{enumerate}[label=(\roman*)]
  \item \textbf{Emotion blindness.}  Standard RAG retrieves documents based
    on lexical or semantic similarity alone, ignoring the affective state of
    the conversation.  This leads to emotionally incongruent responses---e.g.,
    cheerful replies to a user expressing sadness.  While emotion recognition
    in conversation (ERC) has been studied extensively using neural
    classifiers~\cite{poria2019meld,li2022emocaps,shen2021dialogxl}, these
    methods have not been integrated into the RAG context-injection pipeline.
  \item \textbf{Flat context injection.}  Most systems concatenate retrieved
    passages into a single context block without structural hierarchy, making
    it difficult for the LLM to distinguish identity constraints from
    episodic memories from emotional cues.  Recent work on structured
    prompting~\cite{wei2022chain,yao2023tree} addresses reasoning structure
    but not context-injection structure.
  \item \textbf{Response monotony.}  Without explicit diversity regulation,
    LLMs tend to converge to repetitive response patterns over extended
    conversations~\cite{holtzman2020curious,su2022contrastive}, degrading
    user experience.
\end{enumerate}

We address these limitations with \textbf{AHCA}, a layered architecture
that decomposes context augmentation into six formally defined layers.
Rather than claiming fundamental algorithmic breakthroughs, we contribute
a \emph{principled integration} of existing techniques---BM25, reciprocal
rank fusion, lexicon-based affect detection, and diversity
monitoring---within a unified, mathematically analyzed framework.  The
novelty lies in the \emph{joint formalization} and the \emph{interaction
effects} between layers, not in any single component.

Our contributions are:

\begin{enumerate}[label=\textbf{C\arabic*}.]
  \item A \emph{six-layer hierarchical context augmentation} framework with
    formal token-budget allocation and clean separation of concerns
    (\Cref{sec:architecture}).
  \item An \emph{exponential-decay emotion tracking} model with softmax
    normalization and a non-stationary dynamic regret bound that
    characterizes the bias--variance tradeoff of the half-life parameter
    (\Cref{sec:emotion}).
  \item A \emph{hybrid BM25--cosine W-RRF memory retrieval} scheme with
    formal analysis of fusion properties (\Cref{sec:memory}).
  \item A \emph{dual-stage memory verification} protocol with probabilistic
    fact-preservation bounds under a correlated-error model
    (\Cref{sec:verification}).  We note that this protocol operates
    \emph{offline} during periodic summarization; the factual consistency
    improvements observed in the main experiment are primarily attributable
    to Layer~2's precise memory retrieval and fact-conditioned generation,
    not to the verification protocol itself.
  \item A \emph{diversity regulation} mechanism with a conditional expected
    entropy increase under an empirically calibrated compliance assumption
    (\Cref{sec:diversity}).
  \item \emph{Quantitative evaluation} against four baselines on a
    2{,}000-session role-playing dialogue corpus (\Cref{sec:experiments}).
  \item An honest assessment of limitations, including the prompt-engineering
    gap between emotion detection and emotion-coherent generation, and the
    assumptions underlying each formal result (\Cref{sec:limitations}).
\end{enumerate}

\paragraph{Scope and non-claims.}
We do \emph{not} claim that lexicon-based emotion detection is
state-of-the-art; it is a lightweight proxy suitable for our target domain
(see \Cref{sec:emotion-scope}).  We do \emph{not} claim that any single
component of AHCA is novel in isolation; the contribution is the
integrated framework and its formal analysis.  We do \emph{not}
claim that our formal results constitute deep mathematical contributions;
they are careful formalizations of properties that practitioners might
take for granted, made explicit to guide parameter selection and identify
failure modes.  We do \emph{not} claim a direct causal mechanism from
emotion-state injection to emotion-coherent generation; the intervening
step is mediated by the LLM's response to structured prompts, which we
treat as an empirically validated but theoretically opaque ``prompt
compliance'' channel (see \Cref{sec:prompt-gap}).  We do \emph{not}
claim that the dual-stage verification protocol is responsible for the
factual consistency improvements in the main experiment; the protocol
operates offline during summarization, and the observed FC gains are
primarily attributable to Layer~2's memory retrieval (see
\Cref{sec:fc-attribution}).

% ============================================================
\section{Related Work}\label{sec:related}
% ============================================================

\subsection{Retrieval-Augmented Generation}

RAG~\cite{lewis2020rag} augments LLM generation with retrieved passages.
Dense retrieval~\cite{karpukhin2020dpr} replaces sparse lexical matching
with learned embeddings.  RETRO~\cite{borgeaud2022retro} integrates
retrieval into the transformer architecture itself.
Self-RAG~\cite{asai2024selfrag} adds self-reflective retrieval decisions.
FLARE~\cite{jiang2023flare} performs active retrieval during generation.
None of these incorporate affective signals into the retrieval or
context-injection pipeline.  AHCA is complementary: it structures the
\emph{context injection} stage, which can sit atop any retrieval backend.

\subsection{Emotion Recognition in Conversation}

ERC has progressed from lexicon-based methods~\cite{mohammad2013nrc} to
recurrent models~\cite{hazarika2018conversational}, graph-based
approaches~\cite{ghosal2019dialoguegcn}, and transformer-based
classifiers~\cite{shen2021dialogxl,li2022emocaps}.  State-of-the-art ERC
achieves $>65\%$ weighted F1 on MELD~\cite{poria2019meld} and
$>60\%$ on IEMOCAP~\cite{busso2008iemocap}.

Our lexicon-based approach is deliberately simpler.  We adopt it for three
reasons: (1)~in role-playing dialogue, emotional expression is typically
explicit and exaggerated, making lexicon matching effective in practice
(see \Cref{sec:experiments}); (2)~it requires zero GPU inference, enabling
sub-millisecond latency; (3)~the architecture is designed so that Layer~3
can be replaced with any affect detector that produces scores in
$\R^D_{\geq 0}$, including neural classifiers.  We provide empirical
evidence for this claim in \Cref{sec:ablation}.

\subsection{Empathetic and Emotionally-Aware Dialogue}

Empathetic dialogue~\cite{rashkin2019empathetic} trains models to generate
empathetic responses.  MIME~\cite{majumder2020mime} uses emotion mimicry
and grouping.  CEM~\cite{sabour2022cem} combines commonsense with
empathy.  These approaches modify the \emph{generation model} itself;
AHCA instead modifies the \emph{context} provided to an unmodified LLM,
making it model-agnostic.

\subsection{Memory-Augmented Dialogue}

MemoryBank~\cite{zhong2024memorybank} and
SCM~\cite{xu2022longterm} explore long-term memory for dialogue.
RMN~\cite{liu2023rmn} uses retrieval-augmented memory networks.
These systems use flat memory retrieval without emotion-aware weighting or
hierarchical context structuring.  AHCA extends this line of work by
integrating memory retrieval (Layer~2) with emotion tracking (Layer~3)
and coherence preservation (Layer~4) in a unified pipeline.

\subsection{Reciprocal Rank Fusion}

RRF~\cite{cormack2009rrf} is a well-established technique for combining
multiple ranked lists.  Weighted variants have been explored in
information retrieval~\cite{wu2012weighted}.  We apply RRF with
asymmetric weighting between lexical and semantic signals and provide a
Pareto-dominance theorem that, while straightforward, has not been
explicitly stated in the RRF literature to our knowledge.

\subsection{Response Diversity}

Nucleus sampling~\cite{holtzman2020curious}, contrastive
search~\cite{su2022contrastive}, and typical
decoding~\cite{meister2023typical} address diversity at the
\emph{decoding} level.  AHCA addresses diversity at the \emph{context}
level by detecting repetitive patterns and injecting diversity hints,
which is complementary to decoding-level approaches.

\subsection{Positioning of AHCA}

\Cref{tab:positioning} summarizes the positioning.  AHCA's contribution
is the \emph{integration} of these components into a unified, formally
analyzed framework, not any single component in isolation.

\begin{table}[htbp]
\centering
\caption{Positioning of AHCA relative to prior work.  ``$\bullet$'' =
first-class component; ``$\circ$'' = partial or implicit support;
``---'' = not addressed.}
\label{tab:positioning}
\small
\begin{tabular}{@{}lcccccc@{}}
\toprule
\textbf{Feature} & \textbf{RAG} & \textbf{MemBank} & \textbf{EmpDial}
  & \textbf{SCM} & \textbf{Self-RAG} & \textbf{AHCA} \\
\midrule
Hierarchical context layers
  & --- & --- & --- & --- & --- & $\bullet$ \\
Emotion-aware context injection
  & --- & --- & $\circ$ & --- & --- & $\bullet$ \\
Long-term memory retrieval
  & --- & $\bullet$ & --- & $\bullet$ & --- & $\bullet$ \\
Hybrid lexical--semantic fusion
  & --- & --- & --- & --- & $\circ$ & $\bullet$ \\
Fact verification
  & --- & --- & --- & --- & $\circ$ & $\bullet$ \\
Diversity regulation (context-level)
  & --- & --- & --- & --- & --- & $\bullet$ \\
Formal mathematical analysis
  & --- & --- & --- & --- & --- & $\bullet$ \\
\bottomrule
\end{tabular}
\end{table}

% ============================================================
\section{Problem Formulation}\label{sec:problem}
% ============================================================

Let $\cC = (m_1, m_2, \ldots, m_T)$ denote a conversation of $T$ messages,
where each message $m_t = (r_t, x_t, \tau_t, \sigma_t)$ consists of a role
$r_t \in \{\texttt{user}, \texttt{assistant}, \texttt{system}\}$, textual
content $x_t \in \Sigma^*$ over alphabet $\Sigma$, timestamp
$\tau_t \in \R_{\geq 0}$, and message type
$\sigma_t \in \{\texttt{say}, \texttt{do}, \texttt{mixed}\}$.

Let $\cM = \{s_1, s_2, \ldots, s_N\}$ denote a memory store of $N$ summary
records, where each $s_j = (\text{summary}_j, F_j, K_j, [a_j, b_j])$
contains a natural-language summary, a set of core facts $F_j$, a keyword
set $K_j$, and a turn range $[a_j, b_j]$.

\begin{definition}[Context Augmentation Function]\label{def:caf}
A \emph{context augmentation function} is a mapping
\[
  \Phi: \cC \times \cM \times \Sigma^* \to \cC'
\]
that takes the current conversation $\cC$, memory store $\cM$, and the new
user query $q \in \Sigma^*$, and produces an augmented message sequence
$\cC'$ to be submitted to the LLM.
\end{definition}

The design goals for $\Phi$ are:
\begin{enumerate}[label=(G\arabic*)]
  \item \textbf{Identity consistency:} The character identity encoded in
    system messages is preserved across all turns.
  \item \textbf{Memory relevance:} Retrieved memories are relevant to the
    current query and weighted by both lexical and semantic similarity.
  \item \textbf{Emotional coherence:} The affective state of the
    conversation is tracked and reflected in the context.
  \item \textbf{Topical coherence:} Topic continuity and anaphora
    resolution are maintained across turns.
  \item \textbf{Response diversity:} The LLM is guided away from repetitive
    patterns over extended conversations.
\end{enumerate}

\begin{definition}[Quality Metrics]\label{def:quality}
We define four measurable quality dimensions for a context augmentation
function $\Phi$:
\begin{enumerate}[label=(\alph*)]
  \item \textbf{Emotional coherence} $\cE(\Phi)$: the fraction of
    responses judged emotionally appropriate by human annotators.
  \item \textbf{Factual consistency} $\cF(\Phi)$: the fraction of
    responses that do not contradict established facts in $\cM$.
  \item \textbf{Response diversity} $\cD(\Phi)$: the entropy of the
    empirical distribution of response opening patterns.
  \item \textbf{User preference} $\cP(\Phi)$: the win rate in pairwise
    comparisons against a baseline.
\end{enumerate}
\end{definition}

% ============================================================
\section{The AHCA Architecture}\label{sec:architecture}
% ============================================================

AHCA decomposes the context augmentation function $\Phi$ into six sequential
layers, each with a dedicated token budget:
\[
  \Phi = \Lambda_6 \circ \Lambda_5 \circ \Lambda_4 \circ \Lambda_3
         \circ \Lambda_2 \circ \Lambda_1
\]
where $\Lambda_\ell: \cC'_{\ell-1} \to \cC'_\ell$ denotes the $\ell$-th
layer transformation, with $\cC'_0 = \emptyset$.

\begin{remark}[On the sequential composition]
The sequential composition is a design choice, not a necessity.  Layers
1--4 could in principle operate in parallel since they read from $\cC$ and
$\cM$ independently.  The sequential formulation simplifies token-budget
accounting: each layer knows the budget consumed by preceding layers.
\end{remark}

\subsection{Layer 1: Identity Anchoring ($\Lambda_1$)}\label{sec:layer1}

The first layer extracts the system prompt $m_{\text{sys}}$ from $\cC$ and
places it as the first element of $\cC'$:
\[
  \Lambda_1(\cC) = \bigl[m_{\text{sys}}\bigr], \quad
  m_{\text{sys}} = \min_{t}\{m_t \in \cC : r_t = \texttt{system}\}.
\]
This ensures that the LLM's identity constraints are always the
highest-priority context, occupying a token budget of
$B_1 = |x_{\text{sys}}| / \alpha$, where $\alpha$ is the bytes-per-token
ratio (empirically $\alpha \approx 2$ for mixed Chinese--English text).

\subsection{Layer 2: Memory-Augmented Retrieval ($\Lambda_2$)}\label{sec:layer2}

Given query $q$ and memory store $\cM$, Layer~2 retrieves the top-$k$ most
relevant memories using a hybrid BM25--cosine W-RRF scheme (detailed in
\Cref{sec:memory}) and injects them as system messages:
\[
  \Lambda_2(\cC'_1, q, \cM) = \cC'_1 \oplus
  \bigl[m_{\text{mem}}^{(1)}, \ldots, m_{\text{mem}}^{(k)}\bigr]
\]
where $\oplus$ denotes sequence concatenation and each
$m_{\text{mem}}^{(i)}$ encodes the summary and core facts of the $i$-th
retrieved memory.

\subsection{Layer 3: Affective State Tracking ($\Lambda_3$)}\label{sec:layer3}

Layer~3 computes a real-time emotion distribution over a Plutchik-inspired
$D$-dimensional affective space and injects it as a system message.  The
full mathematical formulation is given in \Cref{sec:emotion}.
\[
  \Lambda_3(\cC'_2, \cC) = \cC'_2 \oplus [m_{\text{emo}}]
\]

\begin{remark}[The Prompt-Compliance Gap]\label{sec:prompt-gap}
There is a fundamental gap between \emph{detecting} the user's emotional
state and \emph{generating} an emotionally coherent response.  Layer~3
produces a structured emotion summary $m_{\text{emo}}$ that is injected
into the LLM's context as a system message.  The mechanism by which this
injection leads to emotionally appropriate responses is mediated entirely
by the LLM's ability to follow structured prompts---a ``prompt compliance''
channel that we do not model theoretically.

Concretely, the causal chain is:
\[
  \text{lexicon scores} \xrightarrow{\text{formal}}
  \text{emotion distribution } \bp \xrightarrow{\text{formal}}
  \text{system message } m_{\text{emo}} \xrightarrow{\text{opaque}}
  \text{LLM response}.
\]
The first two arrows are mathematically specified; the third is an
empirical black box.  The observed $+9.2\%$ EC improvement from Layer~3
(\Cref{sec:ablation}) demonstrates that the injection is effective in
practice, but we cannot distinguish between two hypotheses:
\begin{enumerate}[label=(\alph*)]
  \item The LLM uses the \emph{precise} emotion distribution to calibrate
    its response (the intended mechanism).
  \item The mere \emph{presence} of emotion-related content in the system
    prompt causes the LLM to attend more to emotional dimensions of the
    conversation (an attention-priming effect).
\end{enumerate}
Disentangling these hypotheses would require controlled experiments with
randomized vs.\ accurate emotion labels, which we leave to future work.
The theoretical results in \Cref{sec:emotion} guarantee the quality of
the \emph{input} to this channel (the emotion distribution $\bp$), not
the quality of the \emph{output} (the LLM's response).
\end{remark}

\subsection{Layer 4: Coherence Preservation ($\Lambda_4$)}\label{sec:layer4}

Layer~4 performs topic-continuity analysis and anaphora disambiguation:
\[
  \Lambda_4(\cC'_3, \cC) = \cC'_3 \oplus [m_{\text{coh}}]
\]
where $m_{\text{coh}}$ encodes topic-switch detection (via bigram overlap),
unanswered-question detection, and emotional-misalignment alerts.  The
topic continuity score is defined as:
\begin{equation}\label{eq:topic-continuity}
  \kappa(x_t, x_{t-1}) = \frac{|B(x_t) \cap B(x_{t-1})|}
    {\min\bigl(|B(x_t)|, |B(x_{t-1})|\bigr) + \epsilon}
\end{equation}
where $B(x)$ denotes the set of character bigrams in message $x$ and
$\epsilon > 0$ is a smoothing constant to avoid division by zero.  A topic
switch is signaled when $\kappa < \kappa_{\min}$, and topic continuation
when $\kappa > \kappa_{\max}$.

\begin{remark}
Bigram overlap is a crude proxy for topic continuity.  More sophisticated
approaches (e.g., sentence embeddings, topic models) would improve
accuracy but increase latency.  In our ablation study
(\Cref{sec:ablation}), removing Layer~4 reduces emotional coherence by
$4.2\%$, suggesting that even this simple approach provides value.
\end{remark}

\subsection{Layer 5: Dialogue History Window ($\Lambda_5$)}\label{sec:layer5}

Layer~5 selects the most recent non-system messages within the remaining
token budget:
\[
  \Lambda_5(\cC'_4, \cC) = \cC'_4 \oplus
  [m_{T-W+1}, \ldots, m_T]
\]
where the window size $W$ is determined by:
\begin{equation}\label{eq:window}
  W = \max\Bigl\{w \leq W_{\max} :
    \sum_{i=T-w+1}^{T} \frac{|x_i|}{\alpha} \leq
    B_{\text{total}} - \sum_{\ell=1}^{4} B_\ell - B_{\text{out}} - B_{\text{style}}
  \Bigr\}
\end{equation}
with $B_{\text{total}} = 120{,}000$ tokens, $B_{\text{out}} = 4{,}096$
tokens reserved for generation, $B_{\text{style}} = 200$ tokens for style
hints, and $W_{\max} = 20$.

\subsection{Layer 6: Style Constraint \& Diversity Regulation ($\Lambda_6$)}\label{sec:layer6}

The final layer injects say/do style prompts and diversity regulation hints
(detailed in \Cref{sec:diversity}):
\[
  \Lambda_6(\cC'_5) = \cC'_5 \oplus [m_{\text{style}}, m_{\text{div}}]
\]

% ============================================================
\section{Exponential-Decay Emotion Tracking}\label{sec:emotion}
% ============================================================

\subsection{Scope and Limitations of the Lexicon Approach}\label{sec:emotion-scope}

Before presenting the formalism, we state clearly what this model \emph{can}
and \emph{cannot} do, and why we adopt it despite its known limitations.

The model uses keyword matching against a predefined lexicon.  This is a
\emph{surface-level} affect detector.  It \textbf{cannot} handle:
\begin{itemize}
  \item \textbf{Irony and sarcasm:} ``Oh great, another wonderful day''
    registers as positive when the true affect is negative.
  \item \textbf{Implicit emotion:} ``I've been staring at the ceiling for
    three hours'' conveys sadness without any sadness keywords.
  \item \textbf{Semantic negation:} ``I'm not happy'' contains ``happy'' but
    expresses the opposite.
  \item \textbf{Cultural nuance:} Emotion expression varies across cultures
    and subcultures.
  \item \textbf{Context-dependent polarity:} ``You're killing it'' is
    positive in casual speech but the lexicon may flag ``killing'' as
    negative.
\end{itemize}

These are well-known limitations of lexicon-based methods, documented
extensively in the sentiment analysis literature since at least
2010~\cite{liu2012sentiment,mohammad2013nrc}.  Modern ERC systems using
contextual embeddings~\cite{shen2021dialogxl,li2022emocaps} substantially
outperform lexicon methods on standard benchmarks.

We adopt the lexicon approach for the following domain-specific reasons:
\begin{enumerate}
  \item \textbf{Domain characteristics:} In role-playing dialogue, emotional
    expression is typically explicit and exaggerated.  Users write
    ``*cries*'', ``哈哈哈'', ``好难过'' rather than expressing emotions
    implicitly.  We validate this empirically: on a sample of 500
    role-playing messages, lexicon matching achieves $78.3\%$ agreement with
    human-annotated dominant emotion (\Cref{sec:experiments}).
  \item \textbf{Latency constraint:} The approach requires zero GPU
    inference, enabling sub-millisecond latency ($< 0.5$ms in production).
    Neural classifiers add 10--50ms per message.
  \item \textbf{Modularity:} The architecture is designed so that Layer~3
    can be replaced with \emph{any} affect detector that produces scores in
    $\R^D_{\geq 0}$.  All theoretical results in this section hold for
    arbitrary non-negative score vectors, not just lexicon-derived ones.
\end{enumerate}

\subsection{Emotion Space and Lexicon}

We model the affective state as a point in a $D$-dimensional emotion space
$\cE = \R^D_{\geq 0}$, with $D = 8$ dimensions inspired by Plutchik's
wheel of emotions~\cite{plutchik1980emotion}:
\[
  \be = (e_{\text{joy}},\; e_{\text{sad}},\; e_{\text{anger}},\;
  e_{\text{fear}},\; e_{\text{surprise}},\; e_{\text{intimacy}},\;
  e_{\text{trust}},\; e_{\text{anticipation}})^\top.
\]

\begin{remark}
We include ``intimacy'' as a non-standard dimension because it is
particularly relevant to role-playing dialogue.  This is an engineering
choice, not a claim about emotion theory.
\end{remark}

\begin{definition}[Emotion Lexicon]\label{def:lexicon}
An \emph{emotion lexicon} is a collection of keyword sets
$L = \{L_1, L_2, \ldots, L_D\}$ where $L_d \subset \Sigma^*$ is the set of
keywords associated with emotion dimension $d$.
\end{definition}

\begin{assumption}[Lexicon Disjointness]\label{asm:disjoint}
For the theoretical analysis, we assume $L_i \cap L_j = \emptyset$ for
$i \neq j$.  In the production system, the lexicons are \emph{not}
strictly disjoint (e.g., ``嗯'' could appear in multiple categories).
\Cref{prop:non-disjoint} shows that relaxing this assumption introduces
bounded cross-talk between dimensions but does not affect the
well-definedness results.
\end{assumption}

For a message $m_t$ with content $x_t$, the \emph{hit count} for dimension
$d$ is:
\begin{equation}\label{eq:hit}
  h_d(x_t) = \bigl|\{w \in L_d : w \sqsubseteq x_t\}\bigr|
\end{equation}
where $w \sqsubseteq x_t$ denotes that keyword $w$ appears as a substring
of $x_t$.

\subsection{Exponential Decay Weighting}

\begin{definition}[Temporal Weight]\label{def:temporal-weight}
For a message at position $i$ in a sequence of $T$ messages (1-indexed),
the \emph{temporal weight} with half-life $\tau > 0$ is:
\begin{equation}\label{eq:decay}
  w(i; T, \tau) = 2^{-(T-1-i)/\tau}
  = \exp\!\Bigl(-\frac{(T-1-i)\ln 2}{\tau}\Bigr).
\end{equation}
\end{definition}

\begin{definition}[Role Factor]\label{def:role-factor}
The \emph{role factor} assigns asymmetric importance to user vs.\ assistant
messages:
\begin{equation}\label{eq:role}
  \rho(r_t) = \begin{cases}
    \rho_u & \text{if } r_t = \texttt{user}, \\
    \rho_a & \text{if } r_t = \texttt{assistant},
  \end{cases}
\end{equation}
with $\rho_u > \rho_a > 0$.  In production, $\rho_u = 1.2$, $\rho_a = 0.8$.
The rationale is that the user's emotional state is the primary signal the
system should respond to.
\end{definition}

\subsection{Logarithmic Saturation}

\begin{definition}[Saturated Contribution]\label{def:saturation}
The contribution of message $m_i$ to emotion dimension $d$ is:
\begin{equation}\label{eq:contribution}
  c_d(m_i) = w(i; T, \tau) \cdot \rho(r_i) \cdot \ln(1 + h_d(x_i)).
\end{equation}
\end{definition}

\begin{proposition}[Saturation Properties]\label{prop:saturation}
The saturation function $f(h) = \ln(1 + h)$ satisfies:
\begin{enumerate}[label=(\alph*)]
  \item $f(0) = 0$ (no hits $\Rightarrow$ no contribution).
  \item $f'(h) = 1/(1+h) > 0$ for all $h \geq 0$ (monotonically increasing).
  \item $f''(h) = -1/(1+h)^2 < 0$ for all $h \geq 0$ (strictly concave).
  \item $f(h) \leq h$ for all $h \geq 0$ (sub-linear growth).
  \item For $h_1, h_2 \geq 0$: $f(h_1 + h_2) \leq f(h_1) + f(h_2)$
    (sub-additivity).
\end{enumerate}
\end{proposition}

\begin{proof}
Parts (a)--(d) follow from elementary calculus.  For (e):
$\ln(1 + h_1 + h_2) \leq \ln((1+h_1)(1+h_2)) = \ln(1+h_1) + \ln(1+h_2)$,
where the inequality uses $1 + h_1 + h_2 \leq 1 + h_1 + h_2 + h_1 h_2
= (1+h_1)(1+h_2)$.
\end{proof}

The raw emotion score for dimension $d$ is:
\begin{equation}\label{eq:raw-score}
  e_d = \sum_{i=1}^{T} c_d(m_i) = \sum_{i=1}^{T}
  w(i; T, \tau) \cdot \rho(r_i) \cdot \ln(1 + h_d(x_i)).
\end{equation}

\subsection{Softmax Normalization}

We convert raw scores to a probability distribution via softmax.  In the
production code, we first filter to dimensions with $e_d > \theta_{\min}$
(the ``significance threshold'', $\theta_{\min} = 0.3$), then apply softmax
only over the significant dimensions.  For the theoretical analysis, we
consider the full $D$-dimensional softmax:
\begin{equation}\label{eq:softmax}
  p_d = \frac{\exp(e_d)}{\sum_{j=1}^{D} \exp(e_j)}, \quad d = 1, \ldots, D.
\end{equation}

For numerical stability, the implementation uses the shifted variant:
\begin{equation}\label{eq:softmax-stable}
  p_d = \frac{\exp(e_d - e_{\max})}{\sum_{j=1}^{D} \exp(e_j - e_{\max})},
  \quad e_{\max} = \max_{j} e_j.
\end{equation}

\subsection{Well-Definedness and Boundedness}

\begin{theorem}[Well-Definedness of the Emotion Distribution]\label{thm:softmax-welldef}
Let $\{e_d\}_{d=1}^{D}$ be the raw emotion scores computed by
\eqref{eq:raw-score} for a conversation of $T \geq 1$ messages with
temporal weight half-life $\tau > 0$, role factors $\rho_u, \rho_a > 0$,
and emotion lexicon $L = \{L_1, \ldots, L_D\}$.  Then:
\begin{enumerate}[label=(\alph*)]
  \item $\bp = (p_1, \ldots, p_D)^\top$ defined by
    \eqref{eq:softmax} is a valid probability distribution:
    $p_d > 0$ for all $d$, and $\sum_{d=1}^{D} p_d = 1$.
  \item Each raw score is bounded:
    $0 \leq e_d \leq S_\tau \cdot \rho_u \cdot \ln(1 + |L_d|)$,
    where $S_\tau = \sum_{i=1}^{T} w(i; T, \tau)
    = \frac{1 - 2^{-T/\tau}}{1 - 2^{-1/\tau}}$.
  \item The Kish effective sample size~\cite{kish1965survey} of the
    weighted sum is:
    \[
      T_{\textup{eff}} = \frac{S_\tau^2}{\sum_{i=1}^{T} w(i;T,\tau)^2}
    \]
    and for $T \to \infty$:
    \begin{equation}\label{eq:teff-limit}
      T_{\textup{eff}} \to
      \frac{1 - 2^{-2/\tau}}{(1 - 2^{-1/\tau})^2}.
    \end{equation}
    For $\tau = 3$: $T_{\textup{eff}} \to 8.70$.
  \item The entropy of $\bp$ satisfies
    $0 < \Ent(\bp) \leq \ln D$, with equality iff all $e_d$ are equal.
\end{enumerate}
\end{theorem}

\begin{proof}
\textbf{(a)} Since $e_d \in \R$ for all $d$, $\exp(e_d) > 0$, and the
denominator $\sum_j \exp(e_j) > 0$.  Hence $p_d > 0$.  The identity
$\sum_d p_d = 1$ follows directly from the definition.

\textbf{(b)} Lower bound: each term $c_d(m_i) \geq 0$ since
$w(\cdot) > 0$, $\rho(\cdot) > 0$, and $\ln(1 + h) \geq 0$ for
$h \geq 0$.  Hence $e_d \geq 0$.

Upper bound: $w(i; T, \tau) \leq 1$, $\rho(r_i) \leq \rho_u$, and
$h_d(x_i) \leq |L_d|$ (under \Cref{asm:disjoint}), so
$c_d(m_i) \leq w(i;T,\tau) \cdot \rho_u \cdot \ln(1 + |L_d|)$.  Summing:
\[
  e_d \leq \rho_u \cdot \ln(1 + |L_d|) \cdot \sum_{i=1}^{T} w(i; T, \tau)
  = \rho_u \cdot \ln(1 + |L_d|) \cdot S_\tau.
\]
The sum of temporal weights is a geometric series with ratio
$r = 2^{-1/\tau}$:
\[
  S_\tau = \sum_{k=0}^{T-1} 2^{-k/\tau}
  = \frac{1 - r^T}{1 - r}
  = \frac{1 - 2^{-T/\tau}}{1 - 2^{-1/\tau}}.
\]

\textbf{(c)} The denominator is $\sum_{k=0}^{T-1} 2^{-2k/\tau}
= \frac{1 - 2^{-2T/\tau}}{1 - 2^{-2/\tau}}$.  As $T \to \infty$:
\[
  T_{\text{eff}} \to
  \frac{(1 - 2^{-1/\tau})^{-2}}{(1 - 2^{-2/\tau})^{-1}}
  = \frac{1 - 2^{-2/\tau}}{(1 - 2^{-1/\tau})^2}.
\]
For $\tau = 3$: $2^{-1/3} \approx 0.7937$, $2^{-2/3} \approx 0.6300$,
giving $T_{\text{eff}} \approx 0.3700 / 0.04256 \approx 8.70$.

\textbf{(d)} Since $p_d > 0$ for all $d$, the entropy
$\Ent(\bp) = -\sum_d p_d \ln p_d > 0$.  The maximum $\ln D$ is achieved
when $\bp$ is uniform, which occurs iff all $e_d$ are equal (since softmax
preserves the ordering and maps equal inputs to the uniform distribution).
\end{proof}

\begin{proposition}[Non-Disjoint Lexicon Extension]\label{prop:non-disjoint}
If the lexicons are not disjoint, i.e., $\exists\, w \in L_i \cap L_j$
for some $i \neq j$, then:
\begin{enumerate}[label=(\alph*)]
  \item \Cref{thm:softmax-welldef}(a) and (c) still hold unchanged.
  \item The upper bound in (b) becomes
    $e_d \leq S_\tau \cdot \rho_u \cdot \ln(1 + |L_d| + C_d)$
    where $C_d = |\{w \in L_d : \exists\, j \neq d,\, w \in L_j\}|$
    counts the cross-listed keywords.
  \item The cross-talk introduces a positive correlation between
    dimensions sharing keywords:
    $\text{Cov}(e_i, e_j) \geq 0$ when $L_i \cap L_j \neq \emptyset$.
\end{enumerate}
\end{proposition}

\begin{proof}
(a) follows because the softmax well-definedness depends only on
$e_d \in \R$, not on the lexicon structure.  (b) follows because a keyword
$w \in L_i \cap L_j$ can contribute to both $h_i$ and $h_j$, but the
hit count for dimension $d$ is still bounded by the number of keywords
that can match, which is $|L_d|$ (each keyword is counted at most once
per dimension).  (c) follows because a message containing $w \in L_i \cap L_j$
simultaneously increases both $e_i$ and $e_j$.
\end{proof}

\begin{corollary}[Exponential Negligibility of Old Messages]\label{cor:old-negligible}
For any $\tau > 0$ and any $\Delta > 0$, the total weight of messages
older than $\Delta$ positions from the most recent message satisfies:
\begin{equation}\label{eq:old-weight}
  \frac{\sum_{k=\Delta}^{\infty} 2^{-k/\tau}}{S_\infty}
  = 2^{-\Delta/\tau}.
\end{equation}
For $\tau = 3$ and $\Delta = 3\tau = 9$: the tail fraction is
$2^{-3} = 12.5\%$.  For $\Delta = 6\tau = 18$: $2^{-6} \approx 1.6\%$.
\end{corollary}

\begin{proof}
$\sum_{k=\Delta}^{\infty} 2^{-k/\tau} = \frac{2^{-\Delta/\tau}}{1 - 2^{-1/\tau}}
= 2^{-\Delta/\tau} \cdot S_\infty$.  Dividing by $S_\infty$ gives the result.
\end{proof}

\begin{remark}
With $\tau = 3$, messages older than 9 positions contribute only $12.5\%$
of the total weight.  This is a moderate decay by design: in role-playing
conversations, emotional context from 5--10 messages ago is still relevant.
For applications requiring sharper decay, $\tau$ should be reduced.
\end{remark}

\subsection{Emotional Valence Computation}

\begin{definition}[Emotional Valence]\label{def:valence}
The \emph{emotional valence} of a message subsequence
$\cC_{[a,b]} = (m_a, \ldots, m_b)$ is:
\begin{equation}\label{eq:valence}
  v(\cC_{[a,b]}) = \frac{n^+(\cC_{[a,b]}) - n^-(\cC_{[a,b]})}
    {n^+(\cC_{[a,b]}) + n^-(\cC_{[a,b]}) + \epsilon}
\end{equation}
where $n^+$ counts keyword hits in positive dimensions
$\cP = \{\text{joy}, \text{intimacy}, \text{trust},
\text{anticipation}\}$, $n^-$ counts hits in negative dimensions
$\cN = \{\text{sadness}, \text{anger}, \text{fear}\}$, and
$\epsilon > 0$ is a smoothing constant (we use $\epsilon = 1$).
\end{definition}

\begin{proposition}[Valence Boundedness]\label{prop:valence-bound}
For any subsequence, $v(\cC_{[a,b]}) \in (-1, 1)$.
\end{proposition}

\begin{proof}
With $\epsilon > 0$: $|n^+ - n^-| < n^+ + n^- + \epsilon$, so $|v| < 1$.
\end{proof}

\subsection{Non-Stationary Tracking via Online Convex Optimization}\label{sec:regret}

The stationarity assumption underlying simple averaging is unrealistic for
real conversations.  We now provide a regret bound for the exponential-decay
estimator viewed as an online learning algorithm.

\begin{definition}[Path Length]\label{def:path-length}
For a sequence of true emotion states $\be^*_1, \ldots, \be^*_T \in \cE$,
the \emph{path length} is:
\begin{equation}\label{eq:path-length}
  P_T = \sum_{t=2}^{T} \|\be^*_t - \be^*_{t-1}\|_2.
\end{equation}
\end{definition}

\begin{assumption}[Noisy Observation Model]\label{asm:noisy-obs}
At each time $t$, the lexicon-based detector produces a noisy observation
$\hat{\be}_t = \be^*_t + \boldsymbol{\xi}_t$ where
$\boldsymbol{\xi}_t \in \R^D$ is a zero-mean noise vector with
$\|\boldsymbol{\xi}_t\|_2 \leq \sigma$ almost surely.  The noise captures
both lexicon inaccuracy and the stochastic nature of keyword usage.
\end{assumption}

\begin{theorem}[Dynamic Regret of Exponential-Decay Estimator]\label{thm:regret}
Under \Cref{asm:noisy-obs}, the exponential-decay weighted estimate
$\tilde{\be}_T = \frac{1}{S_\tau} \sum_{i=1}^{T} w(i;T,\tau) \hat{\be}_i$
satisfies the dynamic regret bound:
\begin{equation}\label{eq:regret}
  \|\tilde{\be}_T - \be^*_T\|_2
  \leq \underbrace{\frac{\sigma}{\sqrt{T_{\textup{eff}}}}}_{\text{noise term}}
  + \underbrace{\frac{P_T}{S_\tau} \cdot
    \frac{1 - 2^{-1/\tau}}{(\ln 2)/\tau}}_{\text{tracking lag}}.
\end{equation}
\end{theorem}

\begin{proof}
Decompose the error:
\begin{align*}
  \tilde{\be}_T - \be^*_T
  &= \frac{1}{S_\tau}\sum_{i=1}^{T} w_i (\be^*_i + \boldsymbol{\xi}_i) - \be^*_T \\
  &= \underbrace{\frac{1}{S_\tau}\sum_{i=1}^{T} w_i \boldsymbol{\xi}_i}_{\text{noise}}
  + \underbrace{\frac{1}{S_\tau}\sum_{i=1}^{T} w_i (\be^*_i - \be^*_T)}_{\text{bias}}.
\end{align*}

\textbf{Noise term:} Since $\E[\boldsymbol{\xi}_i] = 0$ and
$\|\boldsymbol{\xi}_i\|_2 \leq \sigma$:
\[
  \E\!\left[\left\|\frac{1}{S_\tau}\sum_i w_i \boldsymbol{\xi}_i\right\|_2^2\right]
  \leq \frac{\sigma^2}{S_\tau^2} \sum_i w_i^2
  = \frac{\sigma^2}{T_{\text{eff}}}.
\]
By Jensen's inequality:
$\E[\|\text{noise}\|_2] \leq \sigma / \sqrt{T_{\text{eff}}}$.

\textbf{Bias term:} By telescoping:
$\be^*_i - \be^*_T = -\sum_{j=i}^{T-1}(\be^*_{j+1} - \be^*_j)$.
Therefore:
\begin{align*}
  \left\|\frac{1}{S_\tau}\sum_{i=1}^{T} w_i (\be^*_i - \be^*_T)\right\|_2
  &\leq \frac{1}{S_\tau}\sum_{i=1}^{T} w_i \sum_{j=i}^{T-1}
    \|\be^*_{j+1} - \be^*_j\|_2 \\
  &= \frac{1}{S_\tau}\sum_{j=1}^{T-1} \|\be^*_{j+1} - \be^*_j\|_2
    \sum_{i=1}^{j} w_i \\
  &\leq \frac{P_T}{S_\tau} \cdot \max_{1 \leq j \leq T-1}
    \frac{\sum_{i=1}^{j} w_i}{1}.
\end{align*}
Since $\sum_{i=1}^{j} w(i;T,\tau) = \sum_{k=T-j}^{T-1} 2^{-k/\tau}
\leq \frac{1}{1 - 2^{-1/\tau}} = \frac{\tau/\ln 2}{1 - e^{-\ln 2/\tau}}
\leq \frac{1}{(1-2^{-1/\tau})}$, the bias is bounded by
$\frac{P_T}{S_\tau} \cdot \frac{1}{1 - 2^{-1/\tau}}$.

Combining and noting $\frac{1}{S_\tau(1-2^{-1/\tau})} = \frac{1}{1-2^{-T/\tau}}
\leq \frac{1}{1-2^{-1/\tau}} \cdot \frac{1-2^{-1/\tau}}{1-2^{-T/\tau}}$,
for $T \geq \tau$ the bound simplifies to \eqref{eq:regret}.
\end{proof}

\begin{remark}[Interpretation]
The bound reveals a bias--variance tradeoff controlled by $\tau$:
\begin{itemize}
  \item Larger $\tau$ $\Rightarrow$ larger $T_{\text{eff}}$ $\Rightarrow$
    smaller noise term, but larger tracking lag (slower adaptation).
  \item Smaller $\tau$ $\Rightarrow$ smaller tracking lag, but larger noise
    term (fewer effective samples).
\end{itemize}
For slowly varying emotions ($P_T$ small), large $\tau$ is optimal.  For
rapidly changing emotions, small $\tau$ is preferred.  An adaptive scheme
that learns $\tau$ online is left to future work.
\end{remark}

\subsection{Compound Psychological State Inference}

\begin{definition}[Compound Psychological State]\label{def:compound}
A \emph{compound psychological state} is a predicate
$\psi_{A,B}: \R^D_{\geq 0} \to \{0, 1\}$ defined by:
\begin{equation}\label{eq:compound}
  \psi_{A,B}(\be) = \mathbf{1}[e_A > \theta_A \;\wedge\; e_B > \theta_B]
\end{equation}
for emotion dimensions $A, B$ and thresholds $\theta_A, \theta_B > 0$.
\end{definition}

The production system detects six compound states (see \Cref{app:compound}).
These are heuristic rules inspired by psychological literature on mixed
emotions~\cite{larsen2001can}; they do \emph{not} constitute a validated
psychometric instrument and should be understood as engineering heuristics
for the role-playing dialogue domain.

% ============================================================
\section{Hybrid BM25--Cosine W-RRF Memory Retrieval}\label{sec:memory}
% ============================================================

\subsection{BM25 Scoring}

Given a query $q$ with extracted keyword set $K_q$ and a memory document
$s_j$ with keyword set $K_j$, the BM25 score~\cite{robertson2009bm25} is:
\begin{equation}\label{eq:bm25}
  \text{BM25}(q, s_j) = \sum_{w \in K_q}
  \underbrace{\ln\!\Bigl(\frac{N - \text{df}(w) + 0.5}{\text{df}(w) + 0.5}
    + 1\Bigr)}_{\text{IDF}(w)}
  \cdot
  \underbrace{\frac{\text{tf}(w, s_j) \cdot (k_1 + 1)}
    {\text{tf}(w, s_j) + k_1 \cdot \bigl(1 - b + b \cdot
    \frac{|K_j|}{\text{avgdl}}\bigr)}}_{\text{TF-norm}(w, s_j)}
\end{equation}
where $N = |\cM|$, $\text{df}(w) = |\{s_j \in \cM : w \in K_j\}|$,
$\text{tf}(w, s_j)$ is the term frequency of $w$ in $K_j$,
$\text{avgdl} = \frac{1}{N}\sum_{j=1}^{N}|K_j|$, and $k_1 = 1.2$,
$b = 0.75$ are standard BM25 parameters.

\begin{lemma}[BM25 Non-negativity]\label{lem:bm25-nonneg}
For $N \geq 1$ and $0 < \text{df}(w) \leq N$,
$\text{IDF}(w) > 0$ and hence $\text{BM25}(q, s_j) \geq 0$.
\end{lemma}

\begin{proof}
$\frac{N - \text{df}(w) + 0.5}{\text{df}(w) + 0.5} + 1
= \frac{N + 1}{\text{df}(w) + 0.5}$.
Since $\text{df}(w) \leq N$: $\text{df}(w) + 0.5 \leq N + 0.5 < N + 1$,
so the fraction is $> 1$ and $\text{IDF}(w) > 0$.
\end{proof}

\subsection{Keyword Cosine Similarity}

As a lightweight proxy for semantic similarity (avoiding the need for
embedding models):
\begin{equation}\label{eq:cosine}
  \text{cos}(K_q, K_j) = \frac{|K_q \cap K_j|}
    {\sqrt{|K_q|} \cdot \sqrt{|K_j|}}.
\end{equation}

\begin{remark}
This is the Jaccard-like set cosine, not the standard vector cosine.  It
captures keyword overlap but not semantic similarity.  Replacing this with
dense embeddings (e.g., from a sentence transformer) would improve recall
at the cost of latency.  Our ablation (\Cref{sec:ablation}) shows that
the hybrid BM25+cosine approach outperforms BM25-only by $8.4\%$ in
memory retrieval precision.
\end{remark}

\subsection{Weighted Reciprocal Rank Fusion}

Let $\pi_{\text{BM25}}$ and $\pi_{\text{cos}}$ be the rankings induced by
BM25 and cosine similarity respectively.

\begin{definition}[Weighted RRF Score]\label{def:rrf}
The \emph{weighted RRF score} of document $s_j$ is:
\begin{equation}\label{eq:rrf}
  \text{RRF}(s_j) = \frac{\alpha_1}{k + r_1(j) + 1}
  + \frac{\alpha_2}{k + r_2(j) + 1}
\end{equation}
where $r_1 = r_{\text{BM25}}$, $r_2 = r_{\text{cos}}$ are 0-indexed ranks,
$\alpha_1, \alpha_2 > 0$ with $\alpha_1 + \alpha_2 = 1$, and $k > 0$ is
the RRF constant.  In production: $\alpha_1 = 0.6$, $\alpha_2 = 0.4$,
$k = 60$.
\end{definition}

\begin{theorem}[Pareto Dominance of W-RRF]\label{thm:rrf-dominance}
If document $s_j$ Pareto-dominates $s_{j'}$ in both rankers, i.e.,
$r_\ell(j) \leq r_\ell(j')$ for both $\ell \in \{1, 2\}$ with strict
inequality in at least one, then $\text{RRF}(s_j) > \text{RRF}(s_{j'})$.
\end{theorem}

\begin{proof}
Since $f(r) = \frac{\alpha}{k + r + 1}$ is strictly decreasing in $r$ for
$\alpha > 0$ and $k > 0$:
$r_\ell(j) \leq r_\ell(j')$ implies
$\frac{\alpha_\ell}{k + r_\ell(j) + 1} \geq
 \frac{\alpha_\ell}{k + r_\ell(j') + 1}$ for each $\ell$,
with strict inequality in at least one term.
Summing gives $\text{RRF}(s_j) > \text{RRF}(s_{j'})$.
\end{proof}

\begin{remark}
This is a standard property of weighted sums of strictly monotone
functions and follows immediately from the monotonicity of
$r \mapsto (\alpha)/(k+r+1)$.  We state it explicitly not as a novel
result, but as a \emph{sanity check} on the fusion mechanism: it confirms
that W-RRF does not introduce pathological rank inversions for
Pareto-dominant documents.  For documents with \emph{conflicting}
rankings, no ordering guarantee is possible without assumptions on ranker
quality; \Cref{prop:weight-sensitivity} characterizes the weight ratio
needed to resolve such conflicts.
\end{remark}

\begin{theorem}[RRF Score Bounds]\label{thm:rrf-bounds}
For any document $s_j$ in a collection of $N$ documents:
\begin{equation}\label{eq:rrf-bounds}
  \frac{\alpha_1 + \alpha_2}{k + N} \leq \text{RRF}(s_j)
  \leq \frac{\alpha_1 + \alpha_2}{k + 1}.
\end{equation}
The score ratio between the best and worst ranked documents is
$\frac{k + N}{k + 1}$.  With $k = 60$ and $N = 100$: ratio $\approx 2.62$.
\end{theorem}

\begin{proof}
Direct substitution of extreme ranks ($r = 0$ and $r = N-1$).
\end{proof}

\begin{remark}[Score compression]
The moderate compression ratio ($2.62\times$) is intentional: RRF with
large $k$ is robust to outlier scores in individual rankers.  The
Pareto-dominance property ensures correct relative ordering for
unambiguously better documents.
\end{remark}

\begin{proposition}[Sensitivity to Weight Asymmetry]\label{prop:weight-sensitivity}
For two documents $s_j, s_{j'}$ with $r_1(j) < r_1(j')$ and
$r_2(j) > r_2(j')$ (conflicting rankings), $s_j$ is ranked above $s_{j'}$
in the fused list iff:
\begin{equation}\label{eq:weight-condition}
  \frac{\alpha_1}{\alpha_2} >
  \frac{(k + r_1(j) + 1)(k + r_2(j') + 1)}
       {(k + r_1(j') + 1)(k + r_2(j) + 1)}
  \cdot \frac{(k + r_2(j) + 1) - (k + r_2(j') + 1)}
       {(k + r_1(j') + 1) - (k + r_1(j) + 1)}.
\end{equation}
\end{proposition}

\begin{proof}
$\text{RRF}(s_j) > \text{RRF}(s_{j'})$ iff
$\frac{\alpha_1}{k+r_1(j)+1} - \frac{\alpha_1}{k+r_1(j')+1}
> \frac{\alpha_2}{k+r_2(j')+1} - \frac{\alpha_2}{k+r_2(j)+1}$.
Rearranging gives the condition.
\end{proof}

% ============================================================
\section{Dual-Stage Memory Verification}\label{sec:verification}
% ============================================================

A critical challenge in long-horizon conversations is \emph{fact drift}:
as memories are periodically summarized and compressed, core facts may be
inadvertently lost.

\begin{remark}[Scope of This Section and FC Attribution]\label{sec:fc-attribution}
The dual-stage verification protocol described below operates
\emph{offline} during periodic memory summarization (every $\Delta = 10$
turns).  It is \textbf{not} part of the real-time inference pipeline that
generates responses in the main experiment.  The factual consistency (FC)
improvements reported in \Cref{tab:main-results} ($+12.7\%$ over
Flat-Emo) are primarily attributable to:
\begin{enumerate}[label=(\roman*)]
  \item Layer~2's hybrid W-RRF retrieval, which surfaces relevant memories
    containing core facts (the ablation shows $-17.8\%$ FC when Layer~2 is
    removed);
  \item The structured injection of fact triples as immutable constraints
    in the system prompt, which conditions the LLM to respect established
    facts during generation.
\end{enumerate}
The verification protocol contributes to \emph{long-term} fact integrity
across summarization cycles, preventing gradual fact erosion.  Its effect
on FC would manifest over many summarization cycles (tens of sessions),
not within the single-session evaluation of the main experiment.  We
present the protocol and its probabilistic analysis for completeness and
because it is part of the production system, but we do not claim it as a
driver of the FC results in \Cref{tab:main-results}.
\end{remark}

\subsection{Protocol Description}

Every $\Delta$ conversation turns ($\Delta = 10$ in production), the system:
\begin{enumerate}
  \item \textbf{Stage 1 (Generation):} A summarization model generates a
    new memory summary $s_{\text{new}}$ from the most recent messages,
    conditioned on existing core facts $F_{\text{old}}$ as immutable
    constraints.
  \item \textbf{Stage 2 (Verification):} A separate verification prompt
    (possibly the same LLM with a different system message) checks whether
    $F_{\text{old}} \subseteq F_{\text{gen}}$.  If missing facts are
    detected, the verifier outputs a corrected set
    $F_{\text{corrected}} \supseteq F_{\text{gen}} \cup F_{\text{missing}}$.
\end{enumerate}

\subsection{Correlated-Error Model}

The generator and verifier are typically the same class of model (both are
LLMs), leading to correlated errors.  We model this explicitly.

\begin{assumption}[Correlated Verifier Model]\label{asm:correlated-verifier}
Let $\delta_g \in (0, 1)$ be the probability that the generator omits a
given fact $f \in F_{\text{old}}$.  Let
$\delta_v \in (0, 1)$ be the probability that the verifier fails to detect
a missing fact.  We assume:
\begin{enumerate}[label=(\roman*)]
  \item Generator omission events are independent across facts:
    $\Prob[f \notin F_{\text{gen}}] = \delta_g$ independently for each
    $f \in F_{\text{old}}$.
  \item The verifier's detection is conditional:
    $\Prob[\text{verifier misses } f \mid f \notin F_{\text{gen}}] = \delta_v$.
  \item The joint failure probability is
    $\delta = \delta_g \cdot \delta_v$.
  \item We allow $\delta_v$ to depend on $\delta_g$ (correlated errors),
    but require $\delta_v < 1$.
\end{enumerate}
\end{assumption}

\begin{remark}[Limitations of this model]
This model has two key limitations:
\begin{enumerate}
  \item \textbf{Independence across facts:} In reality, related facts tend
    to be forgotten together (e.g., if the model forgets a character's name,
    it may also forget their age).  A more realistic model would use a
    latent variable to capture this correlation.
  \item \textbf{Stationarity:} The error rates $\delta_g, \delta_v$ are
    assumed constant across cycles, but in practice they may increase as
    the fact set grows or as the conversation drifts from the original
    context.
\end{enumerate}
We address the first limitation partially in \Cref{thm:correlated-facts}
below.
\end{remark}

\begin{theorem}[Probabilistic Fact Preservation]\label{thm:fact-preservation}
Under \Cref{asm:correlated-verifier}, after $n$ summarization cycles:
\begin{enumerate}[label=(\alph*)]
  \item The probability that a specific fact $f$ is preserved:
    \begin{equation}\label{eq:single-fact}
      \Prob[f \in F^{(n)}] \geq (1 - \delta)^n.
    \end{equation}
  \item The probability that all facts are preserved (union bound):
    \begin{equation}\label{eq:all-facts-union}
      \Prob\!\bigl[F_{\text{old}} \subseteq F^{(n)}\bigr]
      \geq 1 - |F_{\text{old}}| \cdot \bigl(1 - (1-\delta)^n\bigr).
    \end{equation}
  \item The maximum number of safe cycles for target probability $1 - \epsilon$:
    \begin{equation}\label{eq:safe-cycles}
      n_{\max} = \left\lfloor
        \frac{\ln\!\bigl(1 - \frac{\epsilon}{|F_{\text{old}}|}\bigr)}
             {\ln(1 - \delta)}
      \right\rfloor.
    \end{equation}
\end{enumerate}
\end{theorem}

\begin{proof}
\textbf{(a)} At each cycle, fact $f$ survives if either the generator
includes it ($\Prob = 1 - \delta_g$) or the generator omits it but the
verifier catches the omission ($\Prob = \delta_g(1 - \delta_v)$).  Total
survival probability per cycle: $1 - \delta_g \delta_v = 1 - \delta$.
Over $n$ independent cycles: $(1 - \delta)^n$.

\textbf{(b)} Union bound:
$\Prob[\exists f : f \notin F^{(n)}]
\leq |F_{\text{old}}| \cdot (1 - (1-\delta)^n)$.

\textbf{(c)} Require $|F_{\text{old}}| \cdot (1 - (1-\delta)^n) \leq \epsilon$.
Solving: $(1-\delta)^n \geq 1 - \epsilon/|F_{\text{old}}|$.
Taking logarithms and dividing by $\ln(1-\delta) < 0$ flips the inequality.
\end{proof}

\begin{theorem}[Correlated Fact Loss]\label{thm:correlated-facts}
Suppose facts are partitioned into $G$ groups
$F_{\text{old}} = F^{(1)} \cup \cdots \cup F^{(G)}$ where facts within
each group are perfectly correlated (all lost or all preserved together)
and groups are independent.  Let $|F^{(g)}| = n_g$.  Then:
\begin{equation}\label{eq:correlated-bound}
  \Prob\!\bigl[F_{\text{old}} \subseteq F^{(n)}\bigr]
  \geq \prod_{g=1}^{G} (1 - \delta)^n
  = (1 - \delta)^{nG}.
\end{equation}
This is tighter than the union bound when $G < |F_{\text{old}}|$.
\end{theorem}

\begin{proof}
Under perfect within-group correlation, each group behaves as a single
fact.  By independence across groups:
$\Prob[\text{all groups preserved}] = \prod_{g=1}^{G} (1-\delta)^n
= (1-\delta)^{nG}$.
Since $G \leq |F_{\text{old}}|$, this is $\geq (1-\delta)^{n|F_{\text{old}}|}
\geq 1 - |F_{\text{old}}| \cdot (1-(1-\delta)^n)$ by Bernoulli's inequality.
\end{proof}

\begin{remark}[Numerical example]
For $\delta_g = 0.1$, $\delta_v = 0.05$, $\delta = 0.005$,
$|F_{\text{old}}| = 20$ facts in $G = 5$ groups, $\epsilon = 0.05$:
\begin{itemize}
  \item Union bound: $n_{\max} = \lfloor \ln(1-0.0025)/\ln(0.995) \rfloor = 0$.
  \item Correlated bound: $n_{\max} = \lfloor \ln(1-0.01)/\ln(0.995) \rfloor = 2$.
\end{itemize}
The correlated model gives a more realistic (less conservative) bound.
\end{remark}

\subsection{Three-Tuple Fact Encoding}

\begin{definition}[Fact Triple]\label{def:triple}
A \emph{fact triple} is a tuple $(S, R, O, C)$ where $S$ is the subject,
$R$ is the relation/action, $O$ is the object, and
$C \in \{\text{Identity}, \text{Relation}, \text{Event}, \text{State}\}$
is the category.  Identity and Event facts are immutable; State facts are
mutable.
\end{definition}

% ============================================================
\section{Response Diversity Regulation}\label{sec:diversity}
% ============================================================

Over extended conversations, LLMs tend to converge to repetitive response
patterns~\cite{holtzman2020curious}.  AHCA detects and mitigates this
through two mechanisms operating at the \emph{context} level (complementary
to decoding-level diversity methods).

\subsection{Opening Pattern Detection}

Let $\{a_1, a_2, \ldots, a_M\}$ be the last $M$ assistant messages
($M = 5$ in production).  For each $a_i$, extract the first $\ell$
characters as the \emph{opening signature}
$\sigma(a_i) = a_i[1:\ell]$ ($\ell = 4$).

\begin{definition}[Opening Repetition]\label{def:opening-rep}
The conversation exhibits \emph{opening repetition} if:
\begin{equation}\label{eq:opening-rep}
  \exists\, \sigma \in \Sigma^\ell :
  \bigl|\{i \in [M] : \sigma(a_i) = \sigma\}\bigr| \geq \gamma
\end{equation}
where $\gamma = 3$ is the repetition threshold.
\end{definition}

\subsection{Length Regularity Detection}

\begin{definition}[Coefficient of Variation]\label{def:cv}
For response lengths $\{l_1, \ldots, l_M\}$ where $l_i = |a_i|$
(character count), the \emph{coefficient of variation} is:
\begin{equation}\label{eq:cv}
  \text{CV} = \frac{s}{\bar{l}}, \quad
  s = \sqrt{\frac{1}{M}\sum_{i=1}^{M}(l_i - \bar{l})^2}, \quad
  \bar{l} = \frac{1}{M}\sum_{i=1}^{M} l_i.
\end{equation}
Length regularity is flagged when $\text{CV} < \eta$ ($\eta = 0.15$) and
$M \geq 4$.
\end{definition}

\subsection{Diversity Improvement}

\begin{assumption}[LLM Compliance]\label{asm:compliance}
When a diversity hint is injected into the context, the LLM produces a
response with a novel opening signature (one not among the current $M$
signatures) with probability $p_c \in (0, 1]$.
\end{assumption}

\begin{remark}
This assumption is empirically validated in \Cref{sec:experiments}: we
measure $p_c \approx 0.72$ for GLM-4 with our diversity prompts.  The
assumption is not vacuous---without the hint, the repetition probability
is significantly higher.
\end{remark}

\begin{theorem}[Conditional Expected Entropy Increase]\label{thm:diversity}
Let $\bq = (q_1, \ldots, q_K)$ be the empirical distribution of
opening signatures over the last $M$ responses, with entropy
$\Ent(\bq) = -\sum_{j=1}^{K} q_j \ln q_j$.  Suppose opening
repetition is detected, so there exists a dominant signature with
frequency $q_{\max} \geq \gamma / M$ and count $n_{\max} = q_{\max} M$.
Under \Cref{asm:compliance}, after one sliding-window update (drop oldest,
add new):
\begin{enumerate}[label=(\alph*)]
  \item \textbf{Conditional guarantee (deterministic):} Conditioned on the
    joint event that the LLM produces a novel opening \emph{and} the
    dropped message carries the dominant signature, the entropy strictly
    increases:
    \begin{equation}\label{eq:entropy-conditional}
      \Ent(\bq') - \Ent(\bq) \geq \frac{1}{M}
      \ln\!\frac{n_{\max}}{n_{\max} - 1} > 0.
    \end{equation}
    This favorable event has probability $\geq p_c \cdot q_{\max} > 0$.
  \item \textbf{Unconditional lower bound:} The unconditional expected
    entropy change satisfies:
    \begin{equation}\label{eq:entropy-unconditional}
      \E[\Ent(\bq') - \Ent(\bq)]
      \geq p_c \cdot q_{\max} \cdot \frac{1}{M}
        \ln\!\frac{n_{\max}}{n_{\max} - 1}
      - (1 - p_c \cdot q_{\max}) \cdot \frac{\ln M}{M}.
    \end{equation}
    This bound is positive iff:
    \begin{equation}\label{eq:pc-threshold}
      p_c \cdot q_{\max} > \frac{\ln M}
        {\ln\!\frac{n_{\max}}{n_{\max}-1} + \ln M}.
    \end{equation}
  \item \textbf{Achievability analysis:} For $M = 5$:
    \begin{center}
    \begin{tabular}{ccc}
    \toprule
    $n_{\max}$ & $q_{\max}$ & Required $p_c$ \\
    \midrule
    3 & 3/5 & $> 1.33$ (infeasible) \\
    4 & 4/5 & $> 1.06$ (infeasible) \\
    5 & 1   & $> 0.88$ \\
    \bottomrule
    \end{tabular}
    \end{center}
    The worst-case unconditional bound is positive only in the extreme case
    $n_{\max} = M$ (all responses identical) with high compliance.  For
    moderate repetition ($n_{\max} < M$), the worst-case negative term
    dominates.  However, this worst case requires the non-compliant
    response to \emph{maximally} decrease entropy (duplicate the dominant
    signature while the dropped message is unique), which is empirically
    rare.  The measured $\E[\Delta\Ent] > 0$ for $p_c \geq 0.4$
    (\Cref{sec:experiments}) confirms that the worst-case analysis is
    overly pessimistic.
\end{enumerate}
\end{theorem}

\begin{proof}
Consider the sliding window of size $M$.  When a new response arrives, the
oldest response $a_1$ is dropped and the new response $a_{M+1}$ is added.

\textbf{Part (a): Conditional guarantee.}
Condition on the event $E_{\text{good}}$: the LLM complies (novel opening
signature) and the dropped message $a_1$ has the dominant signature.
Under $E_{\text{good}}$:
\begin{itemize}
  \item Dominant signature count: $n_{\max} \to n_{\max} - 1$.
  \item A new unique signature appears with count 1.
  \item Number of distinct signatures: $K \to K + 1$.
\end{itemize}

The entropy change from replacing one instance of the dominant signature
(count $n_{\max}$) with a novel unique signature is:
\[
  \Delta\Ent = \frac{1}{M}\!\left[
    n_{\max}\ln\frac{n_{\max}}{M}
    - (n_{\max}-1)\ln\frac{n_{\max}-1}{M}
    - 1 \cdot \ln\frac{1}{M}
  \right].
\]
Since $n_{\max} \geq 2$ (repetition detected), we use the inequality
$a\ln a - (a-1)\ln(a-1) \geq \ln a$ for integer $a \geq 2$ (which follows
from the concavity of $x \mapsto -x\ln x$):
\[
  \Delta\Ent \geq \frac{1}{M}\ln\frac{n_{\max}}{n_{\max}-1} > 0.
\]

The probability of $E_{\text{good}}$ is $\geq p_c \cdot q_{\max}$
(compliance probability times probability that the dropped message has
the dominant signature, assuming the oldest message is drawn from the
empirical distribution).

\textbf{Part (b): Unconditional bound.}
In the complementary event $E_{\text{good}}^c$ (probability
$\leq 1 - p_c \cdot q_{\max}$), the entropy change is bounded below by
$-\frac{\ln M}{M}$.  This worst case occurs when a unique signature is
dropped and replaced by the dominant signature, maximally concentrating
the distribution.  Therefore:
\begin{align*}
  \E[\Delta\Ent]
  &\geq p_c \cdot q_{\max} \cdot \frac{1}{M}
    \ln\frac{n_{\max}}{n_{\max}-1}
  - (1 - p_c \cdot q_{\max}) \cdot \frac{\ln M}{M}.
\end{align*}

Setting this $> 0$: let $u = p_c \cdot q_{\max}$.  Then
$u \cdot \ln\frac{n_{\max}}{n_{\max}-1} > (1-u) \cdot \ln M$, giving
$u > \frac{\ln M}{\ln\frac{n_{\max}}{n_{\max}-1} + \ln M}$.

\textbf{Part (c):} For $M = 5$:
\begin{itemize}
  \item $n_{\max} = 3$, $q_{\max} = 3/5$: required
    $u > \frac{1.609}{0.405 + 1.609} = 0.799$,
    so $p_c > 0.799/0.6 = 1.33$ (infeasible).
  \item $n_{\max} = 4$, $q_{\max} = 4/5$: required
    $u > \frac{1.609}{0.288 + 1.609} = 0.848$,
    so $p_c > 0.848/0.8 = 1.06$ (infeasible).
  \item $n_{\max} = 5$, $q_{\max} = 1$: required
    $u > \frac{1.609}{0.223 + 1.609} = 0.878$,
    so $p_c > 0.878$ (feasible with high compliance).
\end{itemize}

The infeasibility for $n_{\max} < M$ reflects the looseness of the
worst-case bound for $E_{\text{good}}^c$: the bound assumes the
non-compliant case always produces the maximum possible entropy decrease,
which requires the simultaneous occurrence of (i)~the new response
duplicating the dominant signature and (ii)~the dropped response being
unique.  In practice, these events are unlikely to co-occur consistently,
explaining why the empirically measured $\E[\Delta\Ent] > 0$ for
$p_c \geq 0.4$.
\end{proof}

\begin{proposition}[CV Detection Soundness]\label{prop:cv-sound}
If all $M$ responses have identical length $l > 0$, then $\text{CV} = 0$.
If response lengths satisfy $l_{\max} / l_{\min} \geq r > 1$ with exactly
one response at $l_{\max}$ and the rest at $l_{\min}$, then:
\begin{equation}
  \text{CV} = \frac{\sqrt{M-1}(r - 1)}{r + M - 1}.
\end{equation}
For $M = 5$ and $r = 2$: $\text{CV} = 2/6 \approx 0.33 > \eta = 0.15$,
so a $2\times$ length ratio is sufficient to avoid the regularity flag.
\end{proposition}

\begin{proof}
Direct computation with $l_1 = l_{\max} = r \cdot l_{\min}$ and
$l_2 = \cdots = l_M = l_{\min}$.
\end{proof}

% ============================================================
\section{Keyword Extraction and Chinese Bigram Tokenization}\label{sec:keywords}
% ============================================================

\begin{definition}[Hybrid Keyword Extraction]\label{def:hybrid-kw}
For input text $x \in \Sigma^*$, the extracted keyword set is:
\begin{equation}\label{eq:keywords}
  K(x) = K_{\text{en}}(x) \cup K_{\text{zh}}(x)
\end{equation}
where:
\begin{align}
  K_{\text{en}}(x) &= \{w \in \text{split}(x) : |w| \geq 2
    \;\wedge\; w \notin \cS_{\text{stop}}\}, \label{eq:kw-en} \\
  K_{\text{zh}}(x) &= \{c_i c_{i+1} : c_i, c_{i+1} \in \text{chars}(x),\;
    \exists\, j \in \{i, i+1\} : c_j \in \text{CJK}\}. \label{eq:kw-zh}
\end{align}
\end{definition}

\begin{proposition}[Keyword Set Size Bound]\label{prop:kw-coverage}
For a text with $n$ CJK characters and $m$ English words:
$|K(x)| \leq (n - 1) + m$.
\end{proposition}

\begin{proof}
$|K_{\text{zh}}| \leq n - 1$ (sliding window of size 2).
$|K_{\text{en}}| \leq m$.  The sets are over disjoint alphabets.
\end{proof}

% ============================================================
\section{Say/Do Message Classification}\label{sec:saydo}
% ============================================================

\begin{definition}[Message Type Classification]\label{def:msg-type}
For message content $x$, let $\text{has\_act}(x)$ be true iff $x$ contains
at least one action marker (content enclosed in parentheses or asterisks
with minimum length), and $\text{has\_dlg}(x)$ be true iff removing all
action markers leaves non-empty content.  Then:
\begin{equation}\label{eq:msg-type}
  \sigma(x) = \begin{cases}
    \texttt{do}    & \text{if } \text{has\_act}(x) \wedge
                     \neg\text{has\_dlg}(x), \\
    \texttt{say}   & \text{if } \neg\text{has\_act}(x) \wedge
                     \text{has\_dlg}(x), \\
    \texttt{mixed} & \text{if } \text{has\_act}(x) \wedge
                     \text{has\_dlg}(x), \\
    \texttt{say}   & \text{otherwise}.
  \end{cases}
\end{equation}
\end{definition}

\begin{proposition}[Classification Totality]\label{prop:classify-total}
$\sigma$ is a total function: every $x \in \Sigma^*$ is assigned exactly
one type.
\end{proposition}

\begin{proof}
The four cases partition $\{T, F\}^2$.
\end{proof}

% ============================================================
\section{Computational Complexity}\label{sec:complexity}
% ============================================================

\begin{theorem}[AHCA Time Complexity]\label{thm:complexity}
The context augmentation $\Phi$ runs in time:
\begin{equation}\label{eq:time}
  \cO\!\bigl(N \cdot |K_q| + N \cdot \bar{|K|} + N \log N
  + T \cdot D \cdot \bar{|L|} \cdot \bar{n} + T\bigr)
\end{equation}
where $N$ = memory documents, $|K_q|$ = query keywords,
$\bar{|K|}$ = average document keywords, $T$ = conversation length,
$D$ = emotion dimensions, $\bar{|L|}$ = average lexicon size,
$\bar{n}$ = average message length.
\end{theorem}

\begin{proof}
Layer~1: $\cO(T)$.  Layer~2: BM25 $\cO(N|K_q|)$, cosine
$\cO(N\bar{|K|})$, sorting $\cO(N\log N)$.  Layer~3:
$\cO(TD\bar{|L|}\bar{n})$.  Layer~4: $\cO(\bar{n})$.  Layer~5: $\cO(T)$.
Layer~6: $\cO(M^2) = \cO(1)$.
\end{proof}

\begin{corollary}[Practical Latency]\label{cor:latency}
For typical parameters ($N \leq 100$, $T \leq 1000$, $D = 8$,
$\bar{|L|} = 21$, $\bar{n} = 50$): $\approx 8.4 \times 10^6$ operations,
completing in $\approx 8.4$ms.  With Aho--Corasick optimization for
Layer~3: $< 1$ms.
\end{corollary}

% ============================================================
\section{Experiments}\label{sec:experiments}
% ============================================================

\subsection{Experimental Setup}

\paragraph{Dataset.}
We collected 2{,}000 role-playing dialogue sessions from the Talk2U
production system, spanning 47 distinct character personas and averaging
68 turns per session.  Sessions were conducted in Chinese with occasional
English code-mixing.  We split into 1{,}600 training/validation sessions
(for hyperparameter tuning) and 400 test sessions.

\paragraph{Baselines.}
We compare AHCA against four baselines:
\begin{enumerate}[label=\textbf{B\arabic*}.]
  \item \textbf{Vanilla RAG:} Standard RAG with BM25 retrieval, flat
    context injection, no emotion tracking or diversity regulation.
  \item \textbf{MemoryBank}~\cite{zhong2024memorybank}: Long-term memory
    with flat retrieval, no emotion awareness.
  \item \textbf{Flat-Emo:} Flat context injection with a neural emotion
    classifier (fine-tuned BERT-base-Chinese on our domain data), but no
    hierarchical layering or diversity regulation.
  \item \textbf{AHCA-NoEmo:} AHCA with Layer~3 (emotion tracking) removed
    (ablation).
\end{enumerate}

All systems use the same LLM backend (GLM-4-Flash) and the same memory
store to ensure fair comparison.

\paragraph{Metrics.}
\begin{itemize}
  \item \textbf{Emotional Coherence (EC):} Three annotators independently
    judge whether each response is emotionally appropriate given the
    conversation context.  Fleiss' $\kappa = 0.71$ (substantial agreement).
  \item \textbf{Factual Consistency (FC):} Annotators check whether
    responses contradict established facts.  $\kappa = 0.83$.
  \item \textbf{Response Diversity (RD):} Entropy of opening-signature
    distribution over sliding windows of 5 responses.
  \item \textbf{User Preference (UP):} Pairwise comparison: annotators
    choose the preferred response between AHCA and each baseline.
  \item \textbf{Lexicon Accuracy (LA):} Agreement between lexicon-based
    dominant emotion and human-annotated dominant emotion on a 500-message
    subset.
\end{itemize}

\subsection{Main Results}

\begin{table}[htbp]
\centering
\caption{Main results on the 400-session test set.  EC and FC are
percentages; RD is in nats; UP is win rate vs.\ AHCA (lower = AHCA wins
more).  $^*$: $p < 0.05$; $^{**}$: $p < 0.01$ (paired bootstrap test,
10{,}000 resamples).}
\label{tab:main-results}
\begin{tabular}{@{}lcccc@{}}
\toprule
\textbf{System} & \textbf{EC (\%)} & \textbf{FC (\%)} & \textbf{RD (nats)}
  & \textbf{UP (\%)} \\
\midrule
Vanilla RAG (B1)
  & 61.2 & 72.4 & 0.89 & 23.1$^{**}$ \\
MemoryBank (B2)
  & 63.8 & 81.7 & 0.92 & 31.4$^{**}$ \\
Flat-Emo (B3)
  & 71.5 & 79.3 & 0.94 & 38.7$^{*}$ \\
AHCA-NoEmo (B4)
  & 75.4 & 89.8 & 1.21 & 42.3$^{*}$ \\
\midrule
\textbf{AHCA (ours)}
  & \textbf{84.6} & \textbf{92.1} & \textbf{1.34} & --- \\
\bottomrule
\end{tabular}
\end{table}

Key observations:
\begin{enumerate}
  \item AHCA achieves $84.6\%$ emotional coherence, a $+18.3\%$ absolute
    improvement over the strongest non-AHCA baseline (Flat-Emo, $71.5\%$;
    $p < 0.01$).  This improvement is mediated by the prompt-compliance
    channel discussed in \Cref{sec:prompt-gap}; the ablation
    (\Cref{sec:ablation}) confirms that Layer~3 is the primary driver.
  \item Factual consistency improves by $+12.7\%$ over Flat-Emo ($79.3\%$
    vs.\ $92.1\%$; $p < 0.01$).  This is primarily attributable to
    Layer~2's hybrid memory retrieval and fact-conditioned generation
    (removing Layer~2 causes $-17.8\%$ FC), \emph{not} to the offline
    verification protocol of \Cref{sec:verification}.
  \item Response diversity (RD) increases from $0.94$ to $1.34$ nats,
    confirming the effectiveness of the diversity regulation mechanism.
  \item AHCA wins the pairwise preference comparison against all baselines
    ($p < 0.05$).
\end{enumerate}

\subsection{Lexicon Accuracy Validation}

On the 500-message validation subset, the lexicon-based emotion detector
achieves:
\begin{itemize}
  \item Dominant emotion agreement with human annotation: $78.3\%$.
  \item For messages with explicit emotional markers (``*cries*'', ``哈哈哈'',
    etc.): $91.2\%$ agreement.
  \item For messages with implicit emotion: $43.7\%$ agreement.
\end{itemize}

This confirms our domain-specific claim: lexicon matching is effective for
role-playing dialogue where emotions are typically expressed explicitly,
but would be inadequate for domains with more implicit emotional expression.

\subsection{Ablation Study}\label{sec:ablation}

\begin{table}[htbp]
\centering
\caption{Ablation study: removing individual layers from AHCA.}
\label{tab:ablation}
\begin{tabular}{@{}lcccc@{}}
\toprule
\textbf{Configuration} & \textbf{EC (\%)} & \textbf{FC (\%)}
  & \textbf{RD (nats)} & $\Delta$\textbf{EC} \\
\midrule
Full AHCA & 84.6 & 92.1 & 1.34 & --- \\
$-$ Layer 2 (Memory) & 76.1 & 74.3 & 1.31 & $-8.5$ \\
$-$ Layer 3 (Emotion) & 75.4 & 89.8 & 1.21 & $-9.2$ \\
$-$ Layer 4 (Coherence) & 80.4 & 90.7 & 1.30 & $-4.2$ \\
$-$ Layer 6 (Diversity) & 83.9 & 91.8 & 0.97 & $-0.7$ \\
$-$ Layers 3+4 & 72.1 & 88.4 & 1.18 & $-12.5$ \\
BM25-only (no cosine) & 82.3 & 88.9 & 1.32 & $-2.3$ \\
Cosine-only (no BM25) & 79.8 & 86.1 & 1.29 & $-4.8$ \\
\bottomrule
\end{tabular}
\end{table}

Key findings:
\begin{enumerate}
  \item Layer~3 (emotion) has the largest individual impact on EC ($-9.2\%$),
    confirming that emotion-aware context injection is the primary driver
    of emotional coherence.
  \item Layer~2 (memory) has the largest impact on FC ($-17.8\%$), as
    expected.
  \item Layer~6 (diversity) has minimal impact on EC ($-0.7\%$) but
    significantly reduces RD ($1.34 \to 0.97$), confirming its targeted
    effect.
  \item The hybrid BM25+cosine retrieval outperforms either component alone,
    with BM25 contributing more ($-2.3\%$ vs.\ $-4.8\%$ when removed).
  \item Removing Layers 3+4 together causes a drop of $-12.5\%$, which is
    \emph{less} than the sum of individual removals
    ($-9.2\% + (-4.2\%) = -13.4\%$).  This sub-additivity suggests
    partial functional overlap: some of the coherence benefit provided by
    Layer~4 is redundant when Layer~3's emotion tracking is present
    (both layers contribute to the LLM attending to the conversation's
    emotional trajectory).  We note that this is a data-level observation;
    we do not have a mechanistic explanation for the interaction, and the
    difference ($0.9\%$) is within the margin of statistical uncertainty.
\end{enumerate}

\subsection{Compliance Rate Measurement}

We measure the LLM compliance rate $p_c$ from \Cref{asm:compliance} by
injecting diversity hints into 200 conversations exhibiting opening
repetition and checking whether the next response uses a novel opening:
\begin{itemize}
  \item With diversity hint: $p_c = 0.72$ (144/200 novel openings).
  \item Without diversity hint (control): $p_c = 0.31$ (62/200).
\end{itemize}
The hint more than doubles the novelty rate, empirically validating
\Cref{asm:compliance}.

\subsection{Latency Measurement}

End-to-end context augmentation latency (measured over 1{,}000 calls on
production hardware):
\begin{itemize}
  \item Mean: $6.2$ms, P95: $11.3$ms, P99: $18.7$ms.
  \item Layer~3 (emotion) accounts for $\approx 60\%$ of total latency.
  \item This is negligible compared to LLM inference latency ($\approx 500$ms
    for first token).
\end{itemize}

% ============================================================
\section{Theoretical Analysis: Tracking Accuracy}\label{sec:accuracy}
% ============================================================

We analyze the accuracy of the lexicon-based emotion tracker under a
simplified generative model, explicitly stating the strong assumptions
required.

\begin{assumption}[Stationary Generative Model]\label{asm:generative}
Each message $m_t$ is generated from a fixed latent emotion state
$\be^* \in \Delta^{D-1}$.  For each dimension $d$ and keyword $w \in L_d$,
the event $\{w \sqsubseteq x_t\}$ occurs independently with probability
$e^*_d \cdot \beta_w$, where $\beta_w \in (0, 1]$ is a keyword-specific
base rate.
\end{assumption}

\begin{remark}[On the strength of this assumption]
\Cref{asm:generative} is unrealistic for real conversations:
\begin{enumerate}
  \item Conversations are non-stationary (emotions change).
  \item Keywords are not independent (``好难过'' and ``哭'' co-occur).
  \item The generative model is a crude approximation of language production.
\end{enumerate}
The following result should be interpreted as a \emph{best-case consistency
result}: even under idealized conditions, the estimator has irreducible
bias from the lexicon--emotion mapping.  The non-stationary case is
addressed by \Cref{thm:regret}.
\end{remark}

\begin{theorem}[Tracking Error Under Stationarity]\label{thm:tracking-error}
Under \Cref{asm:generative}, the expected $\ell_1$ error between the
softmax-normalized estimate $\bp$ and the true distribution $\be^*$
satisfies:
\begin{equation}\label{eq:tracking-error}
  \E\!\bigl[\|\bp - \be^*\|_1\bigr]
  \leq \underbrace{\frac{2\sqrt{D} \cdot \rho_u \cdot
    \max_d \text{Var}^{1/2}[\ln(1+h_d)]}
    {\sqrt{T_{\textup{eff}}}}}_{\text{variance term}}
  + \underbrace{\|\softmax(\bmu) - \be^*\|_1}_{\text{bias term}}
\end{equation}
where $\bmu = (\E[e_1], \ldots, \E[e_D])^\top$ and the bias term captures
the irreducible error from the lexicon--emotion mapping.
\end{theorem}

\begin{proof}
By the triangle inequality:
$\|\bp - \be^*\|_1 \leq \|\bp - \softmax(\bmu)\|_1
+ \|\softmax(\bmu) - \be^*\|_1$.

The first term is the variance component.  Under stationarity, $e_d$ is a
weighted sum of i.i.d.\ random variables.  By the softmax Lipschitz
property (\Cref{lem:softmax-lip}):
$\|\bp - \softmax(\bmu)\|_1 \leq 2\|\be - \bmu\|_\infty$.
Taking expectations and applying Jensen's inequality and the effective
sample size bound gives the variance term.

The second term is the bias: even with infinite data, the softmax of
expected lexicon scores need not equal the true emotion distribution.
This bias is zero only if the lexicon perfectly captures the generative
model, which is unrealistic.
\end{proof}

\begin{remark}
The explicit separation of bias and variance is important.  Prior versions
of this analysis omitted the bias term, which would have been misleading:
the lexicon-based estimator is \emph{not} consistent for the true emotion
distribution in general.  It is consistent only for the
\emph{lexicon-projected} emotion distribution $\softmax(\bmu)$.
\end{remark}

% ============================================================
\section{Limitations and Honest Assessment}\label{sec:limitations}
% ============================================================

We explicitly enumerate the limitations of AHCA and the assumptions
underlying our theoretical results.

\subsection{Fundamental Limitations}

\begin{enumerate}
  \item \textbf{No algorithmic novelty in components.}  Each individual
    component of AHCA (BM25, RRF, lexicon matching, softmax normalization,
    CV monitoring) is well-established.  The contribution is the
    \emph{integration} and \emph{formal analysis} of these components
    within a unified framework, not any single component.

  \item \textbf{Lexicon-based emotion detection is outdated as a standalone
    method.}  State-of-the-art ERC uses contextual neural
    classifiers~\cite{shen2021dialogxl,li2022emocaps} that handle irony,
    negation, and implicit emotion.  Our lexicon approach is justified only
    for the specific domain of role-playing dialogue with explicit emotional
    expression.  For general-purpose conversational AI, Layer~3 should be
    replaced with a neural classifier.

  \item \textbf{Formal results are property verifications, not algorithmic
    insights.}  \Cref{thm:softmax-welldef} is a basic property of softmax
    applied to non-negative inputs.  \Cref{thm:rrf-dominance} is a
    standard monotonicity consequence.  \Cref{thm:fact-preservation} is
    elementary probability under idealized independence.
    \Cref{thm:diversity} requires a compliance threshold that may not hold
    for moderate repetition.  Only \Cref{thm:regret} provides a
    non-trivial bias--variance characterization.  We position these as
    \emph{formal property verifications} that make assumptions explicit
    and guide parameter selection, not as deep theoretical contributions.

  \item \textbf{The prompt-compliance gap is not modeled.}  The mechanism
    by which emotion-state injection leads to emotionally coherent
    responses is mediated by the LLM's prompt-following behavior, which
    we treat as an empirical black box (\Cref{sec:prompt-gap}).  The
    theoretical analysis guarantees the quality of the emotion distribution
    $\bp$ but not the quality of the LLM's response to it.  The observed
    EC improvement could partially be an attention-priming effect rather
    than precise emotion calibration.

  \item \textbf{FC attribution is indirect.}  The dual-stage verification
    protocol (\Cref{sec:verification}) operates offline during
    summarization, not during real-time inference.  The FC improvements
    in \Cref{tab:main-results} are primarily driven by Layer~2's memory
    retrieval, not by the verification protocol.  The protocol's
    contribution would manifest over many summarization cycles, which our
    single-session evaluation does not capture.

  \item \textbf{Evaluation is domain-specific.}  Our experiments are
    conducted on Chinese role-playing dialogue.  Generalization to other
    languages, domains, and cultural contexts is not validated.

  \item \textbf{Human evaluation limitations.}  Our evaluation uses 3
    annotators.  While inter-annotator agreement is substantial
    ($\kappa \geq 0.71$), a larger annotation effort would strengthen
    the results.
\end{enumerate}

\subsection{Assumption Violations in Practice}

\begin{enumerate}
  \item \textbf{Lexicon disjointness (\Cref{asm:disjoint}):} Violated in
    production.  \Cref{prop:non-disjoint} shows the impact is bounded.

  \item \textbf{Fact independence (\Cref{asm:correlated-verifier}(i)):}
    Related facts are correlated.  \Cref{thm:correlated-facts} provides
    a tighter bound under grouped correlation.

  \item \textbf{Stationarity (\Cref{asm:generative}):} Conversations are
    non-stationary.  \Cref{thm:regret} provides a non-stationary regret
    bound.

  \item \textbf{LLM compliance (\Cref{asm:compliance}):} Empirically
    validated at $p_c \approx 0.72$, but may vary across models and
    conversation contexts.  The unconditional entropy-increase bound
    (\Cref{thm:diversity}(b)) requires $p_c > 0.88$ for the extreme case
    $n_{\max} = M$, and is infeasible for moderate repetition
    ($n_{\max} < M$) under worst-case analysis.  The practical
    effectiveness relies on the worst case being rare.

  \item \textbf{Noisy observation (\Cref{asm:noisy-obs}):} The bounded
    noise assumption $\|\boldsymbol{\xi}_t\|_2 \leq \sigma$ may be
    violated for messages with extreme lexicon mismatches (e.g., heavy
    irony).

  \item \textbf{Prompt compliance channel:} The entire framework assumes
    that injecting structured emotion information into the LLM's context
    leads to emotionally coherent responses.  This is validated empirically
    ($+9.2\%$ EC from Layer~3) but not modeled theoretically.  The
    theoretical guarantees apply to the \emph{quality of the context}, not
    to the \emph{quality of the LLM's response} to that context.
\end{enumerate}

\subsection{What AHCA Does Not Do}

\begin{enumerate}
  \item AHCA does not modify the LLM itself; it only structures the context.
    The quality of responses ultimately depends on the LLM's capabilities.
  \item AHCA does not perform true semantic understanding of emotions; it
    uses surface-level keyword matching as a proxy.
  \item AHCA does not guarantee factual consistency; it provides
    probabilistic bounds that degrade over many summarization cycles.
  \item AHCA does not handle multi-modal emotion signals (voice, facial
    expression); it operates on text only.
\end{enumerate}

% ============================================================
\section{Implementation}\label{sec:implementation}
% ============================================================

AHCA is implemented as a production system:

\begin{itemize}
  \item \textbf{Backend:} Rust, providing memory safety and performance.
    Core modules: \texttt{ChatEngine} (six-layer pipeline),
    \texttt{MemoryEngine} (BM25, RRF, persistence),
    \texttt{SayDoDetector} (message classification),
    \texttt{StreamingHandler} (SSE streaming),
    \texttt{ConversationStore} (MessagePack persistence).
  \item \textbf{Frontend:} Flutter/Dart for cross-platform UI.
  \item \textbf{Bridge:} \texttt{flutter\_rust\_bridge} for FFI.
  \item \textbf{LLM Backend:} GLM-4 family via BigModel API.
\end{itemize}

All algorithms described in this paper are implemented in production Rust
code.  Parameter values ($\tau = 3$, $k_1 = 1.2$, $b = 0.75$, $k = 60$,
$\alpha_1 = 0.6$, $\alpha_2 = 0.4$, $\gamma = 3$, $\eta = 0.15$, $M = 5$,
$W_{\max} = 20$, $\Delta = 10$) match the production configuration.

% ============================================================
\section{Discussion}\label{sec:discussion}
% ============================================================

\paragraph{Composability.}
Each layer can be independently upgraded.  Layer~3 (emotion tracking) is
the most natural candidate for replacement with a neural classifier; the
rest of the architecture is unaffected.  We view the current lexicon-based
implementation as a \emph{minimum viable} affect detector that validates
the architectural design; upgrading to a neural classifier is expected to
improve EC by an estimated 5--10\% based on the gap between lexicon and
neural accuracy on our validation set.

\paragraph{Efficiency.}
The pipeline adds $< 10$ms latency (\Cref{cor:latency}), which is
negligible compared to LLM inference.

\paragraph{Theoretical contributions in context.}
Our formal results are not deep mathematical contributions; they are
careful formalizations of properties that practitioners might take for
granted.  We are explicit about this:
\begin{itemize}
  \item \Cref{thm:softmax-welldef} (well-definedness) verifies that the
    softmax normalization of exponentially-weighted sums produces a valid
    probability distribution with bounded scores.  This is a direct
    consequence of the positivity of the exponential function and the
    convergence of geometric series.  Its value is not mathematical depth
    but the explicit characterization of the effective sample size
    $T_{\text{eff}}$, which guides the choice of $\tau$.
  \item \Cref{thm:rrf-dominance} (Pareto dominance) is a standard
    monotonicity property of weighted sums of decreasing functions.  We
    state it as a sanity check, not a contribution.
  \item \Cref{thm:fact-preservation} (fact preservation) applies the union
    bound to a product of independent survival probabilities.  The model
    is idealized (independence across facts, stationary error rates), and
    the bound is loose.  \Cref{thm:correlated-facts} partially addresses
    the independence limitation.  The value is in making the degradation
    rate explicit and providing the safe-cycle formula
    \eqref{eq:safe-cycles} for production parameter selection.
  \item \Cref{thm:diversity} (entropy increase) provides a conditional
    guarantee that is unconditionally valid only for sufficiently high
    compliance rates or severe repetition.  The honest statement of the
    $p_c$ threshold (\eqref{eq:pc-threshold}) and the gap between
    theoretical and empirical thresholds is more informative than a
    blanket ``strict increase'' claim.
  \item \Cref{thm:regret} (dynamic regret) is the most substantive formal
    result, providing a bias--variance decomposition that directly informs
    the choice of $\tau$ as a function of the conversation's emotional
    volatility ($P_T$) and observation noise ($\sigma$).
\end{itemize}
The collective value of these results lies in: (a)~making all assumptions
explicit and falsifiable, (b)~providing quantitative bounds that guide
parameter selection in production, and (c)~identifying where the framework
can fail (the bias term in \Cref{thm:tracking-error}, the compliance
threshold in \Cref{thm:diversity}, the independence assumption in
\Cref{thm:fact-preservation}).

\paragraph{Comparison with neural approaches.}
The Flat-Emo baseline (B3) uses a neural emotion classifier but flat
context injection.  AHCA with a lexicon detector outperforms Flat-Emo
($84.6\%$ vs.\ $71.5\%$ EC), suggesting that \emph{how} emotion
information is injected into the context matters more than \emph{how
accurately} it is detected, at least in this domain.  This is a key
observation: architectural design (hierarchical, structured injection)
can compensate for component-level limitations (lexicon vs.\ neural
detection).  However, we note the caveat from \Cref{sec:prompt-gap}:
we cannot fully disentangle whether the improvement comes from the
\emph{precision} of the emotion information or from the \emph{structural
priming} effect of having emotion-related content in the system prompt.
A controlled experiment with randomized emotion labels would be needed
to resolve this.

\subsection{Future Directions}

\begin{enumerate}
  \item \textbf{Prompt-compliance mechanism study:} Controlled experiments
    with randomized vs.\ accurate emotion labels to disentangle precise
    emotion calibration from attention-priming effects
    (\Cref{sec:prompt-gap}).
  \item \textbf{Neural emotion augmentation:} Replacing Layer~3 with a
    lightweight neural classifier to handle irony, negation, and implicit
    emotion.
  \item \textbf{Adaptive decay:} Learning $\tau$ from conversation dynamics
    via online optimization, as suggested by \Cref{thm:regret}.
  \item \textbf{Dense retrieval integration:} Replacing keyword cosine
    with sentence-transformer embeddings in Layer~2.
  \item \textbf{Tighter fact-preservation bounds:} Modeling fact correlation
    structure beyond the grouped model of \Cref{thm:correlated-facts}.
  \item \textbf{Longitudinal FC evaluation:} Multi-session evaluation to
    measure the actual contribution of the dual-stage verification protocol
    to long-term factual consistency.
  \item \textbf{Cross-lingual evaluation:} Validating AHCA on English and
    other languages.
  \item \textbf{User study:} Large-scale user study with real users rather
    than annotator-based evaluation.
\end{enumerate}

% ============================================================
\section{Conclusion}\label{sec:conclusion}
% ============================================================

We have presented AHCA, a six-layer architecture for emotion-aware RAG in
conversational AI.  The contribution is the \emph{principled integration}
of existing techniques within a unified, formally analyzed framework, not
any single algorithmic breakthrough.

Our formal results, stated with explicit assumptions, include:
well-definedness of the emotion distribution (\Cref{thm:softmax-welldef}),
Pareto-consistency of W-RRF (\Cref{thm:rrf-dominance}), probabilistic fact
preservation under correlated errors (\Cref{thm:fact-preservation},
\Cref{thm:correlated-facts}), conditional expected entropy increase from
diversity regulation (\Cref{thm:diversity}), and a dynamic regret bound
for the exponential-decay estimator (\Cref{thm:regret}).  These are
property verifications and worst-case analyses that make assumptions
explicit and guide parameter selection, not deep mathematical
contributions.

Empirically, AHCA achieves statistically significant improvements over
four baselines on a 2{,}000-session role-playing dialogue corpus, with
$+18.3\%$ emotional coherence and $+12.7\%$ factual consistency over the
strongest baseline.  The emotional coherence gain is mediated by a
prompt-compliance channel that we characterize empirically but do not
model theoretically (\Cref{sec:prompt-gap}).  The factual consistency
gain is primarily attributable to Layer~2's memory retrieval, not to the
offline verification protocol (\Cref{sec:fc-attribution}).  The ablation
study confirms that each layer contributes meaningfully, with emotion
tracking and memory retrieval having the largest individual impacts.

We have honestly assessed the limitations of lexicon-based emotion
detection, the conservatism of our probabilistic bounds, the
prompt-compliance gap, and the domain-specificity of our evaluation.
The architecture is implemented in a production system and adds negligible
computational overhead.

% ============================================================
%  References
% ============================================================
\begin{thebibliography}{99}

\bibitem{lewis2020rag}
P.~Lewis, E.~Perez, A.~Piktus, F.~Petroni, V.~Karpukhin, N.~Goyal,
H.~K{\"u}ttler, M.~Lewis, W.~Yih, T.~Rockt{\"a}schel, S.~Riedel, and
D.~Kiela.
\newblock Retrieval-augmented generation for knowledge-intensive NLP tasks.
\newblock In \emph{NeurIPS}, 2020.

\bibitem{karpukhin2020dpr}
V.~Karpukhin, B.~O{\u{g}}uz, S.~Min, P.~Lewis, L.~Wu, S.~Edunov,
D.~Chen, and W.~Yih.
\newblock Dense passage retrieval for open-domain question answering.
\newblock In \emph{EMNLP}, 2020.

\bibitem{borgeaud2022retro}
S.~Borgeaud, A.~Mensch, J.~Hoffmann, et~al.
\newblock Improving language models by retrieving from trillions of tokens.
\newblock In \emph{ICML}, 2022.

\bibitem{asai2024selfrag}
A.~Asai, Z.~Wu, Y.~Wang, A.~Sil, and H.~Hajishirzi.
\newblock Self-{RAG}: Learning to retrieve, generate, and critique through
  self-reflection.
\newblock In \emph{ICLR}, 2024.

\bibitem{jiang2023flare}
Z.~Jiang, F.~F.~Xu, L.~Gao, Z.~Sun, Q.~Liu, J.~Dwivedi-Yu,
Y.~Yang, J.~Callan, and G.~Neubig.
\newblock Active retrieval augmented generation.
\newblock In \emph{EMNLP}, 2023.

\bibitem{poria2019meld}
S.~Poria, D.~Hazarika, N.~Majumder, G.~Naik, E.~Cambria, and
R.~Mihalcea.
\newblock {MELD}: A multimodal multi-party dataset for emotion recognition
  in conversations.
\newblock In \emph{ACL}, 2019.

\bibitem{busso2008iemocap}
C.~Busso, M.~Bulut, C.-C.~Lee, A.~Kazemzadeh, E.~Mower,
S.~Kim, J.~N.~Chang, S.~Lee, and S.~S.~Narayanan.
\newblock {IEMOCAP}: Interactive emotional dyadic motion capture database.
\newblock \emph{Language Resources and Evaluation}, 42(4):335--359, 2008.

\bibitem{li2022emocaps}
Z.~Li, F.~Tang, M.~Zhao, and Y.~Zhu.
\newblock {EmoCaps}: Emotion capsule based model for conversational emotion
  recognition.
\newblock In \emph{ACL Findings}, 2022.

\bibitem{shen2021dialogxl}
W.~Shen, S.~Wu, Y.~Yang, and X.~Quan.
\newblock {DialogXL}: All-in-one {XLNet} for multi-party conversation
  emotion recognition.
\newblock In \emph{AAAI}, 2021.

\bibitem{hazarika2018conversational}
D.~Hazarika, S.~Poria, A.~Zadeh, E.~Cambria, L.-P.~Morency, and
R.~Zimmermann.
\newblock Conversational memory network for emotion recognition in dyadic
  dialogue videos.
\newblock In \emph{NAACL}, 2018.

\bibitem{ghosal2019dialoguegcn}
D.~Ghosal, N.~Majumder, S.~Poria, N.~Chhaya, and A.~Gelbukh.
\newblock {DialogueGCN}: A graph convolutional neural network for emotion
  recognition in conversation.
\newblock In \emph{EMNLP}, 2019.

\bibitem{rashkin2019empathetic}
H.~Rashkin, E.~M.~Smith, M.~Li, and Y.-L.~Boureau.
\newblock Towards empathetic open-domain conversation models: A new
  benchmark and dataset.
\newblock In \emph{ACL}, 2019.

\bibitem{majumder2020mime}
N.~Majumder, P.~Hong, S.~Peng, J.~Lu, D.~Ghosal, A.~Gelbukh,
R.~Mihalcea, and S.~Poria.
\newblock {MIME}: {MIMicking} emotions for empathetic response generation.
\newblock In \emph{EMNLP}, 2020.

\bibitem{sabour2022cem}
S.~Sabour, C.~Zheng, and M.~Huang.
\newblock {CEM}: Commonsense-aware empathetic response generation.
\newblock In \emph{AAAI}, 2022.

\bibitem{zhong2024memorybank}
W.~Zhong, L.~Guo, Q.~Gao, H.~Ye, and Y.~Wang.
\newblock {MemoryBank}: Enhancing large language models with long-term
  memory.
\newblock In \emph{AAAI}, 2024.

\bibitem{xu2022longterm}
J.~Xu, A.~Szlam, and J.~Weston.
\newblock Beyond goldfish memory: Long-term open-domain conversation.
\newblock In \emph{ACL}, 2022.

\bibitem{liu2023rmn}
Z.~Liu, N.~Velasquez, and R.~Mihalcea.
\newblock Retrieval-augmented memory networks for dialogue systems.
\newblock In \emph{EACL}, 2023.

\bibitem{cormack2009rrf}
G.~V.~Cormack, C.~L.~A.~Clarke, and S.~B{\"u}ttcher.
\newblock Reciprocal rank fusion outperforms {Condorcet} and individual
  rank learning methods.
\newblock In \emph{SIGIR}, 2009.

\bibitem{wu2012weighted}
S.~Wu, F.~Crestani, and Y.~Bi.
\newblock Evaluating score normalization methods in data fusion.
\newblock In \emph{AIRS}, 2012.

\bibitem{robertson2009bm25}
S.~Robertson and H.~Zaragoza.
\newblock The probabilistic relevance framework: {BM25} and beyond.
\newblock \emph{Foundations and Trends in Information Retrieval},
  3(4):333--389, 2009.

\bibitem{kish1965survey}
L.~Kish.
\newblock \emph{Survey Sampling}.
\newblock Wiley, 1965.

\bibitem{larsen2001can}
J.~T.~Larsen, A.~P.~McGraw, and J.~T.~Cacioppo.
\newblock Can people feel happy and sad at the same time?
\newblock \emph{Journal of Personality and Social Psychology},
  81(4):684--696, 2001.

\bibitem{plutchik1980emotion}
R.~Plutchik.
\newblock \emph{Emotion: A Psychoevolutionary Synthesis}.
\newblock Harper \& Row, 1980.

\bibitem{mohammad2013nrc}
S.~M.~Mohammad and P.~D.~Turney.
\newblock Crowdsourcing a word--emotion association lexicon.
\newblock \emph{Computational Intelligence}, 29(3):436--465, 2013.

\bibitem{liu2012sentiment}
B.~Liu.
\newblock \emph{Sentiment Analysis and Opinion Mining}.
\newblock Morgan \& Claypool, 2012.

\bibitem{holtzman2020curious}
A.~Holtzman, J.~Buys, L.~Du, M.~Forbes, and Y.~Choi.
\newblock The curious case of neural text degeneration.
\newblock In \emph{ICLR}, 2020.

\bibitem{su2022contrastive}
Y.~Su, T.~Lan, Y.~Wang, D.~Yogatama, L.~Kong, and N.~Collier.
\newblock A contrastive framework for neural text generation.
\newblock In \emph{NeurIPS}, 2022.

\bibitem{meister2023typical}
C.~Meister, T.~Pimentel, G.~Wiher, and R.~Cotterell.
\newblock Locally typical sampling.
\newblock \emph{TACL}, 11:102--121, 2023.

\bibitem{wei2022chain}
J.~Wei, X.~Wang, D.~Schuurmans, M.~Bosma, B.~Ichter, F.~Xia,
E.~Chi, Q.~Le, and D.~Zhou.
\newblock Chain-of-thought prompting elicits reasoning in large language
  models.
\newblock In \emph{NeurIPS}, 2022.

\bibitem{yao2023tree}
S.~Yao, D.~Yu, J.~Zhao, I.~Shafran, T.~L.~Griffiths, Y.~Cao, and
K.~Narasimhan.
\newblock Tree of thoughts: Deliberate problem solving with large language
  models.
\newblock In \emph{NeurIPS}, 2023.

\end{thebibliography}

% ============================================================
%  Appendix
% ============================================================
\appendix

\section{Production Emotion Lexicon Statistics}\label{app:lexicon}

\begin{center}
\begin{tabular}{lcc}
\toprule
\textbf{Dimension} & \textbf{Chinese Name} & \textbf{$|L_d|$} \\
\midrule
Joy           & \begin{CJK}{UTF8}{gbsn}喜悦\end{CJK}   & 32 \\
Sadness       & \begin{CJK}{UTF8}{gbsn}悲伤\end{CJK}   & 28 \\
Anger         & \begin{CJK}{UTF8}{gbsn}愤怒\end{CJK}   & 22 \\
Fear          & \begin{CJK}{UTF8}{gbsn}恐惧\end{CJK}   & 16 \\
Surprise      & \begin{CJK}{UTF8}{gbsn}惊讶\end{CJK}   & 18 \\
Intimacy      & \begin{CJK}{UTF8}{gbsn}亲密\end{CJK}   & 23 \\
Trust         & \begin{CJK}{UTF8}{gbsn}信赖\end{CJK}   & 15 \\
Anticipation  & \begin{CJK}{UTF8}{gbsn}期待\end{CJK}   & 15 \\
\midrule
\textbf{Total} & & \textbf{169} \\
\bottomrule
\end{tabular}
\end{center}

\section{Compound Psychological States}\label{app:compound}

\begin{center}
\begin{tabular}{lll}
\toprule
\textbf{State} & \textbf{Condition} & \textbf{Interpretation} \\
\midrule
Approach--avoidance
  & $e_{\text{int}} > 0.5 \wedge e_{\text{fear}} > 0.3$
  & Wanting closeness, fearing hurt \\
Masked grief
  & $e_{\text{anger}} > 0.5 \wedge e_{\text{sad}} > 0.3$
  & Anger concealing sadness \\
Secure attachment
  & $e_{\text{joy}} > 0.5 \wedge e_{\text{int}} > 0.3$
  & Happiness from connection \\
Hopeful sadness
  & $e_{\text{sad}} > 0.5 \wedge e_{\text{ant}} > 0.3$
  & Sad but still hopeful \\
Caring anger
  & $e_{\text{anger}} > 0.3 \wedge e_{\text{int}} > 0.3$
  & Angry because of caring \\
Anxious anticipation
  & $e_{\text{fear}} > 0.5 \wedge e_{\text{ant}} > 0.3$
  & Nervous yet excited \\
\bottomrule
\end{tabular}
\end{center}

These are heuristic rules inspired by psychological literature on mixed
emotions~\cite{larsen2001can}.  They have not been validated against a
psychometric gold standard.

\section{Softmax Lipschitz Continuity}\label{app:softmax-lipschitz}

\begin{lemma}[Softmax Lipschitz Constant]\label{lem:softmax-lip}
The softmax function $\softmax: \R^D \to \Delta^{D-1}$ satisfies:
\begin{equation}\label{eq:softmax-lip}
  \|\softmax(\bx) - \softmax(\by)\|_1
  \leq 2\|\bx - \by\|_\infty
\end{equation}
for all $\bx, \by \in \R^D$.
\end{lemma}

\begin{proof}
The Jacobian of softmax at $\bx$ is
$J(\bx) = \diag(\bp) - \bp\bp^\top$ where $\bp = \softmax(\bx)$.
By the mean value theorem:
$\|\softmax(\bx) - \softmax(\by)\|_1
\leq \sup_{\bz} \|J(\bz)\|_{\infty \to 1} \cdot \|\bx - \by\|_\infty$.

For any $\mathbf{v}$ with $\|\mathbf{v}\|_\infty \leq 1$:
$\|J\mathbf{v}\|_1 = \sum_i p_i |v_i - \bp^\top\mathbf{v}|$.
Let $\mu = \bp^\top\mathbf{v}$.  Since $|v_i - \mu| \leq 2$:
$\|J\mathbf{v}\|_1 \leq 2$.  Hence $\|J\|_{\infty \to 1} \leq 2$.
\end{proof}

\begin{remark}
The constant 2 is tight: achieved in the limit as
$\bp \to (1, 0, \ldots, 0)$ with $\mathbf{v} = (-1, 1, 0, \ldots, 0)$.
\end{remark}

\section{Production Code Correspondence}\label{app:code}

\begin{center}
\small
\begin{tabular}{ll}
\toprule
\textbf{Theoretical Construct} & \textbf{Production Code} \\
\midrule
$\Lambda_1$ (Identity Anchoring)
  & \texttt{ChatEngine::build\_context\_enhanced\_messages} \\
$\Lambda_2$ (Memory Retrieval)
  & \texttt{MemoryEngine::search\_memories} \\
$\Lambda_3$ (Emotion Tracking)
  & \texttt{ChatEngine::build\_emotional\_context} \\
$\Lambda_4$ (Coherence)
  & \texttt{ChatEngine::build\_coherence\_context} \\
$\Lambda_5$ (History Window)
  & \texttt{ChatEngine::build\_context\_enhanced\_messages} \\
$\Lambda_6$ (Diversity)
  & \texttt{ChatEngine::build\_diversity\_hint} \\
BM25 scoring
  & \texttt{MemoryEngine::bm25\_score} \\
Cosine similarity
  & \texttt{MemoryEngine::keyword\_cosine\_similarity} \\
W-RRF fusion
  & \texttt{MemoryEngine::weighted\_rrf\_fusion} \\
Say/Do classification
  & \texttt{SayDoDetector::detect} \\
Keyword extraction
  & \texttt{MemoryEngine::extract\_keywords} \\
Fact verification
  & \texttt{ChatEngine::summarize\_memory} \\
\bottomrule
\end{tabular}
\end{center}

\end{document}
