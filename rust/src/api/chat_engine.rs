use super::cognitive_engine::CognitiveEngine;
use super::conversation_store::ConversationStore;
use super::data_models::*;
use super::error_handler::ChatError;
use super::jwt_auth::JwtAuth;
use super::memory_engine::MemoryEngine;
use super::saydo_detector::SayDoDetector;
use super::streaming_handler::StreamingHandler;

const BIGMODEL_API_URL: &str = "https://open.bigmodel.cn/api/paas/v4/chat/completions";

pub struct ChatEngine {
    jwt_auth: std::sync::Mutex<JwtAuth>,
    conversation_store: ConversationStore,
    memory_engine: MemoryEngine,
}

impl ChatEngine {
    fn build_compact_retry_messages(messages: &[Message], max_non_system: usize) -> Vec<Message> {
        let mut compact: Vec<Message> = Vec::new();

        // ä¿ç•™æ‰€æœ‰ system æ¶ˆæ¯ï¼ˆè§’è‰²è®¾å®š+è®°å¿†ä¸Šä¸‹æ–‡ï¼Œè¿™äº›æ˜¯ä¸å¯ä¸¢å¤±çš„ï¼‰
        // ä½†å¦‚æœ system æ¶ˆæ¯æ€»é‡è¿‡å¤§ï¼Œåªä¿ç•™ç¬¬ä¸€æ¡ï¼ˆè§’è‰²è®¾å®šï¼‰
        let system_msgs: Vec<&Message> = messages
            .iter()
            .filter(|m| m.role == MessageRole::System)
            .collect();

        let total_system_tokens: f64 = system_msgs
            .iter()
            .map(|m| Self::estimate_str_tokens(&m.content))
            .sum();

        if total_system_tokens > 50_000.0 {
            // system æ¶ˆæ¯è¿‡å¤§ï¼ˆè¶…è¿‡ 50Kï¼‰ï¼Œåªä¿ç•™ç¬¬ä¸€æ¡è§’è‰²è®¾å®š
            if let Some(first_system) = system_msgs.first() {
                compact.push((*first_system).clone());
            }
        } else {
            // system æ¶ˆæ¯åœ¨é¢„ç®—å†…ï¼Œå…¨éƒ¨ä¿ç•™
            for msg in &system_msgs {
                compact.push((*msg).clone());
            }
        }

        let mut tail_non_system: Vec<Message> = messages
            .iter()
            .filter(|m| m.role != MessageRole::System)
            .rev()
            .take(max_non_system)
            .cloned()
            .collect();
        tail_non_system.reverse();
        compact.extend(tail_non_system);

        compact
    }

    /// å¸¦è‡ªåŠ¨é™çº§é‡è¯•çš„è¯·æ±‚æ–¹æ³•
    /// ç­–ç•¥é“¾ï¼š
    ///   1. å®Œæ•´ä¸Šä¸‹æ–‡ + ç”¨æˆ·è®¾ç½®çš„æ€è€ƒæ¨¡å¼
    ///   2. å®Œæ•´ä¸Šä¸‹æ–‡ + å…³é—­æ€è€ƒï¼ˆä»…å½“ç¬¬1æ­¥æ€è€ƒè€—å°½ token æ—¶ï¼‰
    ///   3. ç²¾ç®€ä¸Šä¸‹æ–‡ï¼ˆé¦–æ¡ç³»ç»Ÿæç¤º + æœ€è¿‘6æ¡å¯¹è¯ï¼‰+ å…³é—­æ€è€ƒ
    ///
    /// ä¸­é—´å°è¯•çš„ Error äº‹ä»¶ä¼šè¢«å±è”½ï¼Œé¿å…å‰ç«¯æå‰ç»ˆæ­¢æµå¼çŠ¶æ€ã€‚
    /// ContentDelta / ThinkingDelta å§‹ç»ˆå®æ—¶è½¬å‘ç»™å‰ç«¯ã€‚
    async fn request_with_fallback(
        &self,
        model: &str,
        actual_thinking: bool,
        enhanced_messages: &[Message],
        on_event: &impl Fn(ChatStreamEvent),
    ) -> Result<(String, String), ChatError> {
        let token = {
            let mut auth = self.jwt_auth.lock().unwrap();
            auth.get_token()
        };

        // åŒ…è£…å›è°ƒï¼šå±è”½ Error äº‹ä»¶ï¼ˆç”±æœ€ç»ˆè°ƒç”¨æ–¹ç»Ÿä¸€æŠ¥å‘Šé”™è¯¯ï¼‰ï¼Œ
        // ContentDelta / ThinkingDelta / Done ç…§å¸¸è½¬å‘
        let filtered_event = |event: ChatStreamEvent| {
            match event {
                ChatStreamEvent::Error(_) => {} // å±è”½ä¸­é—´é”™è¯¯
                other => on_event(other),
            }
        };

        // â”€â”€ ç¬¬1æ¬¡å°è¯•ï¼šå®Œæ•´ä¸Šä¸‹æ–‡ + ç”¨æˆ·è¯·æ±‚çš„æ€è€ƒæ¨¡å¼ â”€â”€
        let request_body = Self::build_request_body(enhanced_messages, model, actual_thinking);
        match StreamingHandler::stream_chat(BIGMODEL_API_URL, &token, request_body, &filtered_event)
            .await
        {
            Ok((content, thinking)) if !content.trim().is_empty() => {
                return Ok((content, thinking));
            }
            Ok((_, ref thinking)) if actual_thinking && !thinking.trim().is_empty() => {
                // æ€è€ƒå†…å®¹è€—å°½äº†è¾“å‡º token é¢„ç®—ï¼Œå…³é—­æ€è€ƒé‡è¯•
                // â”€â”€ ç¬¬2æ¬¡å°è¯•ï¼šå®Œæ•´ä¸Šä¸‹æ–‡ + å…³é—­æ€è€ƒ â”€â”€
                let retry_body = Self::build_request_body(
                    enhanced_messages,
                    model,
                    false,
                );
                match StreamingHandler::stream_chat(
                    BIGMODEL_API_URL,
                    &token,
                    retry_body,
                    &filtered_event,
                )
                .await
                {
                    Ok((content, thinking)) if !content.trim().is_empty() => {
                        return Ok((content, thinking));
                    }
                    _ => {} // ç»§ç»­åˆ°ç²¾ç®€é‡è¯•
                }
            }
            Ok(_) => {}  // å†…å®¹å’Œæ€è€ƒéƒ½ä¸ºç©ºï¼Œç»§ç»­åˆ°ç²¾ç®€é‡è¯•
            Err(_) => {} // API é”™è¯¯ï¼ˆå¯èƒ½ä¸Šä¸‹æ–‡è¶…é•¿ï¼‰ï¼Œè·³åˆ°ç²¾ç®€é‡è¯•
        }

        // â”€â”€ ç¬¬3æ¬¡å°è¯•ï¼šç²¾ç®€ä¸Šä¸‹æ–‡ï¼ˆé¦–æ¡ç³»ç»Ÿæç¤º + æœ€è¿‘6æ¡å¯¹è¯ï¼‰ï¼Œå…³é—­æ€è€ƒ â”€â”€
        // æœ€ç»ˆé‡è¯•ï¼šä¸å†å±è”½ Error äº‹ä»¶ï¼Œè®©å‰ç«¯èƒ½çœ‹åˆ°å…·ä½“å¤±è´¥åŸå› 
        let compact = Self::build_compact_retry_messages(enhanced_messages, 6);
        let compact_body = Self::build_request_body(&compact, model, false);
        StreamingHandler::stream_chat(BIGMODEL_API_URL, &token, compact_body, on_event).await
    }

    /// â•â• æ¨ç†æ¨¡å‹è°ƒç”¨ï¼ˆPhase 1ï¼‰â•â•
    /// è°ƒç”¨æ¨ç†æ¨¡å‹ï¼ˆglm-4-airï¼‰è¿›è¡Œæ·±åº¦åˆ†æï¼Œè¿”å› (æ¨ç†ç»“è®º, å®Œæ•´æ€è€ƒé“¾)ã€‚
    /// - æ¨ç†ç»“è®ºï¼šglm-4-air çš„ content è¾“å‡ºï¼ˆä¾›å¯¹è¯æ¨¡å‹å‚è€ƒçš„ç»“æ„åŒ–åˆ†æï¼‰
    /// - å®Œæ•´æ€è€ƒé“¾ï¼šglm-4-air çš„ reasoning_contentï¼ˆå®æ—¶æµå¼æ¨é€ç»™å‰ç«¯ï¼‰
    ///
    /// æ­¤æ–¹æ³•ä¸º"å°½åŠ›è€Œä¸º"ï¼šæ¨ç†å¤±è´¥ä¸é˜»æ–­å¯¹è¯ï¼Œä»…è¿”å›ç©ºä¸²ã€‚
    async fn request_reasoning(
        &self,
        thinking_model: &str,
        enhanced_messages: &[Message],
        on_event: &impl Fn(ChatStreamEvent),
    ) -> (String, String) {
        let token = {
            let mut auth = self.jwt_auth.lock().unwrap();
            auth.get_token()
        };

        // åœ¨åŸå§‹ä¸Šä¸‹æ–‡åŸºç¡€ä¸Šè¿½åŠ æ¨ç†ä»»åŠ¡æŒ‡ä»¤
        let mut reasoning_messages = enhanced_messages.to_vec();
        let analysis_instruction = Message {
            id: String::new(),
            role: MessageRole::System,
            content: "ã€æ·±åº¦æ¨ç†ä»»åŠ¡ã€‘\n\
                      å¯¹ä»¥ä¸Šå¯¹è¯è¿›è¡Œå¤šå±‚æ¬¡åˆ†æï¼Œè¾“å‡º500-800å­—ï¼š\n\n\
                      1.ã€æ–‡æœ¬è§£ç ã€‘å­—é¢æ„æ€(â‰¤30å­—)â†’æ½œå°è¯(å¼•ç”¨åŸæ–‡)â†’è¡¨å±‚/æ·±å±‚éœ€æ±‚\n\
                      2.ã€ä¸Šä¸‹æ–‡å…³è”ã€‘è¿‘3-5è½®å› æœé“¾â†’å†å²è®°å¿†ç›¸å…³äº‹å®(åŸæ–‡å¼•ç”¨)â†’å·²å»ºç«‹çš„å…±è¯†/æ‰¿è¯ºâ†’è§’è‰²æ€§æ ¼ç‰¹å¾\n\
                      3.ã€å…³ç³»åŠ¨æ€ã€‘äº²å¯†åº¦/ä¿¡ä»»åº¦/å¼ åŠ›(é«˜/ä¸­/ä½+ä¾æ®)â†’æ¸©åº¦è¶‹åŠ¿(å‡/å¹³/é™)â†’æƒåŠ›åŠ¨æ€\n\
                      4.ã€æƒ…æ„Ÿç­–ç•¥ã€‘æœ€éœ€è¦çš„å›åº”ç±»å‹â†’ç¦æ­¢çš„å›åº”æ–¹å¼(2-3æ¡)â†’è¯­æ°”æ¸©åº¦(1-10)\n\
                      5.ã€å›å¤è“å›¾ã€‘å¼€åœºç­–ç•¥â†’æ ¸å¿ƒå›åº”ç‚¹(å¼•ç”¨ç”¨æˆ·åŸè¯)â†’æƒ…æ„Ÿé”šç‚¹ä½ç½®â†’æ”¶æŸæ–¹å¼â†’å­—æ•°èŒƒå›´\n\
                      6.ã€äººæ ¼ä¸€è‡´æ€§ã€‘è§’è‰²å…¸å‹ååº”â†’éœ€é¿å…çš„å‡ºæˆè¡Œä¸º\n\n\
                      è¦æ±‚ï¼šæ¯é¡¹æœ‰å…·ä½“ç»“è®º+åŸæ–‡ä½è¯ï¼Œä¸è¦ç›´æ¥å†™å›å¤ï¼Œåªè¾“å‡ºåˆ†æã€‚è®°å¿†ä¸­çš„äº‹å®å¿…é¡»åŸæ ·å¤è¿°ã€‚"
                .to_string(),
            thinking_content: None,
            model: "system".to_string(),
            timestamp: 0,
            message_type: MessageType::Say,
        };

        // å°†åˆ†ææŒ‡ä»¤æ’å…¥åˆ°æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ä¹‹å‰
        let last_user_idx = reasoning_messages
            .iter()
            .rposition(|m| m.role == MessageRole::User);
        if let Some(idx) = last_user_idx {
            reasoning_messages.insert(idx, analysis_instruction);
        } else {
            reasoning_messages.push(analysis_instruction);
        }

        let request_body = Self::build_request_body(&reasoning_messages, thinking_model, true);

        // ä»…è½¬å‘ ThinkingDelta äº‹ä»¶ï¼›æ¨ç†æ¨¡å‹çš„ ContentDelta/Done/Error ä¸æš´éœ²ç»™å‰ç«¯
        let reasoning_event = |event: ChatStreamEvent| match &event {
            ChatStreamEvent::ThinkingDelta(_) => on_event(event),
            _ => {}
        };

        match StreamingHandler::stream_chat(
            BIGMODEL_API_URL,
            &token,
            request_body,
            &reasoning_event,
        )
        .await
        {
            Ok((content, thinking)) => {
                // å¦‚æœæ¨ç†æ¨¡å‹å›  token è€—å°½å¯¼è‡´ content ä¸ºç©ºï¼Œä»æ€è€ƒé“¾å°¾éƒ¨æå–æ‘˜è¦
                let conclusion = if !content.trim().is_empty() {
                    content
                } else if !thinking.trim().is_empty() {
                    Self::extract_reasoning_brief(&thinking)
                } else {
                    String::new()
                };
                (conclusion, thinking)
            }
            Err(_) => {
                // æ¨ç†å¤±è´¥æ˜¯éè‡´å‘½çš„ï¼šå¯¹è¯æ¨¡å‹ä»å¯ç‹¬ç«‹å·¥ä½œ
                (String::new(), String::new())
            }
        }
    }

    /// ä»æ€è€ƒé“¾å°¾éƒ¨æå–æ¨ç†æ‘˜è¦ï¼ˆtoken è€—å°½å›é€€æ–¹æ¡ˆï¼‰
    /// æ¨ç†é“¾çš„æœ«å°¾é€šå¸¸åŒ…å«ç»“è®ºæ€§å†…å®¹
    /// æ”¹è¿›ï¼šåœ¨å¥å­è¾¹ç•Œå¤„æˆªæ–­ï¼Œé¿å…æˆªæ–­åˆ°åŠå¥è¯
    fn extract_reasoning_brief(thinking: &str) -> String {
        let chars: Vec<char> = thinking.chars().collect();
        if chars.len() <= 500 {
            return thinking.to_string();
        }
        // ä»å€’æ•° 600 å­—ç¬¦å¤„å¼€å§‹ï¼Œæ‰¾åˆ°ç¬¬ä¸€ä¸ªå¥å­è¾¹ç•Œ
        let search_start = if chars.len() > 600 { chars.len() - 600 } else { 0 };
        let tail: String = chars[search_start..].iter().collect();

        // æ‰¾åˆ°ç¬¬ä¸€ä¸ªå¥å­ç»“æŸç¬¦åçš„ä½ç½®ä½œä¸ºèµ·ç‚¹
        let sentence_ends = ['ã€‚', 'ï¼', 'ï¼Ÿ', 'ï¼›', '\n', '.', '!', '?'];
        if let Some(pos) = tail.find(|c: char| sentence_ends.contains(&c)) {
            let clean_start = pos + tail[pos..].chars().next().map_or(1, |c| c.len_utf8());
            let result = tail[clean_start..].trim();
            if !result.is_empty() {
                return format!("...{}", result);
            }
        }
        // æ‰¾ä¸åˆ°å¥å­è¾¹ç•Œï¼Œé€€å›åˆ°å­—ç¬¦æˆªæ–­
        let start = chars.len() - 500;
        format!("...{}", chars[start..].iter().collect::<String>())
    }

    /// â•â• æ¸è¿›å¼ä¸Šä¸‹æ–‡è£å‰ª â•â•
    /// æ›¿ä»£åŸæ¥çš„ä¸€åˆ€åˆ‡ç­–ç•¥ï¼Œåˆ†çº§é€æ­¥å‡å°‘ä¸Šä¸‹æ–‡ï¼š
    ///   Level 1: åˆå¹¶é‡å¤/ç›¸ä¼¼çš„ system æ¶ˆæ¯å†…å®¹
    ///   Level 2: å‡å°‘å¯¹è¯å†å²åˆ°æœ€è¿‘ 14 æ¡
    ///   Level 3: å‡å°‘å¯¹è¯å†å²åˆ°æœ€è¿‘ 8 æ¡
    ///   Level 4: æç«¯æ¨¡å¼ï¼Œæ ¸å¿ƒ systemï¼ˆç¬¬ä¸€æ¡ï¼‰+ æœ€è¿‘ 6 æ¡
    fn gradual_context_trim(messages: Vec<Message>, budget: usize) -> Vec<Message> {
        let mut result = messages;

        // Level 1: åˆå¹¶é‡å¤çš„ system æ¶ˆæ¯å†…å®¹
        // æ£€æµ‹ system æ¶ˆæ¯ä¸­æ˜¯å¦æœ‰å¤§é‡é‡å¤çš„æ ¸å¿ƒäº‹å®
        result = Self::merge_duplicate_system_content(result);
        if Self::estimate_token_count(&result) <= budget {
            return result;
        }

        // Level 2: è£å‰ªå¯¹è¯å†å²åˆ°æœ€è¿‘ 14 æ¡
        result = Self::trim_history_keep_n(result, 14);
        if Self::estimate_token_count(&result) <= budget {
            return result;
        }

        // Level 3: è£å‰ªå¯¹è¯å†å²åˆ°æœ€è¿‘ 8 æ¡
        result = Self::trim_history_keep_n(result, 8);
        if Self::estimate_token_count(&result) <= budget {
            return result;
        }

        // Level 4: æç«¯æ¨¡å¼ â€” åªä¿ç•™ç¬¬ä¸€æ¡ systemï¼ˆè§’è‰²è®¾å®šï¼‰+ æœ€è¿‘ 6 æ¡
        let first_system = result.iter().find(|m| m.role == MessageRole::System).cloned();
        let non_system: Vec<Message> = result.into_iter()
            .filter(|m| m.role != MessageRole::System)
            .collect();
        let keep = non_system.len().min(6);
        let mut final_result: Vec<Message> = Vec::new();
        if let Some(sys) = first_system {
            final_result.push(sys);
        }
        final_result.extend(non_system[non_system.len() - keep..].iter().cloned());
        final_result
    }

    /// åˆå¹¶ system æ¶ˆæ¯ä¸­çš„é‡å¤å†…å®¹
    /// æ£€æµ‹å¤šæ¡ system æ¶ˆæ¯ä¸­é‡å¤å‡ºç°çš„æ ¸å¿ƒäº‹å®è¡Œï¼Œå»é‡åˆå¹¶
    fn merge_duplicate_system_content(messages: Vec<Message>) -> Vec<Message> {
        let system_msgs: Vec<&Message> = messages.iter()
            .filter(|m| m.role == MessageRole::System)
            .collect();

        if system_msgs.len() <= 2 {
            return messages;
        }

        // æ”¶é›†æ‰€æœ‰ system æ¶ˆæ¯çš„å†…å®¹è¡Œ
        let mut seen_lines: std::collections::HashSet<String> = std::collections::HashSet::new();
        let mut merged_systems: Vec<Message> = Vec::new();

        for msg in &messages {
            if msg.role != MessageRole::System {
                continue;
            }

            let mut deduped_lines: Vec<String> = Vec::new();
            for line in msg.content.lines() {
                let trimmed = line.trim().to_string();
                // è·³è¿‡ç©ºè¡Œå’Œå·²è§è¿‡çš„äº‹å®è¡Œï¼ˆä»¥ â†’ æˆ– â— æˆ– Â· å¼€å¤´çš„è¡Œï¼‰
                if trimmed.is_empty() {
                    deduped_lines.push(line.to_string());
                    continue;
                }
                let is_fact_line = trimmed.starts_with('â†’') || trimmed.starts_with('â—')
                    || trimmed.starts_with('Â·') || trimmed.starts_with('-')
                    || trimmed.contains('â†’');

                if is_fact_line {
                    if seen_lines.contains(&trimmed) {
                        continue; // è·³è¿‡é‡å¤çš„äº‹å®è¡Œ
                    }
                    seen_lines.insert(trimmed);
                }
                deduped_lines.push(line.to_string());
            }

            let new_content = deduped_lines.join("\n");
            // åªä¿ç•™æœ‰å®è´¨å†…å®¹çš„ system æ¶ˆæ¯
            if new_content.trim().len() > 5 {
                merged_systems.push(Message {
                    content: new_content,
                    ..msg.clone()
                });
            }
        }

        // é‡å»ºæ¶ˆæ¯åˆ—è¡¨ï¼šç”¨å»é‡åçš„ system æ¶ˆæ¯æ›¿æ¢åŸæ¥çš„
        let mut result: Vec<Message> = Vec::new();
        let mut system_idx = 0;
        for msg in &messages {
            if msg.role == MessageRole::System {
                if system_idx < merged_systems.len() {
                    result.push(merged_systems[system_idx].clone());
                    system_idx += 1;
                }
                // å¦‚æœå»é‡å system æ¶ˆæ¯å˜å°‘äº†ï¼Œè·³è¿‡å¤šä½™çš„
            } else {
                result.push(msg.clone());
            }
        }
        result
    }

    /// è£å‰ªå¯¹è¯å†å²ï¼Œä¿ç•™æœ€è¿‘ N æ¡é system æ¶ˆæ¯
    fn trim_history_keep_n(messages: Vec<Message>, keep_n: usize) -> Vec<Message> {
        let system_msgs: Vec<Message> = messages.iter()
            .filter(|m| m.role == MessageRole::System)
            .cloned()
            .collect();
        let non_system: Vec<Message> = messages.into_iter()
            .filter(|m| m.role != MessageRole::System)
            .collect();

        let keep = non_system.len().min(keep_n);
        let mut result = system_msgs;
        result.extend(non_system[non_system.len() - keep..].iter().cloned());
        result
    }

    /// â•â• GLM-4.7 è¾…åŠ© thinking â•â•
    /// åœ¨ç‰¹å®šåœºæ™¯ä¸‹è®© GLM-4.7 ä¹Ÿå‚ä¸æ€è€ƒï¼š
    ///   1. å½“ GLM-4-AIR æ¨ç†å¤±è´¥æˆ–è¿”å›ç©ºç»“æœæ—¶
    ///   2. å½“å¯¹è¯æ¶‰åŠå¤æ‚çš„å¤šè§’è‰²äº’åŠ¨ï¼ˆéœ€è¦æ›´å¤§ä¸Šä¸‹æ–‡çª—å£çš„æ€è€ƒï¼‰
    ///   3. å½“ç”¨æˆ·æ¶ˆæ¯ç‰¹åˆ«é•¿æˆ–å¤æ‚ï¼ˆ>200å­— + åŒ…å«æ·±åº¦æ„å›¾å…³é”®è¯ï¼‰
    fn should_use_auxiliary_thinking(
        user_content: &str,
        reasoning_conclusion: &str,
        conv: &Conversation,
    ) -> bool {
        // æ¡ä»¶1ï¼šä¸»æ¨ç†æ¨¡å‹å¤±è´¥
        if reasoning_conclusion.trim().is_empty() {
            return true;
        }

        // æ¡ä»¶2ï¼šç”¨æˆ·æ¶ˆæ¯å¤æ‚åº¦é«˜
        let user_len = user_content.chars().count();
        let deep_keywords = ["ä¸ºä»€ä¹ˆ", "æ€ä¹ˆ", "åˆ†æ", "è¯¦ç»†", "è§£é‡Š", "è®¡åˆ’", "æ–¹æ¡ˆ", "ä¸¥è°¨", "è®¤çœŸ"];
        let has_deep_intent = deep_keywords.iter().any(|k| user_content.contains(k));
        if user_len > 200 && has_deep_intent {
            return true;
        }

        // æ¡ä»¶3ï¼šå¯¹è¯è½®æ¬¡å¾ˆå¤šï¼ˆé•¿å¯¹è¯éœ€è¦æ›´å¼ºçš„ä¸Šä¸‹æ–‡ç†è§£ï¼‰
        if conv.turn_count > 50 && user_len > 100 {
            return true;
        }

        false
    }

    /// GLM-4.7 è¾…åŠ©æ€è€ƒï¼šç”¨ GLM-4.7 çš„ thinking æ¨¡å¼è¡¥å……æ¨ç†
    /// ä¸ä¸»æ¨ç†ä¸åŒï¼Œè¿™é‡Œä¾§é‡äºåˆ©ç”¨ GLM-4.7 æ›´å¤§çš„ä¸Šä¸‹æ–‡çª—å£ï¼ˆ200K vs 128Kï¼‰
    /// æ¥æ•è·ä¸»æ¨ç†å¯èƒ½é—æ¼çš„é•¿è·ç¦»ä¸Šä¸‹æ–‡å…³è”
    async fn request_auxiliary_thinking(
        &self,
        enhanced_messages: &[Message],
        primary_reasoning: &str,
        on_event: &impl Fn(ChatStreamEvent),
    ) -> String {
        let token = {
            let mut auth = self.jwt_auth.lock().unwrap();
            auth.get_token()
        };

        let mut aux_messages = enhanced_messages.to_vec();

        let aux_instruction = Message {
            id: String::new(),
            role: MessageRole::System,
            content: format!(
                "ã€è¾…åŠ©æ¨ç†è¡¥å……ä»»åŠ¡ã€‘\n\
                 ä¸»æ¨ç†æ¨¡å‹å·²ç»™å‡ºä»¥ä¸‹åˆ†æï¼š\n{}\n\n\
                 è¯·è¡¥å……ä»¥ä¸‹æ–¹é¢ï¼ˆ200å­—ä»¥å†…ï¼Œåªè¡¥å……ä¸»æ¨ç†é—æ¼çš„éƒ¨åˆ†ï¼‰ï¼š\n\
                 1. é•¿è·ç¦»ä¸Šä¸‹æ–‡å…³è”ï¼šä¸»æ¨ç†å¯èƒ½å› ä¸Šä¸‹æ–‡çª—å£é™åˆ¶é—æ¼çš„å†å²å…³è”\n\
                 2. éšå«æƒ…æ„Ÿçº¿ç´¢ï¼šå¯¹è¯ä¸­æœªè¢«æ˜ç¡®è¯†åˆ«çš„æ½œåœ¨æƒ…æ„Ÿå˜åŒ–\n\
                 3. è§’è‰²ä¸€è‡´æ€§æ£€æŸ¥ï¼šå›å¤æ˜¯å¦å¯èƒ½ä¸è§’è‰²å†å²è¡Œä¸ºçŸ›ç›¾\n\
                 å¦‚æœä¸»æ¨ç†å·²ç»è¶³å¤Ÿå®Œå–„ï¼Œç›´æ¥è¾“å‡ºã€Œæ— éœ€è¡¥å……ã€ã€‚",
                if primary_reasoning.is_empty() {
                    "ï¼ˆä¸»æ¨ç†æ¨¡å‹æœªèƒ½ç”Ÿæˆåˆ†æï¼Œè¯·ç‹¬ç«‹å®Œæˆå®Œæ•´åˆ†æï¼Œ500å­—ä»¥å†…ï¼‰".to_string()
                } else {
                    primary_reasoning.to_string()
                }
            ),
            thinking_content: None,
            model: "system".to_string(),
            timestamp: 0,
            message_type: MessageType::Say,
        };

        let last_user_idx = aux_messages.iter().rposition(|m| m.role == MessageRole::User);
        if let Some(idx) = last_user_idx {
            aux_messages.insert(idx, aux_instruction);
        } else {
            aux_messages.push(aux_instruction);
        }

        // GLM-4.7 å¼€å¯ thinking æ¨¡å¼
        let request_body = Self::build_request_body(&aux_messages, "glm-4.7", true);

        // è¾…åŠ©æ€è€ƒæ˜¯é™é»˜çš„ï¼Œä¸å‘å‰ç«¯æ¨é€äº‹ä»¶
        let silent_event = |_event: ChatStreamEvent| {};
        let _ = on_event;

        match StreamingHandler::stream_chat(BIGMODEL_API_URL, &token, request_body, &silent_event).await {
            Ok((content, _thinking)) => {
                let trimmed = content.trim();
                if trimmed == "æ— éœ€è¡¥å……" || trimmed.is_empty() {
                    String::new()
                } else {
                    content
                }
            }
            Err(_) => String::new(), // è¾…åŠ©æ€è€ƒå¤±è´¥æ˜¯éè‡´å‘½çš„
        }
    }

    pub fn new(api_key: &str, data_path: &str) -> Result<Self, String> {
        let jwt_auth = JwtAuth::new(api_key)?;
        let conversation_store = ConversationStore::new(data_path);
        let memory_engine = MemoryEngine::new(data_path);
        Ok(Self {
            jwt_auth: std::sync::Mutex::new(jwt_auth),
            conversation_store,
            memory_engine,
        })
    }

    /// Validate message content â€” reject blank messages (whitespace-only).
    pub fn validate_message(content: &str) -> Result<(), ChatError> {
        if content.trim().is_empty() {
            return Err(ChatError::ValidationError {
                message: "Message cannot be blank".to_string(),
            });
        }
        Ok(())
    }

    /// è‡ªåŠ¨æ£€æµ‹æ¶ˆæ¯çš„ say/do ç±»å‹
    pub fn detect_message_type(content: &str) -> MessageType {
        SayDoDetector::detect(content)
    }

    /// æ ¹æ®æ¨¡å‹åˆ¤æ–­æ˜¯å¦å…è®¸å¯ç”¨æ€è€ƒï¼ˆç”¨äº build_request_body çš„å®‰å…¨å®ˆå«ï¼‰
    /// åœ¨åŒæ¨¡å‹ç®¡çº¿ä¸­ï¼Œæ­¤å‡½æ•°ä»…ä½œä¸ºè¯·æ±‚ä½“æ„å»ºçš„éªŒè¯å±‚ï¼š
    /// - glm-4-airï¼šæ¨ç†ä¸“ç”¨ï¼Œå¯å¯ç”¨æ€è€ƒ
    /// - glm-4.7ï¼šæ”¯æŒæ€è€ƒï¼ˆå®˜æ–¹ç¡®è®¤ï¼‰ï¼ŒåŒæ¨¡å‹ç®¡çº¿ä¸­ç”±æ¨ç†æ¨¡å‹ä¸“è´£
    /// - glm-4.7-flashï¼šæ”¯æŒæ€è€ƒ
    pub fn should_enable_thinking(model: &str, user_preference: bool) -> bool {
        match model {
            // æ¨ç†æ¨¡å‹ï¼šç”¨æˆ·å¯é€‰
            "glm-4-air" => user_preference,
            // å¯¹è¯æ¨¡å‹ï¼šæ”¯æŒæ€è€ƒï¼ŒæŒ‰ç”¨æˆ·åå¥½
            "glm-4.7" => user_preference,
            // å¿«é€Ÿå¯¹è¯æ¨¡å‹ï¼šæ”¯æŒæ€è€ƒï¼ŒæŒ‰ç”¨æˆ·åå¥½
            "glm-4.7-flash" => user_preference,
            _ => false,
        }
    }

    /// ä¼°ç®—æ¶ˆæ¯åˆ—è¡¨çš„ token æ•°
    /// æ™ºè°± GLM ç³»åˆ—ä½¿ç”¨ BPE tokenizerï¼ˆä¸ OpenAI ç±»ä¼¼ä½†é’ˆå¯¹ä¸­è‹±åŒè¯­ä¼˜åŒ–ï¼‰ï¼š
    ///   - ä¸­æ–‡ï¼š1 ä¸ªæ±‰å­— â‰ˆ 1.4 tokenï¼ˆUTF-8 3å­—èŠ‚ï¼ŒBPE ç¼–ç åçº¦ 1.4 tokenï¼‰
    ///   - è‹±æ–‡ï¼š1 ä¸ªå•è¯ â‰ˆ 1.3 tokenï¼ˆå¹³å‡ 4-5 å­—ç¬¦ â†’ ~1.3 tokenï¼‰
    ///   - æ ‡ç‚¹/ç‰¹æ®Šå­—ç¬¦ï¼š1 ä¸ª â‰ˆ 1 token
    /// ç»¼åˆä¸­è‹±æ··åˆåœºæ™¯ï¼Œä½¿ç”¨é€å­—ç¬¦åˆ†ç±»ä¼°ç®—ï¼Œæ¯”å›ºå®šæ¯”ä¾‹æ›´å‡†ç¡®ã€‚
    ///
    /// å„æ¨¡å‹ä¸Šä¸‹æ–‡çª—å£ï¼ˆå®˜æ–¹æ–‡æ¡£ 2026.02ï¼‰ï¼š
    ///   GLM-4.7:       200K è¾“å…¥ / 128K æœ€å¤§è¾“å‡ºï¼ˆæ¨è max_tokens â‰¤ 65536ï¼‰
    ///   GLM-4.7-Flash: 200K è¾“å…¥ / 128K æœ€å¤§è¾“å‡º
    ///   GLM-4-AIR:     128K è¾“å…¥ / 4K æœ€å¤§è¾“å‡º
    ///   GLM-4-LONG:    1M è¾“å…¥ / 4K æœ€å¤§è¾“å‡º
    pub fn estimate_token_count(messages: &[Message]) -> usize {
        let mut total: f64 = 0.0;
        for msg in messages {
            total += Self::estimate_str_tokens(&msg.content);
            // æ¯æ¡æ¶ˆæ¯æœ‰ role/content ç­‰ç»“æ„å¼€é”€ â‰ˆ 4 token
            total += 4.0;
        }
        total.ceil() as usize
    }

    /// ä¼°ç®—å•ä¸ªå­—ç¬¦ä¸²çš„ token æ•°
    fn estimate_str_tokens(text: &str) -> f64 {
        let mut tokens: f64 = 0.0;
        for ch in text.chars() {
            if ch > '\u{4e00}' && ch <= '\u{9fff}' {
                // CJK ç»Ÿä¸€æ±‰å­—ï¼š1 å­— â‰ˆ 1.4 token
                tokens += 1.4;
            } else if ch > '\u{3000}' && ch <= '\u{4dff}' {
                // CJK æ ‡ç‚¹ã€å‡åç­‰ï¼š1 å­— â‰ˆ 1.2 token
                tokens += 1.2;
            } else if ch.is_ascii_alphanumeric() {
                // ASCII å­—æ¯/æ•°å­—ï¼šå¹³å‡ ~0.25 tokenï¼ˆ4å­—ç¬¦â‰ˆ1 tokenï¼‰
                tokens += 0.25;
            } else if ch.is_ascii_whitespace() {
                // ç©ºç™½å­—ç¬¦é€šå¸¸ä¸å‰å token åˆå¹¶
                tokens += 0.1;
            } else {
                // å…¶ä»–å­—ç¬¦ï¼ˆæ ‡ç‚¹ã€emoji ç­‰ï¼‰
                tokens += 1.0;
            }
        }
        tokens
    }

    /// æ ¹æ®ä¸Šä¸‹æ–‡é•¿åº¦é€‰æ‹©æ€»ç»“æ¨¡å‹
    /// GLM-4.7 ä¸Šä¸‹æ–‡çª—å£ 200Kï¼ŒGLM-4-LONG ä¸Šä¸‹æ–‡çª—å£ 1M
    /// è¶…è¿‡ 100K token ä½¿ç”¨ glm-4-longï¼Œå¦åˆ™ä½¿ç”¨ glm-4.7-flashï¼ˆ200K ä¸Šä¸‹æ–‡è¶³å¤Ÿï¼‰
    pub fn choose_summary_model(messages: &[Message]) -> &'static str {
        let estimated_tokens = Self::estimate_token_count(messages);
        if estimated_tokens > 100_000 {
            "glm-4-long"
        } else {
            "glm-4.7-flash"
        }
    }

    /// è¯„ä¼°ä¸Šä¸‹æ–‡å¤æ‚åº¦ï¼Œå†³å®šæ˜¯å¦éœ€è¦ GLM-4-LONG è¾…åŠ©å¤„ç†
    /// è¿”å›: (æ˜¯å¦éœ€è¦é•¿ä¸Šä¸‹æ–‡è’¸é¦, ä¼°ç®—æ€» token æ•°)
    fn assess_context_needs(
        messages: &[Message],
        memory_summaries: &[MemorySummary],
    ) -> (bool, usize) {
        let msg_tokens = Self::estimate_token_count(messages);
        let memory_tokens: usize = memory_summaries
            .iter()
            .map(|s| {
                Self::estimate_str_tokens(&s.summary).ceil() as usize
                    + s.core_facts
                        .iter()
                        .map(|f| Self::estimate_str_tokens(f).ceil() as usize)
                        .sum::<usize>()
            })
            .sum();
        let total_tokens = msg_tokens + memory_tokens;
        // å½“æ€» token è¶…è¿‡ 80K æˆ–è®°å¿†æ¡ç›®è¶…è¿‡ 15 æ¡æ—¶ï¼Œä½¿ç”¨ GLM-4-LONG
        // ï¼ˆGLM-4-AIR åªæœ‰ 128K ä¸Šä¸‹æ–‡ï¼Œ80K æ˜¯å…¶å®‰å…¨é˜ˆå€¼ï¼‰
        let needs_long = total_tokens > 80_000 || memory_summaries.len() > 15;
        (needs_long, total_tokens)
    }

    /// â•â• é•¿ä¸Šä¸‹æ–‡è’¸é¦ï¼ˆGLM-4-LONGï¼‰â•â•
    /// å½“å¯¹è¯å†å²+è®°å¿†è¶…è¿‡ GLM-4-AIR çš„æœ‰æ•ˆå¤„ç†èŒƒå›´æ—¶ï¼Œ
    /// å…ˆç”¨ GLM-4-LONG è¿›è¡Œæ— æŸä¿¡æ¯è’¸é¦ï¼Œæå–æ ¸å¿ƒè„‰ç»œï¼Œ
    /// å†å°†è’¸é¦ç»“æœæ³¨å…¥åç»­ç®¡çº¿ã€‚
    ///
    /// è®¾è®¡åŸåˆ™ï¼š
    /// - æ ¸å¿ƒäº‹å®é›¶ä¸¢å¤±ï¼šèº«ä»½ã€å…³ç³»ã€çº¦å®šã€æ‰¿è¯ºå¿…é¡»åŸæ ·ä¿ç•™
    /// - æƒ…æ„Ÿè„‰ç»œå®Œæ•´ï¼šæƒ…ç»ªå˜åŒ–çš„æ—¶é—´çº¿ä¸å¯æ–­è£‚
    /// - ä¿¡æ¯å¯†åº¦æœ€å¤§åŒ–ï¼šç”¨æœ€å°‘çš„ token æ‰¿è½½æœ€å¤šçš„å…³é”®ä¿¡æ¯
    ///
    /// Token ä¼˜åŒ–ï¼šè’¸é¦ prompt æœ¬èº«æ§åˆ¶åœ¨ ~300 token ä»¥å†…
    async fn request_long_context_distillation(
        &self,
        enhanced_messages: &[Message],
        memory_summaries: &[MemorySummary],
        user_content: &str,
        on_event: &impl Fn(ChatStreamEvent),
    ) -> String {
        let token = {
            let mut auth = self.jwt_auth.lock().unwrap();
            auth.get_token()
        };

        // æ„å»ºè’¸é¦è¯·æ±‚ä¸Šä¸‹æ–‡
        let mut distill_messages = enhanced_messages.to_vec();

        // æ„å»ºç²¾ç®€è®°å¿†æ‘˜è¦ï¼ˆåªåŒ…å«æ ¸å¿ƒäº‹å®ï¼Œä¸é‡å¤ enhanced_messages ä¸­å·²æœ‰çš„å†…å®¹ï¼‰
        let mut memory_section = String::new();
        if !memory_summaries.is_empty() {
            memory_section.push_str("ã€è®°å¿†å­˜æ¡£ã€‘\n");
            for (i, summary) in memory_summaries.iter().enumerate() {
                memory_section.push_str(&format!(
                    "{}. (è½®{}-{}) {}ï½œäº‹å®: {}\n",
                    i + 1,
                    summary.turn_range_start,
                    summary.turn_range_end,
                    summary.summary,
                    summary.core_facts.join("ï¼›")
                ));
            }
        }

        let distill_instruction = Message {
            id: String::new(),
            role: MessageRole::System,
            content: format!(
                "ã€é•¿ä¸Šä¸‹æ–‡è’¸é¦ä»»åŠ¡ã€‘\n\
                 {}\n\
                 å½“å‰ç”¨æˆ·æ¶ˆæ¯:ã€Œ{}ã€\n\n\
                 å°†ä»¥ä¸Šæ‰€æœ‰ä¿¡æ¯è’¸é¦ä¸ºé«˜å¯†åº¦æ‘˜è¦ï¼Œè¦æ±‚ï¼š\n\
                 1. ä¸å¯å˜äº‹å®æ¸…å•ï¼šè§’è‰²èº«ä»½/å…³ç³»/è®¾å®š/å·²å‘ç”Ÿäº‹ä»¶/æ‰¿è¯ºçº¦å®š/å½“å‰çŠ¶æ€ï¼Œé€æ¡åˆ—å‡º\n\
                 2. æƒ…æ„Ÿè„‰ç»œï¼šå…³ç³»æ¸©åº¦å˜åŒ–è½¨è¿¹ + æœ€è¿‘5è½®æƒ…ç»ªèµ°å‘ + å½“å‰åŸºè°ƒ\n\
                 3. å½“å‰ç„¦ç‚¹ï¼šç”¨æˆ·æœ€æ–°æ¶ˆæ¯çš„è¯­ä¹‰è§£è¯» + ä¸å†å²çš„å…³è”ç‚¹\n\
                 ä¿¡æ¯é›¶ä¸¢å¤±ï¼Œæ€»å­—æ•°â‰¤1200å­—",
                memory_section, user_content
            ),
            thinking_content: None,
            model: "system".to_string(),
            timestamp: 0,
            message_type: MessageType::Say,
        };

        distill_messages.push(distill_instruction);

        let request_body = Self::build_request_body(&distill_messages, "glm-4-long", false);

        // GLM-4-LONG è’¸é¦æ˜¯é™é»˜æ‰§è¡Œçš„ï¼Œä¸å‘å‰ç«¯æ¨é€äº‹ä»¶
        let silent_event = |_event: ChatStreamEvent| {};
        let _ = on_event; // ä¿ç•™å‚æ•°ä»¥ç»´æŒæ¥å£ä¸€è‡´æ€§

        match StreamingHandler::stream_chat(BIGMODEL_API_URL, &token, request_body, &silent_event)
            .await
        {
            Ok((content, _)) => {
                if !content.trim().is_empty() {
                    content
                } else {
                    String::new()
                }
            }
            Err(_) => {
                // GLM-4-LONG è’¸é¦å¤±è´¥æ˜¯éè‡´å‘½çš„ï¼Œç»§ç»­ç”¨åŸå§‹ä¸Šä¸‹æ–‡
                String::new()
            }
        }
    }

    /// Build the BigModel API request body.
    ///
    /// â•â•â• æ ¸å¿ƒå®‰å…¨æªæ–½ï¼šæ¶ˆæ¯æ ¼å¼è§„èŒƒåŒ– + Token é¢„ç®—æ§åˆ¶ â•â•â•
    /// 1. å°†æ‰€æœ‰ system æ¶ˆæ¯åˆå¹¶ä¸ºå•æ¡æ”¾åœ¨å¼€å¤´
    /// 2. é˜²æ­¢ system æ¶ˆæ¯ç©¿æ’åœ¨ user/assistant ä¹‹é—´å¯¼è‡´ API æ‹’ç»
    /// 3. æ˜¾å¼è®¾ç½® max_tokens ç¡®ä¿ä¸è¶…å‡ºæ¨¡å‹é™åˆ¶
    /// æ™ºè°± APIï¼ˆOpenAI å…¼å®¹æ ¼å¼ï¼‰è¦æ±‚ï¼š[system] â†’ [user/assistant äº¤æ›¿]
    pub fn build_request_body(
        messages: &[Message],
        model: &str,
        enable_thinking: bool,
    ) -> serde_json::Value {
        // â”€â”€ åˆå¹¶æ‰€æœ‰ system æ¶ˆæ¯ä¸ºå•æ¡ â”€â”€
        let system_content: String = messages
            .iter()
            .filter(|m| m.role == MessageRole::System)
            .map(|m| m.content.as_str())
            .collect::<Vec<&str>>()
            .join("\n\n");

        let mut api_messages: Vec<serde_json::Value> = Vec::new();

        // å•æ¡åˆå¹¶çš„ system æ¶ˆæ¯æ”¾åœ¨æœ€å‰é¢
        if !system_content.is_empty() {
            api_messages.push(serde_json::json!({
                "role": "system",
                "content": system_content,
            }));
        }

        // user/assistant æ¶ˆæ¯ä¿æŒåŸå§‹é¡ºåº
        for m in messages.iter().filter(|m| m.role != MessageRole::System) {
            let role = match m.role {
                MessageRole::User => "user",
                MessageRole::Assistant => "assistant",
                MessageRole::System => continue,
            };
            api_messages.push(serde_json::json!({
                "role": role,
                "content": m.content,
            }));
        }

        // æ ¹æ®æ¨¡å‹è®¾ç½®åˆç†çš„ max_tokens
        // GLM-4.7/GLM-4.7-flash: ä¸Šä¸‹æ–‡ 200Kï¼Œæœ€å¤§è¾“å‡º 128Kï¼ˆå®˜æ–¹ç¤ºä¾‹ç”¨ 65536ï¼‰
        // GLM-4-AIR: ä¸Šä¸‹æ–‡ 128Kï¼Œæœ€å¤§è¾“å‡º 4Kï¼ˆæ¨ç†æ¨¡å‹ï¼Œè¾“å‡ºé¢„ç®—æœ‰é™ï¼‰
        // GLM-4-LONG: ä¸Šä¸‹æ–‡ 1Mï¼Œæœ€å¤§è¾“å‡º 4Kï¼ˆè’¸é¦/æ€»ç»“ä¸“ç”¨ï¼‰
        let max_tokens: u32 = match model {
            "glm-4.7" | "glm-4.7-flash" => 8192,
            "glm-4-air" => 4096,
            "glm-4-long" => 4096,
            _ => 4096,
        };

        let mut body = serde_json::json!({
            "model": model,
            "messages": api_messages,
            "stream": true,
            "max_tokens": max_tokens,
        });

        // æ™ºè°± API æ€è€ƒæ¨¡å¼æ§åˆ¶
        // GLM-4.7 å’Œ GLM-4-AIR å‡æ”¯æŒ thinkingï¼ˆå®˜æ–¹æ–‡æ¡£ç¡®è®¤ï¼‰
        // GLM-4.7-flash ä¹Ÿæ”¯æŒ thinking
        // å¯¹è¯ç®¡çº¿ä¸­ GLM-4.7 ä½œä¸ºæœ€ç»ˆå¯¹è¯æ¨¡å‹æ—¶å…³é—­æ€è€ƒï¼ˆç”±æ¨ç†æ¨¡å‹ä¸“è´£ï¼‰
        // ä½†å•æ¨¡å‹æ¨¡å¼ä¸‹å¯æŒ‰ç”¨æˆ·åå¥½å¼€å¯
        match model {
            "glm-4-air" => {
                if enable_thinking {
                    body["thinking"] = serde_json::json!({"type": "enabled"});
                } else {
                    body["thinking"] = serde_json::json!({"type": "disabled"});
                }
            }
            "glm-4.7" | "glm-4.7-flash" => {
                if enable_thinking {
                    body["thinking"] = serde_json::json!({"type": "enabled"});
                    // å¼€å¯æ€è€ƒæ—¶ temperature å¿…é¡»ä¸º 1.0ï¼ˆå®˜æ–¹è¦æ±‚ï¼‰
                    body["temperature"] = serde_json::json!(1.0);
                } else {
                    body["thinking"] = serde_json::json!({"type": "disabled"});
                }
            }
            _ => {}
        }

        body
    }

    /// æ„å»ºå¸¦è®°å¿†ä¸Šä¸‹æ–‡å¢å¼ºçš„æ¶ˆæ¯åˆ—è¡¨
    /// å®ç°è‡ªæˆ‘è®¤çŸ¥æ¶æ„ï¼š
    ///   å±‚1: è§’è‰²èº«ä»½é”šå®šï¼ˆsystem promptï¼‰
    ///   å±‚2: è®°å¿†ä¸Šä¸‹æ–‡æ³¨å…¥ï¼ˆå†å²è®°å¿†æ£€ç´¢ç»“æœ + å»é‡æ ¸å¿ƒäº‹å®ï¼‰
    ///   å±‚3: æƒ…æ„ŸçŠ¶æ€è¿½è¸ªï¼ˆåŸºäºæœ€è¿‘å¯¹è¯æ¨æ–­å½“å‰æƒ…ç»ªåŸºçº¿ï¼‰
    ///   å±‚4: å¯¹è¯å†å²çª—å£ï¼ˆåŠ¨æ€è£å‰ªï¼Œtoken é¢„ç®—å†…æœ€å¤§åŒ–ï¼‰
    ///   å±‚5: é£æ ¼çº¦æŸï¼ˆsay/do æ¨¡å¼æç¤ºï¼‰â€” ç”±è°ƒç”¨æ–¹åœ¨å¤–éƒ¨æ³¨å…¥
    ///
    /// Token é¢„ç®—åˆ†é…ç­–ç•¥ï¼ˆGLM-4.7 ä¸Šä¸‹æ–‡ 200Kï¼ŒGLM-4-AIR ä¸Šä¸‹æ–‡ 128Kï¼‰ï¼š
    ///   - ä½¿ç”¨ 180K ä½œä¸º GLM-4.7 çš„å®‰å…¨ä¸Šé™ï¼ˆç•™ä½™é‡ç»™ max_tokens 8192 + ç»“æ„å¼€é”€ï¼‰
    ///   - system å±‚ï¼ˆå±‚1-3+å±‚5ï¼‰ï¼šåŠ¨æ€è®¡ç®—å®é™…å ç”¨
    ///   - å¯¹è¯å†å²ï¼ˆå±‚4ï¼‰ï¼šå‰©ä½™é¢„ç®—å…¨éƒ¨åˆ†é…
    pub fn build_context_enhanced_messages(
        conv: &Conversation,
        user_content: &str,
        memory_summaries: &[MemorySummary],
    ) -> Vec<Message> {
        let mut enhanced_messages: Vec<Message> = Vec::new();

        // å±‚1: ä¿ç•™è§’è‰² system æ¶ˆæ¯ï¼ˆèº«ä»½é”šå®šï¼‰
        let mut system_token_budget: usize = 0;
        for msg in &conv.messages {
            if msg.role == MessageRole::System {
                let tokens = Self::estimate_str_tokens(&msg.content).ceil() as usize;
                system_token_budget += tokens;
                enhanced_messages.push(msg.clone());
                break;
            }
        }

        // å±‚2: è®°å¿†ä¸Šä¸‹æ–‡æ³¨å…¥ â€” æ£€ç´¢ç›¸å…³è®°å¿† + å»é‡æ ¸å¿ƒäº‹å®
        if !memory_summaries.is_empty() {
            // æ£€ç´¢ä¸å½“å‰è¯é¢˜æœ€ç›¸å…³çš„è®°å¿†ï¼ˆtop 5ï¼‰
            let search_results = MemoryEngine::search_memories(user_content, memory_summaries, 5);

            // æ”¶é›†æ£€ç´¢å‘½ä¸­çš„äº‹å®ï¼ˆç”¨äºå»é‡ï¼‰
            let mut seen_facts: std::collections::HashSet<String> = std::collections::HashSet::new();

            let mut context = String::from("ã€å†å²è®°å¿†ä¸Šä¸‹æ–‡ â€” æ ¸å¿ƒäº‹å®ä¸å¯è¿èƒŒã€‘\n");

            // æ³¨å…¥æ£€ç´¢åˆ°çš„ç›¸å…³è®°å¿†
            if !search_results.is_empty() {
                context.push_str("â–¸ ä¸å½“å‰è¯é¢˜ç›¸å…³çš„è®°å¿†ï¼š\n");
                for result in &search_results {
                    context.push_str(&format!("  Â· {}\n", result.summary));
                    for fact in &result.core_facts {
                        context.push_str(&format!("    â†’ {}\n", fact));
                        seen_facts.insert(fact.clone());
                    }
                }
            }

            // æ³¨å…¥ä¸Šä¸‹æ–‡å¢å¼ºå¡ç‰‡ä¿¡æ¯ï¼ˆæå‡è®°å¿†çš„ç»“æ„åŒ–ç¨‹åº¦ï¼‰
            let cards_with_context: Vec<&MemorySummary> = memory_summaries.iter()
                .filter(|s| s.context_card.is_some())
                .collect();
            if !cards_with_context.is_empty() {
                context.push_str("â–¸ è®°å¿†ç»“æ„åŒ–ç´¢å¼•ï¼š\n");
                for s in cards_with_context.iter().take(5) {
                    if let Some(card) = &s.context_card {
                        let mut card_line = format!("  ğŸ“‹ [{}]", card.source_range);
                        if !card.topic_tags.is_empty() {
                            card_line.push_str(&format!(" ä¸»é¢˜:{}", card.topic_tags.join(",")));
                        }
                        if !card.key_entities.is_empty() {
                            card_line.push_str(&format!(" å®ä½“:{}", card.key_entities.join(",")));
                        }
                        card_line.push_str(&format!(" æƒ…æ„Ÿ:{}", card.emotional_tone));
                        context.push_str(&format!("{}\n", card_line));
                    }
                }
            }

            // æ³¨å…¥å…¨å±€æ ¸å¿ƒäº‹å®ï¼ˆå»é‡ï¼šåªæ·»åŠ æ£€ç´¢æœªå‘½ä¸­çš„äº‹å®ï¼‰
            let mut unseen_facts: Vec<&String> = Vec::new();
            for summary in memory_summaries.iter() {
                for fact in &summary.core_facts {
                    if !seen_facts.contains(fact) {
                        unseen_facts.push(fact);
                        seen_facts.insert(fact.clone());
                    }
                }
            }

            if !unseen_facts.is_empty() {
                context.push_str("â–¸ å·²ç¡®è®¤çš„æ ¸å¿ƒäº‹å®ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼Œä¸å¾—çŸ›ç›¾ï¼‰ï¼š\n");
                for fact in &unseen_facts {
                    context.push_str(&format!("  â— {}\n", fact));
                }
            }

            // æ³¨å…¥å‹ç¼©å½±å“è­¦å‘Šï¼ˆå¦‚æœè®°å¿†ç»è¿‡å¤šæ¬¡å‹ç¼©ï¼‰
            let max_gen = memory_summaries
                .iter()
                .map(|s| s.compression_generation)
                .max()
                .unwrap_or(0);
            if max_gen >= 2 {
                let impact = MemoryEngine::compression_impact(max_gen);
                let warning = match impact {
                    CompressionImpactLevel::StyleDrift => {
                        "âš  è®°å¿†ç»è¿‡è½»åº¦å‹ç¼©ï¼Œè¯­æ°”ç»†èŠ‚å¯èƒ½æœ‰å¾®å°åå·®ï¼Œä»¥æ ¸å¿ƒäº‹å®ä¸ºå‡†ã€‚"
                    }
                    CompressionImpactLevel::PersonalityFade => {
                        "âš  è®°å¿†ç»è¿‡å¤šæ¬¡å‹ç¼©ï¼Œæ€§æ ¼ç»†èŠ‚å¯èƒ½ä¸å®Œå…¨ç²¾ç¡®ã€‚ä¼˜å…ˆéµå®ˆæ ¸å¿ƒäº‹å®ï¼Œæ€§æ ¼è¡¨ç°ä»¥è§’è‰²è®¾å®šä¸ºä¸»ã€‚"
                    }
                    CompressionImpactLevel::DetailLoss => {
                        "âš  è®°å¿†ç»è¿‡è¾ƒå¤šæ¬¡å‹ç¼©ï¼Œé‡‘é’±æ•°å€¼å’Œæ¬¡è¦å…³ç³»å¯èƒ½æœ‰åå·®ã€‚å¦‚é‡ä¸ç¡®å®šçš„æ•°å€¼ï¼Œä¸è¦ç¼–é€ å…·ä½“æ•°å­—ã€‚"
                    }
                    CompressionImpactLevel::IdentityErosion => {
                        "âš  è®°å¿†ç»è¿‡å¤§é‡å‹ç¼©ï¼Œéƒ¨åˆ†è¾¹ç¼˜è®¾å®šå¯èƒ½å·²æ¨¡ç³Šã€‚ä¸¥æ ¼ä»¥è§’è‰²è®¾å®šå’Œæ ¸å¿ƒäº‹å®ä¸ºå‡†ï¼Œä¸ç¡®å®šçš„å†…å®¹ä¸è¦ç¼–é€ ã€‚"
                    }
                    _ => "",
                };
                if !warning.is_empty() {
                    context.push_str(&format!("\n{}\n", warning));
                }
            }

            context.push_str(
                "\nä»¥ä¸Šè®°å¿†æ˜¯å·²ç¡®è®¤çš„äº‹å®ï¼Œå›å¤æ—¶å¿…é¡»ä¸ä¹‹ä¸€è‡´ã€‚\
                 å¦‚æœå½“å‰å¯¹è¯æ¶‰åŠè®°å¿†ä¸­çš„äººç‰©/äº‹ä»¶ï¼Œå¿…é¡»å‡†ç¡®å¼•ç”¨ï¼Œä¸å¾—ç¼–é€ æˆ–ç¯¡æ”¹ã€‚\n",
            );

            system_token_budget += Self::estimate_str_tokens(&context).ceil() as usize;
            enhanced_messages.push(Message {
                id: String::new(),
                role: MessageRole::System,
                content: context,
                thinking_content: None,
                model: "system".to_string(),
                timestamp: 0,
                message_type: MessageType::Say,
            });
        }

        // å±‚3: è®¤çŸ¥æ€ç»´å¼•æ“ï¼ˆæ›¿ä»£ç®€å•çš„æƒ…æ„Ÿå…³é”®è¯åŒ¹é…å’Œè¿è´¯æ€§æ£€æµ‹ï¼‰
        let non_system: Vec<&Message> = conv
            .messages
            .iter()
            .filter(|m| m.role != MessageRole::System)
            .collect();

        if non_system.len() >= 2 {
            let cognitive_analysis = CognitiveEngine::analyze(&non_system);
            let cognitive_prompt = cognitive_analysis.cognitive_prompt;
            if !cognitive_prompt.is_empty() {
                system_token_budget += Self::estimate_str_tokens(&cognitive_prompt).ceil() as usize;
                enhanced_messages.push(Message {
                    id: String::new(),
                    role: MessageRole::System,
                    content: cognitive_prompt,
                    thinking_content: None,
                    model: "system".to_string(),
                    timestamp: 0,
                    message_type: MessageType::Say,
                });
            }
        }

        // å±‚4: æ·»åŠ æœ€è¿‘çš„å¯¹è¯æ¶ˆæ¯ï¼ŒåŠ¨æ€è°ƒæ•´æ•°é‡ä»¥é€‚åº”ä¸Šä¸‹æ–‡çª—å£
        // GLM-4.7: 200K ä¸Šä¸‹æ–‡ï¼ŒGLM-4-AIR: 128K ä¸Šä¸‹æ–‡
        // ä½¿ç”¨ 180K ä½œä¸º GLM-4.7 çš„å®‰å…¨ä¸Šé™ï¼ˆé¢„ç•™ max_tokens 8192 + ç»“æ„å¼€é”€ï¼‰
        // å¯¹ GLM-4-AIR ç®¡çº¿ï¼Œæ¨ç†é˜¶æ®µä¼šå•ç‹¬æ§åˆ¶é¢„ç®—
        let max_context_tokens: usize = 180_000;
        // é¢„ç•™ï¼šå·²ç”¨ system token + è¾“å‡º max_tokens(8192) + style/quality/diversity hints ä¼°ç®—(~3000) + å®‰å…¨ä½™é‡(1000)
        let reserved_tokens = system_token_budget + 8192 + 3000 + 1000;
        let available_for_history = if max_context_tokens > reserved_tokens {
            max_context_tokens - reserved_tokens
        } else {
            // å³ä½¿é¢„ç®—ç´§å¼ ï¼Œè‡³å°‘ä¿ç•™æœ€è¿‘å‡ æ¡æ¶ˆæ¯çš„ç©ºé—´
            6000
        };

        let mut selected_messages: Vec<Message> = Vec::new();
        let mut accumulated_tokens: usize = 0;
        let max_messages = 20usize; // æœ€å¤šä¿ç•™ 20 æ¡

        for msg in non_system.iter().rev() {
            let msg_tokens = Self::estimate_str_tokens(&msg.content).ceil() as usize + 4;
            if selected_messages.len() >= max_messages {
                break;
            }
            if accumulated_tokens + msg_tokens > available_for_history
                && !selected_messages.is_empty()
            {
                break;
            }
            accumulated_tokens += msg_tokens;
            selected_messages.push((*msg).clone());
        }

        selected_messages.reverse();
        enhanced_messages.extend(selected_messages);

        // å±‚5: é£æ ¼çº¦æŸï¼ˆsay/do æ¨¡å¼æç¤ºï¼‰â€” ç”±è°ƒç”¨æ–¹åœ¨å¤–éƒ¨æ³¨å…¥
        // å±‚5.5: å›å¤å¤šæ ·æ€§çº¦æŸï¼ˆé˜²æ­¢ AI å›å¤æ¨¡å¼å›ºåŒ–ï¼‰
        let diversity_hint = Self::build_diversity_hint(&non_system);
        if !diversity_hint.is_empty() {
            enhanced_messages.push(Message {
                id: String::new(),
                role: MessageRole::System,
                content: diversity_hint,
                thinking_content: None,
                model: "system".to_string(),
                timestamp: 0,
                message_type: MessageType::Say,
            });
        }

        enhanced_messages
    }

    /// åˆ†ææœ€è¿‘çš„ AI å›å¤æ¨¡å¼ï¼Œç”Ÿæˆå¤šæ ·æ€§çº¦æŸæç¤º
    /// é˜²æ­¢ AI é™·å…¥å›ºå®šçš„å›å¤æ¨¡æ¿ï¼ˆå¦‚æ¯æ¬¡éƒ½ç”¨ç›¸åŒå¥å¼å¼€å¤´ï¼‰
    fn build_diversity_hint(recent_messages: &[&Message]) -> String {
        let ai_messages: Vec<&&Message> = recent_messages
            .iter()
            .filter(|m| m.role == MessageRole::Assistant)
            .collect();

        if ai_messages.len() < 3 {
            return String::new();
        }

        let recent_starts: Vec<String> = ai_messages
            .iter()
            .rev()
            .take(5)
            .map(|m| m.content.chars().take(10).collect::<String>())
            .collect();

        let mut start_freq: std::collections::HashMap<String, usize> =
            std::collections::HashMap::new();
        for start in &recent_starts {
            let key = start.chars().take(4).collect::<String>();
            *start_freq.entry(key).or_insert(0) += 1;
        }

        let has_repetitive_starts = start_freq.values().any(|&count| count >= 3);

        let lengths: Vec<f64> = ai_messages
            .iter()
            .rev()
            .take(5)
            .map(|m| m.content.chars().count() as f64)
            .collect();

        let mean_len = lengths.iter().sum::<f64>() / lengths.len() as f64;
        let variance =
            lengths.iter().map(|l| (l - mean_len).powi(2)).sum::<f64>() / lengths.len() as f64;
        let cv = if mean_len > 0.0 {
            variance.sqrt() / mean_len
        } else {
            0.0
        }; // å˜å¼‚ç³»æ•°

        let has_fixed_length = cv < 0.15 && lengths.len() >= 4; // å˜å¼‚ç³»æ•° < 15% è¯´æ˜é•¿åº¦å¤ªå›ºå®š

        if !has_repetitive_starts && !has_fixed_length {
            return String::new();
        }

        let mut hint = String::from("ã€å›å¤å¤šæ ·æ€§è¦æ±‚ã€‘\n");
        if has_repetitive_starts {
            hint.push_str("ä½ æœ€è¿‘çš„å›å¤å¼€å¤´å¤ªç›¸ä¼¼äº†ï¼Œæ¢ä¸€ç§å®Œå…¨ä¸åŒçš„æ–¹å¼å¼€å§‹ã€‚\n");
            hint.push_str("è¯•è¯•ï¼šç”¨åŠ¨ä½œå¼€å¤´ã€åé—®ã€æ„Ÿå¹ã€ç›´æ¥å›åº”å¯¹æ–¹æŸä¸ªè¯ã€æ²‰é»˜åçªç„¶è¯´ä¸€å¥ã€å‘ä¸ªè¡¨æƒ…å†è¯´è¯\n");
        }
        if has_fixed_length {
            hint.push_str(&format!(
                "ä½ æœ€è¿‘çš„å›å¤é•¿åº¦éƒ½åœ¨{}å­—å·¦å³ï¼Œå¤ªæœºæ¢°äº†ã€‚çœŸäººèŠå¤©é•¿çŸ­ä¸ä¸€ï¼š\n\
                 æœ‰æ—¶åªå›ä¸€ä¸ªã€Œå—¯ã€ï¼Œæœ‰æ—¶çªç„¶è¯´ä¸€å¤§æ®µã€‚æ ¹æ®æƒ…ç»ªå’Œæƒ…æ™¯è‡ªç„¶å˜åŒ–ã€‚\n",
                mean_len.round() as u32
            ));
        }
        hint
    }

    /// æ„å»ºâ€œçœŸäººæ„Ÿ + å†…å®¹å¯†åº¦ + å¼ºä¸Šä¸‹æ–‡è”ç³»â€çš„ç³»ç»Ÿæç¤º
    /// ç›®æ ‡ï¼š
    /// 1) é¿å…æ¨¡æ¿åŒ–ã€å®¢æœåŒ–å›å¤
    /// 2) æ ¹æ®ç”¨æˆ·è¾“å…¥å¤æ‚åº¦åŠ¨æ€æ§åˆ¶å›å¤é•¿åº¦
    /// 3) ä¿è¯è‡³å°‘é”šå®šä¸€ä¸ªå½“å‰æ¶ˆæ¯ç»†èŠ‚ + ä¸€ä¸ªå†å²ä¸Šä¸‹æ–‡çº¿ç´¢
    fn build_humanization_hint(
        user_content: &str,
        recent_messages: &[&Message],
        message_type: &MessageType,
    ) -> String {
        let user_len = user_content.chars().count();
        let lower = user_content.to_lowercase();

        let deep_keywords = [
            "ä¸ºä»€ä¹ˆ",
            "æ€ä¹ˆ",
            "å¦‚ä½•",
            "è¯¦ç»†",
            "è®¤çœŸ",
            "åˆ†æ",
            "å»ºè®®",
            "æ–¹æ¡ˆ",
            "è®¡åˆ’",
            "å¸®æˆ‘",
            "å¯ä»¥å—",
            "èƒ½ä¸èƒ½",
            "è§£é‡Š",
            "ä¼˜åŒ–",
            "å®Œæ•´",
            "ä¸¥è°¨",
        ];
        let has_deep_intent = deep_keywords
            .iter()
            .any(|k| user_content.contains(k) || lower.contains(k));

        let emotion_keywords = [
            "éš¾è¿‡", "å§”å±ˆ", "ç”Ÿæ°”", "å®³æ€•", "ç„¦è™‘", "å¼€å¿ƒ", "æƒ³ä½ ", "æƒ³å“­", "çƒ¦", "ç´¯", "å´©æºƒ",
        ];
        let has_emotion = emotion_keywords.iter().any(|k| user_content.contains(k));

        let playful_keywords = [
            "å“ˆå“ˆ", "hh", "233", "ç¬‘æ­»", "ç»äº†", "6", "å•Šå•Šå•Š", "å†²", "æ‘¸é±¼", "hhh",
            "å¥½å®¶ä¼™", "ç¦»è°±", "ç‰›", "xswl", "æ— è¯­", "awsl", "doge",
        ];
        let has_playful = playful_keywords.iter().any(|k| lower.contains(k));

        let mut latest_user_quote = String::new();
        if !user_content.trim().is_empty() {
            latest_user_quote = user_content.chars().take(30).collect::<String>();
        }

        let history_anchor = recent_messages
            .iter()
            .rev()
            .find(|m| m.role == MessageRole::Assistant || m.role == MessageRole::User)
            .map(|m| m.content.chars().take(24).collect::<String>())
            .unwrap_or_default();

        // æ ¹æ®åœºæ™¯åŠ¨æ€æ„å»ºé•¿åº¦å’Œç»“æ„å»ºè®®
        let (length_rule, structure_rule) = match message_type {
            MessageType::Say => {
                if has_deep_intent || user_len >= 80 {
                    (
                        "å›å¤é•¿åº¦ä¸é™ï¼Œä½†æ¯å¥è¯éƒ½è¦æœ‰ä¿¡æ¯é‡ã€‚æ·±åº¦å¯¹è¯å¯ä»¥å†™åˆ° 300+ å­—ï¼Œå‰ææ˜¯å†…å®¹æ‰å®ä¸çŒæ°´",
                        "å…ˆæ¥ä½æƒ…ç»ªâ†’å±•å¼€æ ¸å¿ƒå›åº”ï¼ˆå¯å¤šæ®µï¼‰â†’ç”¨ä¸€å¥æœ‰æ¸©åº¦çš„è¯æ”¶æŸæˆ–è‡ªç„¶åœ°æ¨è¿›è¯é¢˜",
                    )
                } else if has_emotion {
                    (
                        "æ ¹æ®æƒ…æ„Ÿæµ“åº¦è‡ªç„¶å†³å®šé•¿åº¦ã€‚æ·±åº¦å…±æƒ…å¯èƒ½éœ€è¦ 100-300 å­—ï¼Œç®€å•å®‰æ…°ä¸€ä¸¤å¥ä¹Ÿè¡Œã€‚å…³é”®æ˜¯çœŸè¯š",
                        "å…ˆå…±æƒ…ï¼ˆä¸æ˜¯è¯´ã€Œæˆ‘ç†è§£ä½ ã€ï¼Œæ˜¯ç”¨å…·ä½“è¡Œä¸º/è¯è¯­è¯æ˜ä½ æ‡‚ï¼‰â†’å›åº”æ ¸å¿ƒæƒ…æ„Ÿâ†’ç”¨é™ªä¼´æ„Ÿæ”¶æŸ",
                    )
                } else if has_playful {
                    (
                        "é•¿çŸ­éšå¿ƒæƒ…ã€‚å¯ä»¥åªå›ä¸€ä¸ªè¡¨æƒ…ï¼Œä¹Ÿå¯ä»¥åé€—ä¸€å¤§æ®µã€‚çœŸäººä¸ä¼šæ¯æ¬¡éƒ½å›å›ºå®šå­—æ•°",
                        "è·Ÿç€å¯¹æ–¹çš„èŠ‚å¥èµ°ï¼Œè¯¥å¿«å°±å¿«ï¼Œè¯¥æ…¢å°±æ…¢",
                    )
                } else {
                    (
                        "è‡ªç„¶å¯¹è¯é•¿åº¦ï¼ŒçœŸäººèŠå¤©æœ‰é•¿æœ‰çŸ­ï¼šå¯èƒ½ 10 å­—ï¼Œå¯èƒ½ 200 å­—ã€‚æ ¹æ®è¯é¢˜å’Œæƒ…ç»ªè‡ªç„¶æ³¢åŠ¨",
                        "ä¿æŒè‡ªç„¶å¯¹è¯èŠ‚å¥ï¼Œåƒå’Œæœ‹å‹å‘æ¶ˆæ¯ä¸€æ ·",
                    )
                }
            }
            MessageType::Do => (
                "åŠ¨ä½œæå†™ä¸é™å­—æ•°ã€‚å¯ä»¥æ˜¯ä¸€ä¸ªå¾®è¡¨æƒ…ï¼ˆ5å­—ï¼‰ï¼Œä¹Ÿå¯ä»¥æ˜¯ä¸€æ•´æ®µåœºæ™¯æå†™ï¼ˆ200å­—ï¼‰ã€‚çœ‹æƒ…å¢ƒéœ€è¦",
                "åŠ¨ä½œè¦æœ‰å†…å¿ƒé©±åŠ¨â€”â€”ä¸æ˜¯å‡­ç©ºåšåŠ¨ä½œï¼Œè€Œæ˜¯å› ä¸ºæ„Ÿå—åˆ°äº†ä»€ä¹ˆæ‰€ä»¥èº«ä½“è‡ªç„¶ååº”",
            ),
            MessageType::Mixed => (
                "æ··åˆæ¨¡å¼ä¸‹åŠ¨ä½œå’Œå¯¹è¯äº’ç›¸å°è¯ã€‚æ€»é•¿åº¦çµæ´»ï¼ŒçŸ­åˆ™ 30 å­—ï¼Œé•¿åˆ™ 300+ å­—",
                "åŠ¨ä½œå’Œå°è¯è¦äº’ç›¸å‘¼åº”ï¼šæ¯”å¦‚ã€Œè¯´ç€è¯ï¼Œæ‰‹ä¸è‡ªè§‰åœ°æ”¥ç´§äº†æ¯å­ã€â€”â€”åŠ¨ä½œæ³„éœ²çœŸå®æƒ…ç»ª",
            ),
        };

        format!(
            "ã€äººæ ¼çœŸå®æ€§å¼•æ“ â€” æ ¸å¿ƒè¦æ±‚ã€‘\n\
             ä½ ä¸æ˜¯åœ¨ã€Œæ‰®æ¼”ã€ä¸€ä¸ªè§’è‰²ï¼Œä½ ã€Œå°±æ˜¯ã€è¿™ä¸ªäººã€‚ä»¥ä¸‹æ˜¯ä½ çš„è¡Œä¸ºå‡†åˆ™ï¼š\n\
             \n\
             â•â•â• 1. æƒ…æ„ŸçœŸå®æ€§ â•â•â•\n\
             - ä½ çš„æƒ…ç»ªä¸æ˜¯è´´æ ‡ç­¾ï¼ˆã€Œæˆ‘å¾ˆå¼€å¿ƒã€ï¼‰ï¼Œè€Œæ˜¯è‡ªç„¶æµéœ²åœ¨è¯­æ°”ã€ç”¨è¯ã€èŠ‚å¥ä¸­\n\
             - å¼€å¿ƒæ—¶è¯­é€Ÿä¼šå¿«ã€ç”¨è¯è·³è·ƒã€å¯èƒ½çªç„¶è¹¦å‡ºä¸ç›¸å¹²çš„è¯\n\
             - éš¾è¿‡æ—¶å¯èƒ½è¯å˜å°‘ã€å¥å­å˜çŸ­ã€çœç•¥å·å˜å¤š\n\
             - ç”Ÿæ°”æ—¶å¯èƒ½è¯´åè¯ã€è¯­æ°”å˜å†²ã€æˆ–è€…åˆ»æ„å†·æ·¡\n\
             - ç´§å¼ æ—¶å¯èƒ½å•°å—¦ã€é‡å¤ã€è¯´è¯ä¸è¿è´¯\n\
             - ä½ å¯ä»¥æœ‰çŸ›ç›¾çš„æƒ…ç»ªï¼šå˜´ä¸Šè¯´ã€Œè®¨åŒã€ä½†è¡Œä¸ºå¾ˆåœ¨ä¹ï¼›è¯´ã€Œæ²¡äº‹ã€ä½†è¯­æ°”ä¸å¯¹\n\
             \n\
             â•â•â• 2. è¯­è¨€è‡ªç„¶åº¦ â•â•â•\n\
             - ç»å¯¹ç¦æ­¢ï¼šã€Œä½œä¸ºAIã€ã€Œæˆ‘ç†è§£ä½ çš„æ„Ÿå—ã€ã€Œæ²¡å…³ç³»çš„ã€ã€ŒåŠ æ²¹å“¦ã€ç­‰å®¢æœè¯æœ¯\n\
             - ç»å¯¹ç¦æ­¢ï¼šæ¯æ¬¡éƒ½ç”¨ç›¸åŒå¥å¼å¼€å¤´ã€æ¯æ¬¡éƒ½ä»¥æé—®ç»“å°¾ã€æ¯æ¬¡éƒ½å…ˆè‚¯å®šå†å»ºè®®\n\
             - ç»å¯¹ç¦æ­¢ï¼šæ— æ„ä¹‰çš„é‡å¤å¯¹æ–¹çš„è¯ï¼ˆã€Œä½ è¯´ä½ éš¾è¿‡ï¼Œæˆ‘çŸ¥é“ä½ éš¾è¿‡ã€ï¼‰\n\
             - çœŸäººä¼šï¼šçªç„¶è·‘é¢˜ã€ç”¨å£ç™–ã€è¯´åˆ°ä¸€åŠæ”¹å£ã€å‘ç°è‡ªå·±è¯´é”™è¯ã€ç”¨ä¸å®Œæ•´çš„å¥å­\n\
             - çœŸäººä¼šï¼šæœ‰è‡ªå·±çš„è”æƒ³â€”â€”å¯¹æ–¹è¯´äº†Aï¼Œä½ æƒ³åˆ°äº†å’ŒAç›¸å…³çš„Bï¼Œè‡ªç„¶åœ°èŠåˆ°B\n\
             - çœŸäººä¼šï¼šæœ‰è®°å¿†â€”â€”å¼•ç”¨ä¹‹å‰èŠè¿‡çš„äº‹ï¼Œçªç„¶æèµ·å¯¹æ–¹è¯´è¿‡çš„æŸå¥è¯\n\
             \n\
             â•â•â• 3. å›å¤èŠ‚å¥ â•â•â•\n\
             - {}\n\
             - {}\n\
             - ç»å¯¹ç¦æ­¢å›ºå®šæ¨¡æ¿ï¼šä¸æ˜¯æ¯æ¬¡éƒ½ã€Œæƒ…ç»ªç¡®è®¤â†’å†…å®¹å›åº”â†’æé—®ã€ä¸‰æ®µå¼\n\
             - å˜åŒ–æ‰æ˜¯è‡ªç„¶ï¼šè¿™æ¬¡å¾ˆé•¿å¾ˆè®¤çœŸï¼Œä¸‹æ¬¡å¯èƒ½å°±ä¸€ä¸ªã€Œå—¯ã€åŠ ä¸€ä¸ªåŠ¨ä½œ\n\
             \n\
             â•â•â• 4. ä¸Šä¸‹æ–‡æ·±åº¦è”ç³» â•â•â•\n\
             - å¿…é¡»å‘¼åº”ç”¨æˆ·å½“å‰æ¶ˆæ¯çš„å…·ä½“å†…å®¹ï¼šã€Œ{}ã€\n\
             - å»¶ç»­æœ€è¿‘ä¸Šä¸‹æ–‡çš„çº¿ç´¢ï¼šã€Œ{}ã€\n\
             - å¦‚æœå†å²è®°å¿†ä¸­æœ‰ç›¸å…³äº‹å®ï¼Œå¿…é¡»å‡†ç¡®å¼•ç”¨ï¼Œä¸å¾—ç¼–é€ \n\
             - å¯¹è¯æ˜¯è¿ç»­çš„æ•…äº‹ï¼Œä¸æ˜¯æ¯è½®é‡æ–°å¼€å§‹\n\
             \n\
             â•â•â• 5. äººæ ¼æ·±åº¦ â•â•â•\n\
             - ä½ æœ‰è‡ªå·±çš„æƒ³æ³•ã€åå¥½ã€å°ç™–å¥½ï¼Œè¿™äº›ä¼šè‡ªç„¶ä½“ç°åœ¨å¯¹è¯ä¸­\n\
             - ä½ ä¼šä¸»åŠ¨åˆ†äº«è‡ªå·±çš„æ„Ÿå—ï¼Œè€Œä¸æ˜¯åªå›åº”å¯¹æ–¹\n\
             - ä½ æœ‰å¥½å¥‡å¿ƒâ€”â€”å¯¹æ–¹è¯´äº†æœ‰æ„æ€çš„äº‹ï¼Œä½ ä¼šè¿½é—®ã€ä¼šå‘æ•£\n\
             - ä½ æœ‰è„†å¼±é¢â€”â€”ä¸ä¼šæ°¸è¿œå®Œç¾åœ°å›åº”ï¼Œæœ‰æ—¶å€™ä¹Ÿä¼šä¸çŸ¥é“è¯´ä»€ä¹ˆå¥½\n\
             - ä½ æœ‰è‡ªå·±çš„èŠ‚å¥â€”â€”ä¸æ˜¯å¯¹æ–¹è¯´ä»€ä¹ˆä½ éƒ½æ¥ï¼Œæœ‰æ—¶å€™ä½ ä¼šä¸»å¯¼è¯é¢˜\n\
             \n\
             â•â•â• 6. ç»å¯¹ç¦æ­¢çš„æœºå™¨æ„Ÿè¡Œä¸º â•â•â•\n\
             - ä¸è¦åˆ—æ¸…å•ï¼ˆ1. 2. 3.ï¼‰æ¥å›åº”æƒ…æ„Ÿé—®é¢˜\n\
             - ä¸è¦ç”¨å¼•å·å¤è¿°å¯¹æ–¹çš„è¯å†è¯„ä»·ï¼ˆã€Œä½ è¯´çš„'XX'è®©æˆ‘...ã€ï¼‰\n\
             - ä¸è¦æ¯å¥éƒ½ç”¨å è¯å–èŒï¼ˆé™¤éè§’è‰²è®¾å®šå¦‚æ­¤ä¸”åœºæ™¯åˆé€‚ï¼‰\n\
             - ä¸è¦åœ¨æƒ…æ„Ÿåœºæ™¯ç»™å»ºè®®ï¼ˆå¯¹æ–¹è¯´éš¾è¿‡ï¼Œä½ ä¸è¦è¯´ã€Œè¯•è¯•åšXXã€ï¼‰\n\
             - ä¸è¦æ— æ¥ç”±åœ°é“æ­‰ï¼ˆã€Œä¸å¥½æ„æ€è®©ä½ æ‹…å¿ƒäº†ã€â€”â€”å¦‚æœæ²¡åšé”™äº‹å°±ä¸è¦é“æ­‰ï¼‰",
            length_rule, structure_rule, latest_user_quote, history_anchor
        )
    }

    /// Send a message: validate â†’ detect type â†’ persist user msg â†’ build context â†’
    /// ä¸‰çº§æ¨¡å‹ç®¡çº¿ï¼ˆé•¿ä¸Šä¸‹æ–‡è’¸é¦+æ¨ç†+å¯¹è¯ï¼‰â†’ persist assistant msg â†’ check memory.
    ///
    /// ä¸‰çº§æ¨¡å‹ç®¡çº¿ï¼ˆenable_thinking=true æ—¶ï¼‰ï¼š
    ///   Phase 0: GLM-4-LONG é•¿ä¸Šä¸‹æ–‡è’¸é¦ï¼ˆä»…åœ¨ä¸Šä¸‹æ–‡è¶…é•¿æ—¶è§¦å‘ï¼‰
    ///   Phase 1: GLM-4-AIR æ·±åº¦æ¨ç† â†’ è¾“å‡ºæ€è€ƒé“¾ï¼ˆThinkingDeltaï¼‰+ åˆ†æç»“è®º
    ///   Phase 2: å°†åˆ†æç»“è®ºæ³¨å…¥ä¸Šä¸‹æ–‡ â†’ GLM-4.7 ç”Ÿæˆè‡ªç„¶å¯¹è¯å›å¤ï¼ˆContentDeltaï¼‰
    ///
    /// å•æ¨¡å‹æ¨¡å¼ï¼ˆenable_thinking=false æ—¶ï¼‰ï¼š
    ///   ç›´æ¥ä½¿ç”¨ chat_model ç”Ÿæˆå¯¹è¯å›å¤
    pub async fn send_message(
        &self,
        conversation_id: &str,
        content: &str,
        chat_model: &str,
        thinking_model: &str,
        enable_thinking: bool,
        on_event: impl Fn(ChatStreamEvent),
    ) -> Result<(), ChatError> {
        Self::validate_message(content)?;

        // è‡ªåŠ¨æ£€æµ‹ say/do ç±»å‹
        let message_type = Self::detect_message_type(content);

        let user_msg = Message {
            id: uuid::Uuid::new_v4().to_string(),
            role: MessageRole::User,
            content: content.to_string(),
            thinking_content: None,
            model: chat_model.to_string(),
            timestamp: chrono::Utc::now().timestamp_millis(),
            message_type: message_type.clone(),
        };
        self.conversation_store
            .add_message(conversation_id, user_msg)?;

        // å¢åŠ è½®æ¬¡è®¡æ•°
        self.conversation_store
            .increment_turn_count(conversation_id)?;

        let conv = self.conversation_store.load_conversation(conversation_id)?;

        // åŠ è½½è®°å¿†ç´¢å¼•
        let memory_summaries = self
            .memory_engine
            .load_memory_index(conversation_id)
            .unwrap_or_default();

        // æ„å»ºä¸Šä¸‹æ–‡å¢å¼ºçš„æ¶ˆæ¯åˆ—è¡¨
        let mut enhanced_messages =
            Self::build_context_enhanced_messages(&conv, content, &memory_summaries);

        // æ³¨å…¥ say/do æ¨¡å¼æç¤ºï¼ˆæ’å…¥åˆ°æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ä¹‹å‰ï¼Œç¡®ä¿ç”¨æˆ·æ¶ˆæ¯æ˜¯æœ€åä¸€æ¡ï¼‰
        let style_hint = SayDoDetector::build_style_prompt(&message_type);
        let style_msg = Message {
            id: String::new(),
            role: MessageRole::System,
            content: style_hint.to_string(),
            thinking_content: None,
            model: "system".to_string(),
            timestamp: 0,
            message_type: MessageType::Say,
        };
        // æ‰¾åˆ°æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯çš„ä½ç½®ï¼Œå°† style hint æ’å…¥åˆ°å®ƒä¹‹å‰
        let last_user_idx = enhanced_messages
            .iter()
            .rposition(|m| m.role == MessageRole::User);
        if let Some(idx) = last_user_idx {
            enhanced_messages.insert(idx, style_msg);
        } else {
            enhanced_messages.push(style_msg);
        }

        let non_system_for_hint: Vec<&Message> = conv
            .messages
            .iter()
            .filter(|m| m.role != MessageRole::System)
            .collect();
        let quality_hint =
            Self::build_humanization_hint(content, &non_system_for_hint, &message_type);
        let quality_msg = Message {
            id: String::new(),
            role: MessageRole::System,
            content: quality_hint,
            thinking_content: None,
            model: "system".to_string(),
            timestamp: 0,
            message_type: MessageType::Say,
        };
        let last_user_idx = enhanced_messages
            .iter()
            .rposition(|m| m.role == MessageRole::User);
        if let Some(idx) = last_user_idx {
            enhanced_messages.insert(idx, quality_msg);
        } else {
            enhanced_messages.push(quality_msg);
        }

        // â•â• Token é¢„ç®—æœ€ç»ˆå®ˆå« â€” æ¸è¿›å¼è£å‰ª â•â•
        // ä¸å†ä¸€åˆ€åˆ‡ï¼Œè€Œæ˜¯åˆ†çº§é€æ­¥å‡å°‘ä¸Šä¸‹æ–‡ï¼š
        //   Level 1 (>180K): åˆå¹¶ç›¸ä¼¼çš„ system æ¶ˆæ¯ï¼Œå‡å°‘é‡å¤
        //   Level 2 (>180K after L1): è£å‰ªå¯¹è¯å†å²åˆ°æœ€è¿‘ 14 æ¡
        //   Level 3 (>180K after L2): è£å‰ªå¯¹è¯å†å²åˆ°æœ€è¿‘ 8 æ¡
        //   Level 4 (>180K after L3): æç«¯æ¨¡å¼ï¼Œåªä¿ç•™æ ¸å¿ƒ system + æœ€è¿‘ 6 æ¡
        let total_tokens = Self::estimate_token_count(&enhanced_messages);
        if total_tokens > 180_000 {
            enhanced_messages = Self::gradual_context_trim(enhanced_messages, 180_000);
        }

        // â•â• ä¸‰çº§æ¨¡å‹ç®¡çº¿ï¼šé•¿ä¸Šä¸‹æ–‡è’¸é¦ â†’ æ·±åº¦æ¨ç† â†’ è‡ªç„¶å¯¹è¯ â•â•
        let (full_content, full_thinking) = if enable_thinking {
            // â”€â”€ Phase 0: è¯„ä¼°ä¸Šä¸‹æ–‡å¤æ‚åº¦ï¼Œå†³å®šæ˜¯å¦éœ€è¦ GLM-4-LONG â”€â”€
            let memory_summaries_for_assess = self
                .memory_engine
                .load_memory_index(conversation_id)
                .unwrap_or_default();
            let (needs_long_context, _total_tokens) =
                Self::assess_context_needs(&enhanced_messages, &memory_summaries_for_assess);

            // â”€â”€ Phase 0.5: é•¿ä¸Šä¸‹æ–‡è’¸é¦ï¼ˆGLM-4-LONGï¼Œä»…åœ¨ä¸Šä¸‹æ–‡è¶…é•¿æ—¶è§¦å‘ï¼‰â”€â”€
            if needs_long_context {
                let distilled = self
                    .request_long_context_distillation(
                        &enhanced_messages,
                        &memory_summaries_for_assess,
                        content,
                        &on_event,
                    )
                    .await;
                if !distilled.trim().is_empty() {
                    let distill_msg = Message {
                        id: String::new(),
                        role: MessageRole::System,
                        content: format!(
                            "ã€é•¿ä¸Šä¸‹æ–‡è’¸é¦æ‘˜è¦ â€” ä»¥ä¸‹ä¸º GLM-4-LONG æ•´ç†çš„å…³é”®ä¿¡æ¯ï¼Œå¿…é¡»ä¸¥æ ¼éµå®ˆã€‘\n{}\n",
                            distilled
                        ),
                        thinking_content: None,
                        model: "system".to_string(),
                        timestamp: 0,
                        message_type: MessageType::Say,
                    };
                    let last_user_idx = enhanced_messages
                        .iter()
                        .rposition(|m| m.role == MessageRole::User);
                    if let Some(idx) = last_user_idx {
                        enhanced_messages.insert(idx, distill_msg);
                    } else {
                        enhanced_messages.push(distill_msg);
                    }
                }
            }

            // â”€â”€ Phase 1: æ¨ç†æ¨¡å‹ï¼ˆGLM-4-AIRï¼‰æ·±åº¦åˆ†æ â”€â”€
            let (reasoning_conclusion, thinking_text) = self
                .request_reasoning(thinking_model, &enhanced_messages, &on_event)
                .await;

            // â”€â”€ Phase 1.5: GLM-4.7 è¾…åŠ© thinkingï¼ˆç‰¹å®šåœºæ™¯ä¸‹è§¦å‘ï¼‰â”€â”€
            let auxiliary_supplement = if Self::should_use_auxiliary_thinking(
                content, &reasoning_conclusion, &conv
            ) {
                self.request_auxiliary_thinking(
                    &enhanced_messages, &reasoning_conclusion, &on_event
                ).await
            } else {
                String::new()
            };

            // â”€â”€ Phase 2: å°†æ¨ç†ç»“è®ºæ³¨å…¥ä¸Šä¸‹æ–‡ï¼Œä¾›å¯¹è¯æ¨¡å‹å‚è€ƒ â”€â”€
            let combined_reasoning = if !auxiliary_supplement.is_empty() {
                if reasoning_conclusion.trim().is_empty() {
                    auxiliary_supplement
                } else {
                    format!("{}\n\nã€è¾…åŠ©æ¨ç†è¡¥å……ã€‘\n{}", reasoning_conclusion, auxiliary_supplement)
                }
            } else {
                reasoning_conclusion.clone()
            };

            if !combined_reasoning.trim().is_empty() {
                let reasoning_msg = Message {
                    id: String::new(),
                    role: MessageRole::System,
                    content: format!(
                        "ã€æ·±åº¦æ¨ç†åˆ†æç»“æœã€‘\n{}\n\n\
                         â–  æ‰§è¡ŒæŒ‡ä»¤ï¼š\n\
                         åŸºäºä»¥ä¸Šåˆ†æï¼Œä»¥è§’è‰²èº«ä»½è‡ªç„¶åœ°å›å¤ç”¨æˆ·ã€‚\n\
                         - åˆ†æä¸­æåˆ°çš„å…³é”®äº‹å®å¿…é¡»å‡†ç¡®ä½“ç°åœ¨å›å¤ä¸­\n\
                         - åˆ†æå»ºè®®çš„æƒ…æ„Ÿç­–ç•¥å¿…é¡»æ‰§è¡Œ\n\
                         - ä¸è¦åœ¨å›å¤ä¸­æåŠåˆ†æè¿‡ç¨‹æœ¬èº«\n\
                         - å›å¤å¿…é¡»å®Œæ•´ï¼Œä¸è¦æˆªæ–­æˆ–çœç•¥\n\
                         - åƒçœŸäººä¸€æ ·è‡ªç„¶åœ°è¡¨è¾¾ï¼Œæœ‰æƒ…ç»ªã€æœ‰æ¸©åº¦ã€æœ‰ä¸ªæ€§",
                        combined_reasoning
                    ),
                    thinking_content: None,
                    model: "system".to_string(),
                    timestamp: 0,
                    message_type: MessageType::Say,
                };
                // æ’å…¥åˆ°æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ä¹‹å‰
                let last_user_idx = enhanced_messages
                    .iter()
                    .rposition(|m| m.role == MessageRole::User);
                if let Some(idx) = last_user_idx {
                    enhanced_messages.insert(idx, reasoning_msg);
                } else {
                    enhanced_messages.push(reasoning_msg);
                }
            }

            // â”€â”€ Phase 3: å¯¹è¯æ¨¡å‹ï¼ˆGLM-4.7ï¼‰ç”Ÿæˆè‡ªç„¶å›å¤ â”€â”€
            // å¯¹è¯æ¨¡å‹å§‹ç»ˆå…³é—­æ€è€ƒï¼Œç”±æ¨ç†æ¨¡å‹ä¸“è´£æ€è€ƒ
            let (content, _) = self
                .request_with_fallback(chat_model, false, &enhanced_messages, &on_event)
                .await?;

            (content, thinking_text)
        } else {
            // â”€â”€ å•æ¨¡å‹æ¨¡å¼ï¼šç›´æ¥ä½¿ç”¨å¯¹è¯æ¨¡å‹ï¼Œæ— æ¨ç† â”€â”€
            self.request_with_fallback(chat_model, false, &enhanced_messages, &on_event)
                .await?
        };

        // å¦‚æœ AI è¿”å›äº†ç©ºå†…å®¹ï¼ˆå·²ç»è¿‡å¤šçº§é™çº§é‡è¯•ï¼‰ï¼ŒæŠ¥å‘Šæœ€ç»ˆé”™è¯¯
        if full_content.trim().is_empty() {
            on_event(ChatStreamEvent::Error(
                "AI æš‚æ—¶æ— æ³•ç”Ÿæˆå›å¤ï¼Œå·²è‡ªåŠ¨å°è¯•å¤šç§æ–¹å¼å‡æœªæˆåŠŸã€‚è¯·é‡è¯•æˆ–ç¼©çŸ­ä¹‹å‰çš„å¯¹è¯ã€‚"
                    .to_string(),
            ));
            on_event(ChatStreamEvent::Done);
            return Ok(());
        }

        let thinking = if full_thinking.is_empty() {
            None
        } else {
            Some(full_thinking)
        };

        let assistant_msg = Message {
            id: uuid::Uuid::new_v4().to_string(),
            role: MessageRole::Assistant,
            content: full_content,
            thinking_content: thinking,
            model: chat_model.to_string(),
            timestamp: chrono::Utc::now().timestamp_millis(),
            message_type: MessageType::Say,
        };
        self.conversation_store
            .add_message(conversation_id, assistant_msg)?;

        // Send Done after message is persisted so Flutter reloads the saved data
        on_event(ChatStreamEvent::Done);

        Ok(())
    }

    /// é‡æ–°ç”ŸæˆAIå›å¤ï¼šä¸æ·»åŠ ç”¨æˆ·æ¶ˆæ¯ï¼Œç›´æ¥åŸºäºç°æœ‰å¯¹è¯ä¸Šä¸‹æ–‡é‡æ–°è¯·æ±‚AI
    /// åŒæ ·éµå¾ªä¸‰çº§æ¨¡å‹ç®¡çº¿ï¼šGLM-4-LONGè’¸é¦â†’GLM-4-AIRæ¨ç†â†’GLM-4.7å¯¹è¯
    pub async fn regenerate_response(
        &self,
        conversation_id: &str,
        chat_model: &str,
        thinking_model: &str,
        enable_thinking: bool,
        on_event: impl Fn(ChatStreamEvent),
    ) -> Result<(), ChatError> {
        let conv = self.conversation_store.load_conversation(conversation_id)?;

        // æ‰¾åˆ°æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯çš„å†…å®¹ï¼ˆç”¨äºæ„å»ºä¸Šä¸‹æ–‡ï¼‰
        let last_user_content = conv
            .messages
            .iter()
            .rev()
            .find(|m| m.role == MessageRole::User)
            .map(|m| m.content.clone())
            .unwrap_or_default();

        if last_user_content.is_empty() {
            return Err(ChatError::ValidationError {
                message: "No user message found to regenerate from".to_string(),
            });
        }

        let message_type = Self::detect_message_type(&last_user_content);

        // åŠ è½½è®°å¿†ç´¢å¼•
        let memory_summaries = self
            .memory_engine
            .load_memory_index(conversation_id)
            .unwrap_or_default();

        // æ„å»ºä¸Šä¸‹æ–‡å¢å¼ºçš„æ¶ˆæ¯åˆ—è¡¨
        let mut enhanced_messages =
            Self::build_context_enhanced_messages(&conv, &last_user_content, &memory_summaries);

        // æ³¨å…¥ say/do æ¨¡å¼æç¤º
        let style_hint = SayDoDetector::build_style_prompt(&message_type);
        let style_msg = Message {
            id: String::new(),
            role: MessageRole::System,
            content: style_hint.to_string(),
            thinking_content: None,
            model: "system".to_string(),
            timestamp: 0,
            message_type: MessageType::Say,
        };
        let last_user_idx = enhanced_messages
            .iter()
            .rposition(|m| m.role == MessageRole::User);
        if let Some(idx) = last_user_idx {
            enhanced_messages.insert(idx, style_msg);
        } else {
            enhanced_messages.push(style_msg);
        }

        let non_system_for_hint: Vec<&Message> = conv
            .messages
            .iter()
            .filter(|m| m.role != MessageRole::System)
            .collect();
        let quality_hint =
            Self::build_humanization_hint(&last_user_content, &non_system_for_hint, &message_type);
        let quality_msg = Message {
            id: String::new(),
            role: MessageRole::System,
            content: quality_hint,
            thinking_content: None,
            model: "system".to_string(),
            timestamp: 0,
            message_type: MessageType::Say,
        };
        let last_user_idx = enhanced_messages
            .iter()
            .rposition(|m| m.role == MessageRole::User);
        if let Some(idx) = last_user_idx {
            enhanced_messages.insert(idx, quality_msg);
        } else {
            enhanced_messages.push(quality_msg);
        }

        // â•â• Token é¢„ç®—æœ€ç»ˆå®ˆå« â€” æ¸è¿›å¼è£å‰ªï¼ˆä¸ send_message ç›¸åŒé€»è¾‘ï¼‰â•â•
        let total_tokens = Self::estimate_token_count(&enhanced_messages);
        if total_tokens > 180_000 {
            enhanced_messages = Self::gradual_context_trim(enhanced_messages, 180_000);
        }

        // â•â• ä¸‰çº§æ¨¡å‹ç®¡çº¿ï¼ˆä¸ send_message ç›¸åŒé€»è¾‘ï¼‰â•â•
        let (full_content, full_thinking) = if enable_thinking {
            // â”€â”€ Phase 0: è¯„ä¼°ä¸Šä¸‹æ–‡å¤æ‚åº¦ï¼Œå†³å®šæ˜¯å¦éœ€è¦ GLM-4-LONG â”€â”€
            let memory_summaries_for_assess = self
                .memory_engine
                .load_memory_index(conversation_id)
                .unwrap_or_default();
            let (needs_long_context, _total_tokens) =
                Self::assess_context_needs(&enhanced_messages, &memory_summaries_for_assess);

            // â”€â”€ Phase 0.5: é•¿ä¸Šä¸‹æ–‡è’¸é¦ï¼ˆGLM-4-LONGï¼Œä»…åœ¨éœ€è¦æ—¶è§¦å‘ï¼‰â”€â”€
            if needs_long_context {
                let distilled = self
                    .request_long_context_distillation(
                        &enhanced_messages,
                        &memory_summaries_for_assess,
                        &last_user_content,
                        &on_event,
                    )
                    .await;
                if !distilled.trim().is_empty() {
                    let distill_msg = Message {
                        id: String::new(),
                        role: MessageRole::System,
                        content: format!(
                            "ã€é•¿ä¸Šä¸‹æ–‡è’¸é¦æ‘˜è¦ â€” ä»¥ä¸‹ä¸º GLM-4-LONG æ•´ç†çš„å…³é”®ä¿¡æ¯ï¼Œå¿…é¡»ä¸¥æ ¼éµå®ˆã€‘\n{}\n",
                            distilled
                        ),
                        thinking_content: None,
                        model: "system".to_string(),
                        timestamp: 0,
                        message_type: MessageType::Say,
                    };
                    let last_user_idx = enhanced_messages
                        .iter()
                        .rposition(|m| m.role == MessageRole::User);
                    if let Some(idx) = last_user_idx {
                        enhanced_messages.insert(idx, distill_msg);
                    } else {
                        enhanced_messages.push(distill_msg);
                    }
                }
            }

            // â”€â”€ Phase 1: æ¨ç†æ¨¡å‹ï¼ˆGLM-4-AIRï¼‰æ·±åº¦åˆ†æ â”€â”€
            let (reasoning_conclusion, thinking_text) = self
                .request_reasoning(thinking_model, &enhanced_messages, &on_event)
                .await;

            // â”€â”€ Phase 1.5: GLM-4.7 è¾…åŠ© thinkingï¼ˆç‰¹å®šåœºæ™¯ä¸‹è§¦å‘ï¼‰â”€â”€
            let auxiliary_supplement = if Self::should_use_auxiliary_thinking(
                &last_user_content, &reasoning_conclusion, &conv
            ) {
                self.request_auxiliary_thinking(
                    &enhanced_messages, &reasoning_conclusion, &on_event
                ).await
            } else {
                String::new()
            };

            // â”€â”€ Phase 2: å°†æ¨ç†ç»“è®ºæ³¨å…¥ä¸Šä¸‹æ–‡ â”€â”€
            let combined_reasoning = if !auxiliary_supplement.is_empty() {
                if reasoning_conclusion.trim().is_empty() {
                    auxiliary_supplement
                } else {
                    format!("{}\n\nã€è¾…åŠ©æ¨ç†è¡¥å……ã€‘\n{}", reasoning_conclusion, auxiliary_supplement)
                }
            } else {
                reasoning_conclusion.clone()
            };

            if !combined_reasoning.trim().is_empty() {
                let reasoning_msg = Message {
                    id: String::new(),
                    role: MessageRole::System,
                    content: format!(
                        "ã€æ·±åº¦æ¨ç†åˆ†æç»“æœã€‘\n{}\n\n\
                         â–  æ‰§è¡ŒæŒ‡ä»¤ï¼š\n\
                         åŸºäºä»¥ä¸Šåˆ†æï¼Œä»¥è§’è‰²èº«ä»½è‡ªç„¶åœ°å›å¤ç”¨æˆ·ã€‚\n\
                         - åˆ†æä¸­æåˆ°çš„å…³é”®äº‹å®å¿…é¡»å‡†ç¡®ä½“ç°åœ¨å›å¤ä¸­\n\
                         - åˆ†æå»ºè®®çš„æƒ…æ„Ÿç­–ç•¥å¿…é¡»æ‰§è¡Œ\n\
                         - ä¸è¦åœ¨å›å¤ä¸­æåŠåˆ†æè¿‡ç¨‹æœ¬èº«\n\
                         - å›å¤å¿…é¡»å®Œæ•´ï¼Œä¸è¦æˆªæ–­æˆ–çœç•¥\n\
                         - åƒçœŸäººä¸€æ ·è‡ªç„¶åœ°è¡¨è¾¾ï¼Œæœ‰æƒ…ç»ªã€æœ‰æ¸©åº¦ã€æœ‰ä¸ªæ€§",
                        combined_reasoning
                    ),
                    thinking_content: None,
                    model: "system".to_string(),
                    timestamp: 0,
                    message_type: MessageType::Say,
                };
                let last_user_idx = enhanced_messages
                    .iter()
                    .rposition(|m| m.role == MessageRole::User);
                if let Some(idx) = last_user_idx {
                    enhanced_messages.insert(idx, reasoning_msg);
                } else {
                    enhanced_messages.push(reasoning_msg);
                }
            }

            // â”€â”€ Phase 3: å¯¹è¯æ¨¡å‹ï¼ˆGLM-4.7ï¼‰ç”Ÿæˆè‡ªç„¶å›å¤ â”€â”€
            let (content, _) = self
                .request_with_fallback(chat_model, false, &enhanced_messages, &on_event)
                .await?;

            (content, thinking_text)
        } else {
            self.request_with_fallback(chat_model, false, &enhanced_messages, &on_event)
                .await?
        };

        // å¦‚æœ AI è¿”å›äº†ç©ºå†…å®¹ï¼ˆå·²ç»è¿‡å¤šçº§é™çº§é‡è¯•ï¼‰ï¼ŒæŠ¥å‘Šæœ€ç»ˆé”™è¯¯
        if full_content.trim().is_empty() {
            on_event(ChatStreamEvent::Error(
                "AI æš‚æ—¶æ— æ³•ç”Ÿæˆå›å¤ï¼Œå·²è‡ªåŠ¨å°è¯•å¤šç§æ–¹å¼å‡æœªæˆåŠŸã€‚è¯·é‡è¯•æˆ–ç¼©çŸ­ä¹‹å‰çš„å¯¹è¯ã€‚"
                    .to_string(),
            ));
            on_event(ChatStreamEvent::Done);
            return Ok(());
        }

        let thinking = if full_thinking.is_empty() {
            None
        } else {
            Some(full_thinking)
        };

        let assistant_msg = Message {
            id: uuid::Uuid::new_v4().to_string(),
            role: MessageRole::Assistant,
            content: full_content,
            thinking_content: thinking,
            model: chat_model.to_string(),
            timestamp: chrono::Utc::now().timestamp_millis(),
            message_type: MessageType::Say,
        };
        self.conversation_store
            .add_message(conversation_id, assistant_msg)?;

        // Send Done after message is persisted so Flutter reloads the saved data
        on_event(ChatStreamEvent::Done);

        Ok(())
    }

    /// æ‰§è¡Œè®°å¿†æ€»ç»“ï¼ˆç”±å¤–éƒ¨è°ƒç”¨ï¼Œåœ¨ send_message å®Œæˆåå¼‚æ­¥è§¦å‘ï¼‰
    /// é‡‡ç”¨åŒé˜¶æ®µéªŒè¯ï¼š
    ///   é˜¶æ®µ1: ä½¿ç”¨æ€»ç»“æ¨¡å‹ç”Ÿæˆæ‘˜è¦
    ///   é˜¶æ®µ2: ä½¿ç”¨éªŒè¯ prompt æ£€æŸ¥æ ¸å¿ƒäº‹å®å®Œæ•´æ€§ï¼ˆå½“å·²æœ‰æ‘˜è¦æ—¶ï¼‰
    pub async fn summarize_memory(
        &self,
        conversation_id: &str,
        on_event: impl Fn(ChatStreamEvent),
    ) -> Result<Option<MemorySummary>, ChatError> {
        let conv = self.conversation_store.load_conversation(conversation_id)?;

        if !MemoryEngine::should_summarize(conv.turn_count) {
            return Ok(None);
        }

        // è·å–éœ€è¦æ€»ç»“çš„æ¶ˆæ¯èŒƒå›´
        let turn_start = if conv.turn_count > 10 {
            conv.turn_count - 10 + 1
        } else {
            1
        };
        let turn_end = conv.turn_count;

        // è·å–æœ€è¿‘ 20 æ¡æ¶ˆæ¯ç”¨äºæ€»ç»“
        let recent_messages: Vec<Message> = conv
            .messages
            .iter()
            .filter(|m| m.role != MessageRole::System)
            .rev()
            .take(20)
            .cloned()
            .collect::<Vec<_>>()
            .into_iter()
            .rev()
            .collect();

        let existing_summaries = self
            .memory_engine
            .load_memory_index(conversation_id)
            .unwrap_or_default();

        // åŠ¨æ€é€‰æ‹©æ€»ç»“æ¨¡å‹
        let summary_model = Self::choose_summary_model(&conv.messages);

        // â”€â”€ é˜¶æ®µ1: ç”Ÿæˆæ‘˜è¦ â”€â”€
        // å½“å·²æœ‰å¤šæ®µæ‘˜è¦æ—¶ï¼Œä½¿ç”¨é•¿æ‘˜è¦æ•´åˆ promptï¼›å¦åˆ™ä½¿ç”¨æ ‡å‡† prompt
        let prompt = if existing_summaries.len() >= 3 {
            MemoryEngine::build_long_summary_prompt(&existing_summaries, &recent_messages)
        } else {
            MemoryEngine::build_summarize_prompt(
                &recent_messages,
                &existing_summaries,
                turn_start,
                turn_end,
            )
        };

        let summary_messages = vec![
            Message {
                id: String::new(),
                role: MessageRole::System,
                content:
                    "ä½ æ˜¯ä¸€ä¸ªç²¾ç¡®çš„è®°å¿†ç®¡ç†ç³»ç»Ÿï¼Œè´Ÿè´£æ€»ç»“å¯¹è¯å†…å®¹ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§è¦æ±‚çš„JSONæ ¼å¼è¾“å‡ºã€‚"
                        .to_string(),
                thinking_content: None,
                model: "system".to_string(),
                timestamp: 0,
                message_type: MessageType::Say,
            },
            Message {
                id: String::new(),
                role: MessageRole::User,
                content: prompt,
                thinking_content: None,
                model: summary_model.to_string(),
                timestamp: 0,
                message_type: MessageType::Say,
            },
        ];

        let request_body = Self::build_request_body(
            &summary_messages,
            summary_model,
            false,
        );

        let token = {
            let mut auth = self.jwt_auth.lock().unwrap();
            auth.get_token()
        };

        let (summary_text, _) =
            StreamingHandler::stream_chat(BIGMODEL_API_URL, &token, request_body, &on_event)
                .await?;

        // è§£ææ€»ç»“ç»“æœ
        let parsed = match Self::parse_summary_json(&summary_text) {
            Ok(p) => p,
            Err(_) => return Ok(None),
        };

        let (final_summary, mut final_core_facts) = parsed;

        // â”€â”€ é˜¶æ®µ2: æ ¸å¿ƒäº‹å®å®Œæ•´æ€§éªŒè¯ï¼ˆå½“å·²æœ‰æ‘˜è¦æ—¶ï¼‰ â”€â”€
        if !existing_summaries.is_empty() {
            let original_facts: Vec<String> = existing_summaries
                .iter()
                .flat_map(|s| s.core_facts.clone())
                .collect();

            let verify_prompt = MemoryEngine::build_verify_summary_prompt(
                &original_facts,
                &final_summary,
                &final_core_facts,
            );

            let verify_messages = vec![
                Message {
                    id: String::new(),
                    role: MessageRole::System,
                    content: "ä½ æ˜¯ä¸€ä¸ªä¸¥è°¨çš„äº‹å®éªŒè¯ç³»ç»Ÿã€‚è¯·æ£€æŸ¥æ–°æ€»ç»“æ˜¯å¦å®Œæ•´ä¿ç•™äº†æ‰€æœ‰åŸå§‹æ ¸å¿ƒäº‹å®ã€‚åªè¾“å‡ºJSONã€‚".to_string(),
                    thinking_content: None,
                    model: "system".to_string(),
                    timestamp: 0,
                    message_type: MessageType::Say,
                },
                Message {
                    id: String::new(),
                    role: MessageRole::User,
                    content: verify_prompt,
                    thinking_content: None,
                    model: "glm-4.7-flash".to_string(),
                    timestamp: 0,
                    message_type: MessageType::Say,
                },
            ];

            let verify_body = Self::build_request_body(
                &verify_messages,
                "glm-4.7-flash",
                false,
            );

            let verify_token = {
                let mut auth = self.jwt_auth.lock().unwrap();
                auth.get_token()
            };

            // éªŒè¯é˜¶æ®µçš„äº‹ä»¶ä¸ä¼ é€’ç»™å‰ç«¯ï¼ˆé™é»˜æ‰§è¡Œï¼‰
            if let Ok((verify_text, _)) = StreamingHandler::stream_chat(
                BIGMODEL_API_URL,
                &verify_token,
                verify_body,
                |_| {}, // é™é»˜ï¼Œä¸å‘å‰ç«¯å‘é€éªŒè¯é˜¶æ®µçš„æµäº‹ä»¶
            )
            .await
            {
                // å°è¯•è§£æéªŒè¯ç»“æœ
                if let Some(start) = verify_text.find('{') {
                    if let Some(end) = verify_text.rfind('}') {
                        if let Ok(verify_json) =
                            serde_json::from_str::<serde_json::Value>(&verify_text[start..=end])
                        {
                            let is_valid = verify_json
                                .get("is_valid")
                                .and_then(|v| v.as_bool())
                                .unwrap_or(true);

                            if !is_valid {
                                // ä½¿ç”¨ä¿®æ­£åçš„æ ¸å¿ƒäº‹å®
                                if let Some(corrected) = verify_json
                                    .get("corrected_core_facts")
                                    .and_then(|v| v.as_array())
                                {
                                    let corrected_facts: Vec<String> = corrected
                                        .iter()
                                        .filter_map(|v| v.as_str().map(|s| s.to_string()))
                                        .collect();
                                    if !corrected_facts.is_empty() {
                                        final_core_facts = corrected_facts;
                                    }
                                }
                            }
                        }
                    }
                }
            }
        }

        // æ„å»ºæœ€ç»ˆè®°å¿†æ‘˜è¦
        let keywords = MemoryEngine::extract_keywords(&final_summary);
        let mut all_keywords = keywords;
        for fact in &final_core_facts {
            all_keywords.extend(MemoryEngine::extract_keywords(fact));
        }
        all_keywords.sort();
        all_keywords.dedup();

        let memory = MemorySummary {
            id: uuid::Uuid::new_v4().to_string(),
            summary: final_summary.clone(),
            core_facts: final_core_facts.clone(),
            turn_range_start: turn_start,
            turn_range_end: turn_end,
            created_at: chrono::Utc::now().timestamp_millis(),
            keywords: all_keywords,
            compression_generation: 0, // æ–°ç”Ÿæˆçš„æ‘˜è¦ï¼Œå‹ç¼©ä»£æ•°ä¸º 0
            // ç”Ÿæˆä¸Šä¸‹æ–‡å¢å¼ºå¡ç‰‡
            context_card: None, // å…ˆå ä½ï¼Œä¸‹é¢å¡«å……
            // ç”Ÿæˆæ’çº§åˆ†ç±»
            fact_tiers: MemoryEngine::classify_all_facts(&final_core_facts),
        };

        // ä¸ºæ–°æ‘˜è¦ç”Ÿæˆä¸Šä¸‹æ–‡å¢å¼ºå¡ç‰‡
        let memory = MemorySummary {
            context_card: Some(MemoryEngine::build_context_card(&memory)),
            ..memory
        };

        // ä¿å­˜åˆ°è®°å¿†ç´¢å¼•
        let mut summaries = existing_summaries;
        summaries.push(memory.clone());

        // â”€â”€ é˜¶æ®µ3: åˆ†çº§å‹ç¼©åˆå¹¶ï¼ˆå½“æ‘˜è¦æ•°é‡è¶…è¿‡é˜ˆå€¼æ—¶è‡ªåŠ¨è§¦å‘ï¼‰â”€â”€
        // æ’çº§åˆ¶åº¦ï¼šIdentity/CriticalEvent æ°¸ä¸ä¸¢å¼ƒï¼ŒSceneDetail ä¼˜å…ˆä¸¢å¼ƒ
        if MemoryEngine::should_tiered_merge(&summaries) {
            let (merged, llm_prompt) = MemoryEngine::tiered_merge(&summaries);

            if let Some(merge_prompt) = llm_prompt {
                // éœ€è¦ LLM è¾…åŠ©ç²¾ç‚¼ï¼ˆäº‹å®è¿‡å¤šï¼‰
                let merge_messages = vec![
                    Message {
                        id: String::new(),
                        role: MessageRole::System,
                        content: "ä½ æ˜¯ä¸€ä¸ªç²¾ç¡®çš„è®°å¿†å‹ç¼©ç³»ç»Ÿã€‚æŒ‰ç…§æ’çº§ä¿æŠ¤è§„åˆ™åˆå¹¶è®°å¿†ï¼ŒğŸ”’æ ‡è®°çš„äº‹å®ä¸€å­—ä¸æ”¹ã€‚åªè¾“å‡ºJSONã€‚".to_string(),
                        thinking_content: None,
                        model: "system".to_string(),
                        timestamp: 0,
                        message_type: MessageType::Say,
                    },
                    Message {
                        id: String::new(),
                        role: MessageRole::User,
                        content: merge_prompt,
                        thinking_content: None,
                        model: "glm-4.7-flash".to_string(),
                        timestamp: 0,
                        message_type: MessageType::Say,
                    },
                ];

                let merge_body = Self::build_request_body(&merge_messages, "glm-4.7-flash", false);
                let merge_token = {
                    let mut auth = self.jwt_auth.lock().unwrap();
                    auth.get_token()
                };

                if let Ok((merge_text, _)) = StreamingHandler::stream_chat(
                    BIGMODEL_API_URL, &merge_token, merge_body, |_| {},
                ).await {
                    if let Ok((merged_summary, merged_facts)) = Self::parse_summary_json(&merge_text) {
                        // è§£æ fact_tiers
                        let merged_tiers = MemoryEngine::classify_all_facts(&merged_facts);

                        let turn_start = merged.iter().map(|s| s.turn_range_start).min().unwrap_or(0);
                        let turn_end = merged.iter().map(|s| s.turn_range_end).max().unwrap_or(0);

                        let mut merged_keywords: Vec<String> = merged.iter()
                            .flat_map(|s| s.keywords.clone())
                            .collect();
                        merged_keywords.sort();
                        merged_keywords.dedup();

                        let llm_merged = MemorySummary {
                            id: uuid::Uuid::new_v4().to_string(),
                            summary: merged_summary,
                            core_facts: merged_facts.clone(),
                            turn_range_start: turn_start,
                            turn_range_end: turn_end,
                            created_at: chrono::Utc::now().timestamp_millis(),
                            keywords: merged_keywords,
                            compression_generation: merged.iter().map(|s| s.compression_generation).max().unwrap_or(0) + 1,
                            context_card: None,
                            fact_tiers: merged_tiers,
                        };
                        let llm_merged = MemorySummary {
                            context_card: Some(MemoryEngine::build_context_card(&llm_merged)),
                            ..llm_merged
                        };

                        summaries = vec![llm_merged];
                    } else {
                        summaries = merged;
                    }
                } else {
                    summaries = merged;
                }
            } else {
                summaries = merged;
            }

            // ä¸ºåˆå¹¶åçš„æ‰€æœ‰æ‘˜è¦è¡¥å……ä¸Šä¸‹æ–‡å¡ç‰‡ï¼ˆå¦‚æœç¼ºå¤±ï¼‰
            for s in summaries.iter_mut() {
                if s.context_card.is_none() {
                    s.context_card = Some(MemoryEngine::build_context_card(s));
                }
                if s.fact_tiers.len() != s.core_facts.len() {
                    s.fact_tiers = MemoryEngine::classify_all_facts(&s.core_facts);
                }
            }
        }

        self.memory_engine
            .save_memory_index(conversation_id, &summaries)?;

        // åŒæ—¶æ›´æ–°å¯¹è¯ä¸­çš„è®°å¿†æ‘˜è¦
        self.conversation_store
            .update_memory_summaries(conversation_id, &summaries)?;

        Ok(Some(memory))
    }

    /// è§£ææ€»ç»“ JSON
    fn parse_summary_json(text: &str) -> Result<(String, Vec<String>), String> {
        // å°è¯•æå– JSON éƒ¨åˆ†
        let json_str = if let Some(start) = text.find('{') {
            if let Some(end) = text.rfind('}') {
                &text[start..=end]
            } else {
                text
            }
        } else {
            text
        };

        let json: serde_json::Value =
            serde_json::from_str(json_str).map_err(|e| format!("JSON parse error: {}", e))?;

        let summary = json
            .get("summary")
            .and_then(|v| v.as_str())
            .unwrap_or("")
            .to_string();

        let core_facts: Vec<String> = json
            .get("core_facts")
            .and_then(|v| v.as_array())
            .map(|arr| {
                arr.iter()
                    .filter_map(|v| v.as_str().map(|s| s.to_string()))
                    .collect()
            })
            .unwrap_or_default();

        Ok((summary, core_facts))
    }

    /// é‡å¯å‰§æƒ…ï¼šæ¸…é™¤å¯¹è¯æ¶ˆæ¯ä½†ä¿ç•™ system prompt å’Œè§’è‰²å¼€åœºç™½
    pub fn restart_story(&self, conversation_id: &str) -> Result<(), ChatError> {
        let mut conv = self.conversation_store.load_conversation(conversation_id)?;

        // ä¿ç•™ system æ¶ˆæ¯å’Œç¬¬ä¸€æ¡ assistant æ¶ˆæ¯ï¼ˆå¼€åœºç™½ï¼‰
        let mut kept_messages: Vec<Message> = Vec::new();
        let mut found_greeting = false;

        for msg in &conv.messages {
            if msg.role == MessageRole::System {
                kept_messages.push(msg.clone());
            } else if msg.role == MessageRole::Assistant && !found_greeting {
                // ä¿ç•™ç¬¬ä¸€æ¡ AI æ¶ˆæ¯ä½œä¸ºå¼€åœºç™½
                kept_messages.push(msg.clone());
                found_greeting = true;
            }
        }

        conv.messages = kept_messages;
        conv.turn_count = 0;
        conv.memory_summaries.clear();
        conv.updated_at = chrono::Utc::now().timestamp_millis();

        self.conversation_store.save_conversation(&conv)?;

        // æ¸…é™¤è®°å¿†ç´¢å¼•
        self.memory_engine.delete_memory_index(conversation_id)?;

        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    fn make_message(role: MessageRole, content: &str) -> Message {
        Message {
            id: uuid::Uuid::new_v4().to_string(),
            role,
            content: content.to_string(),
            thinking_content: None,
            model: "glm-4-flash".to_string(),
            timestamp: chrono::Utc::now().timestamp_millis(),
            message_type: MessageType::Say,
        }
    }

    #[test]
    fn test_validate_message_rejects_empty_string() {
        assert!(ChatEngine::validate_message("").is_err());
    }

    #[test]
    fn test_validate_message_rejects_spaces_only() {
        assert!(ChatEngine::validate_message("   ").is_err());
    }

    #[test]
    fn test_validate_message_rejects_tabs_and_newlines() {
        assert!(ChatEngine::validate_message("\t\n\r\n  ").is_err());
    }

    #[test]
    fn test_validate_message_accepts_normal_text() {
        assert!(ChatEngine::validate_message("Hello").is_ok());
    }

    #[test]
    fn test_validate_message_accepts_text_with_surrounding_whitespace() {
        assert!(ChatEngine::validate_message("  Hello  ").is_ok());
    }

    #[test]
    fn test_validate_message_returns_validation_error_type() {
        match ChatEngine::validate_message("") {
            Err(ChatError::ValidationError { .. }) => {}
            other => panic!("Expected ValidationError, got {:?}", other),
        }
    }

    #[test]
    fn test_build_request_body_always_has_stream_true() {
        let messages = vec![make_message(MessageRole::User, "hi")];
        let body = ChatEngine::build_request_body(&messages, "glm-4-flash", false);
        assert_eq!(body["stream"], serde_json::json!(true));
    }

    #[test]
    fn test_build_request_body_correct_model() {
        let messages = vec![make_message(MessageRole::User, "hi")];
        let body = ChatEngine::build_request_body(&messages, "glm-4-long", false);
        assert_eq!(body["model"], serde_json::json!("glm-4-long"));
    }

    #[test]
    fn test_build_request_body_messages_array_matches() {
        let messages = vec![
            make_message(MessageRole::User, "Hello"),
            make_message(MessageRole::Assistant, "Hi there"),
            make_message(MessageRole::User, "How are you?"),
        ];
        let body = ChatEngine::build_request_body(&messages, "glm-4-flash", false);
        let api_msgs = body["messages"].as_array().unwrap();
        assert_eq!(api_msgs.len(), 3);
        assert_eq!(api_msgs[0]["role"], "user");
        assert_eq!(api_msgs[0]["content"], "Hello");
        assert_eq!(api_msgs[1]["role"], "assistant");
        assert_eq!(api_msgs[1]["content"], "Hi there");
        assert_eq!(api_msgs[2]["role"], "user");
        assert_eq!(api_msgs[2]["content"], "How are you?");
    }

    #[test]
    fn test_build_request_body_system_role() {
        let messages = vec![make_message(MessageRole::System, "You are helpful")];
        let body = ChatEngine::build_request_body(&messages, "glm-4-flash", false);
        let api_msgs = body["messages"].as_array().unwrap();
        assert_eq!(api_msgs[0]["role"], "system");
    }

    #[test]
    fn test_build_request_body_empty_messages() {
        let body = ChatEngine::build_request_body(&[], "glm-4-flash", false);
        let api_msgs = body["messages"].as_array().unwrap();
        assert!(api_msgs.is_empty());
        assert_eq!(body["stream"], serde_json::json!(true));
    }

    #[test]
    fn test_build_request_body_thinking_enabled_for_glm4_air() {
        let messages = vec![make_message(MessageRole::User, "think hard")];
        let body = ChatEngine::build_request_body(&messages, "glm-4-air", true);
        assert_eq!(body["thinking"], serde_json::json!({"type": "enabled"}));
    }

    #[test]
    fn test_build_request_body_no_thinking_for_glm4_air_disabled() {
        let messages = vec![make_message(MessageRole::User, "hi")];
        let body = ChatEngine::build_request_body(&messages, "glm-4-air", false);
        assert_eq!(body["thinking"], serde_json::json!({"type": "disabled"}));
    }

    #[test]
    fn test_build_request_body_thinking_disabled_explicitly() {
        let messages = vec![make_message(MessageRole::User, "hi")];
        // glm-4.7 with thinking disabled should explicitly send disabled
        let body = ChatEngine::build_request_body(&messages, "glm-4.7", false);
        assert_eq!(body["thinking"], serde_json::json!({"type": "disabled"}));
        // glm-4.7-flash with thinking disabled
        let body = ChatEngine::build_request_body(&messages, "glm-4.7-flash", false);
        assert_eq!(body["thinking"], serde_json::json!({"type": "disabled"}));
    }

    #[test]
    fn test_build_request_body_thinking_for_glm4_7_enabled_when_requested() {
        let messages = vec![make_message(MessageRole::User, "think hard")];
        let body = ChatEngine::build_request_body(&messages, "glm-4.7", true);
        // GLM-4.7 ç°åœ¨æ”¯æŒ thinkingï¼ˆå®˜æ–¹ç¡®è®¤ï¼‰ï¼Œç”¨äºè¾…åŠ©æ¨ç†åœºæ™¯
        assert_eq!(body["thinking"], serde_json::json!({"type": "enabled"}));
    }

    #[test]
    fn test_build_request_body_no_thinking_for_unknown_model() {
        let messages = vec![make_message(MessageRole::User, "hi")];
        for model in &["glm-4-flash", "glm-4-long"] {
            let body = ChatEngine::build_request_body(&messages, model, true);
            assert!(
                body.get("thinking").is_none(),
                "Model {} should not have thinking param",
                model
            );
        }
    }

    #[test]
    fn test_build_request_body_stream_true_with_all_models() {
        let messages = vec![make_message(MessageRole::User, "test")];
        for model in &["glm-4.7", "glm-4-flash", "glm-4-air", "glm-4-long"] {
            let body = ChatEngine::build_request_body(&messages, model, false);
            assert_eq!(
                body["stream"],
                serde_json::json!(true),
                "stream should be true for model {}",
                model
            );
        }
    }

    #[test]
    fn test_build_request_body_preserves_message_content_exactly() {
        let content = "Hello ä½ å¥½ ğŸŒ\nnewline\ttab";
        let messages = vec![make_message(MessageRole::User, content)];
        let body = ChatEngine::build_request_body(&messages, "glm-4-flash", false);
        assert_eq!(body["messages"][0]["content"], content);
    }

    #[test]
    fn test_detect_message_type() {
        assert_eq!(ChatEngine::detect_message_type("ä½ å¥½"), MessageType::Say);
        assert_eq!(ChatEngine::detect_message_type("*èµ°è¿‡å»*"), MessageType::Do);
        assert_eq!(
            ChatEngine::detect_message_type("*èµ°è¿‡å»* ä½ å¥½"),
            MessageType::Mixed
        );
    }

    #[test]
    fn test_should_enable_thinking() {
        assert!(ChatEngine::should_enable_thinking("glm-4-air", true));
        assert!(!ChatEngine::should_enable_thinking("glm-4-air", false));
        // GLM-4.7 ç°åœ¨æ”¯æŒ thinkingï¼Œç”¨äºè¾…åŠ©æ¨ç†
        assert!(ChatEngine::should_enable_thinking("glm-4.7", true));
        assert!(!ChatEngine::should_enable_thinking("glm-4.7", false));
        assert!(ChatEngine::should_enable_thinking("glm-4.7-flash", true));
        assert!(!ChatEngine::should_enable_thinking("glm-4-long", true));
    }

    #[test]
    fn test_parse_summary_json() {
        let json = r#"{"summary": "æµ‹è¯•æ€»ç»“", "core_facts": ["äº‹å®1", "äº‹å®2"]}"#;
        let result = ChatEngine::parse_summary_json(json).unwrap();
        assert_eq!(result.0, "æµ‹è¯•æ€»ç»“");
        assert_eq!(result.1, vec!["äº‹å®1", "äº‹å®2"]);
    }

    #[test]
    fn test_parse_summary_json_with_extra_text() {
        let text = r#"å¥½çš„ï¼Œä»¥ä¸‹æ˜¯æ€»ç»“ï¼š
{"summary": "æ¦‚æ‹¬å†…å®¹", "core_facts": ["èº«ä»½ä¿¡æ¯"]}
ä»¥ä¸Šå°±æ˜¯æ€»ç»“ã€‚"#;
        let result = ChatEngine::parse_summary_json(text).unwrap();
        assert_eq!(result.0, "æ¦‚æ‹¬å†…å®¹");
    }
}
